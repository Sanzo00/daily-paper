{"RAG": {"2506.12494": "|**2025-06-30**|**FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation**|Zhuocheng Zhang et.al.|[2506.12494_(ACL)](http://arxiv.org/abs/2506.12494)|null|\n", "2506.07334": "|**2025-06-09**|**Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models**|Haoyu Wang et.al.|[2506.07334](http://arxiv.org/abs/2506.07334)|null|\n", "2506.11092": "|**2025-07-19**|**Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation**|Jubin Abhishek Soni et.al.|[2506.11092_(ISS)](http://arxiv.org/abs/2506.11092)|null|\n", "2506.12149": "|**2025-06-13**|**Maximally-Informative Retrieval for State Space Model Generation**|Evan Becker et.al.|[2506.12149](http://arxiv.org/abs/2506.12149)|null|\n", "2506.09200": "|**2025-06-12**|**FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems**|Val Andrei Fajardo et.al.|[2506.09200_(ICML)](http://arxiv.org/abs/2506.09200)|**[link](https://github.com/VectorInstitute/fed-rag)**|\n", "2506.07270": "|**2025-06-08**|**Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs**|Atahan \u00d6zer et.al.|[2506.07270](http://arxiv.org/abs/2506.07270)|null|\n", "2506.09542": "|**2025-06-11**|**KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs**|Dingjun Wu et.al.|[2506.09542](http://arxiv.org/abs/2506.09542)|null|\n", "2506.05939": "|**2025-06-06**|**Respecting Temporal-Causal Consistency: Entity-Event Knowledge Graphs for Retrieval-Augmented Generation**|Ze Yu Zhang et.al.|[2506.05939](http://arxiv.org/abs/2506.05939)|null|\n", "2506.05766": "|**2025-06-06**|**BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions**|Saptarshi Sengupta et.al.|[2506.05766](http://arxiv.org/abs/2506.05766)|null|\n", "2506.13589": "|**2025-06-18**|**AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding**|Zhucun Xue et.al.|[2506.13589](http://arxiv.org/abs/2506.13589)|null|\n", "2506.12483": "|**2025-06-14**|**MALM: A Multi-Information Adapter for Large Language Models to Mitigate Hallucination**|Ao Jia et.al.|[2506.12483](http://arxiv.org/abs/2506.12483)|null|\n", "2506.09645": "|**2025-06-11**|**Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph Question Answering**|Tianjun Yao et.al.|[2506.09645](http://arxiv.org/abs/2506.09645)|null|\n", "2505.21919": "|**2025-05-28**|**Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference**|Yue Zhu et.al.|[2505.21919](http://arxiv.org/abs/2505.21919)|null|\n", "2505.18458": "|**2025-06-01**|**A Survey of LLM $\\times$ DATA**|Xuanhe Zhou et.al.|[2505.18458](http://arxiv.org/abs/2505.18458)|**[link](https://github.com/weAIDB/awesome-data-llm)**|\n", "2505.12731": "|**2025-05-25**|**Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps**|Jie Ou et.al.|[2505.12731_(ACL)](http://arxiv.org/abs/2505.12731)|null|\n", "2505.10951": "|**2025-05-19**|**SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache**|Qiuyu Zhu et.al.|[2505.10951](http://arxiv.org/abs/2505.10951)|null|\n", "2505.08261": "|**2025-05-13**|**Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration**|Rishabh Agrawal et.al.|[2505.08261](http://arxiv.org/abs/2505.08261)|null|\n", "2505.01164": "|**2025-05-02**|**CaGR-RAG: Context-aware Query Grouping for Disk-based Vector Search in RAG Systems**|Yeonwoo Jeong et.al.|[2505.01164](http://arxiv.org/abs/2505.01164)|null|\n", "2504.11765": "|**2025-04-16**|**Shared Disk KV Cache Management for Efficient Multi-Instance Inference in RAG-Powered LLMs**|Hyungwoo Lee et.al.|[2504.11765](http://arxiv.org/abs/2504.11765)|null|\n", "2504.09775": "|**2025-04-20**|**Understanding and Optimizing Multi-Stage AI Inference Pipelines**|Abhimanyu Rajeshkumar Bambhaniya et.al.|[2504.09775](http://arxiv.org/abs/2504.09775)|null|\n", "2504.02921": "|**2025-04-03**|**HyperRAG: Enhancing Quality-Efficiency Tradeoffs in Retrieval-Augmented Generation with Reranker KV-Cache Reuse**|Yuwei An et.al.|[2504.02921](http://arxiv.org/abs/2504.02921)|null|\n", "2504.01281": "|**2025-05-20**|**Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding**|Sakhinana Sagar Srinivas et.al.|[2504.01281](http://arxiv.org/abs/2504.01281)|null|\n", "2504.01157": "|**2025-04-01**|**Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB**|Anas Dorbani et.al.|[2504.01157](http://arxiv.org/abs/2504.01157)|null|\n", "2503.05530": "|**2025-03-07**|**Leveraging Approximate Caching for Faster Retrieval-Augmented Generation**|Shai Bergman et.al.|[2503.05530](http://arxiv.org/abs/2503.05530)|null|\n", "2503.04973": "|**2025-03-06**|**Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning**|Giulio Corallo et.al.|[2503.04973](http://arxiv.org/abs/2503.04973)|null|\n", "2502.20330": "|**2025-06-23**|**RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding**|Guanzheng Chen et.al.|[2502.20330_(ICML)](http://arxiv.org/abs/2502.20330)|null|\n", "2502.11444": "|**2025-02-17**|**Does RAG Really Perform Bad For Long-Context Processing?**|Kun Luo et.al.|[2502.11444](http://arxiv.org/abs/2502.11444)|null|\n", "2502.11083": "|**2025-02-16**|**Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks**|Yuanjie Lyu et.al.|[2502.11083](http://arxiv.org/abs/2502.11083)|null|\n", "2502.05431": "|**2025-02-12**|**APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding**|Xinyu Yang et.al.|[2502.05431_(ICLR)](http://arxiv.org/abs/2502.05431)|null|\n", "2502.15734": "|**2025-02-05**|**Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation**|Shubham Agarwal et.al.|[2502.15734_(SIGMOD)](http://arxiv.org/abs/2502.15734)|null|\n", "2501.09383": "|**2025-01-16**|**Adaptive Contextual Caching for Mobile Edge Large Language Model Service**|Guangyuan Liu et.al.|[2501.09383](http://arxiv.org/abs/2501.09383)|null|\n", "2501.07523": "|**2025-01-23**|**Parallel Key-Value Cache Fusion for Position Invariant RAG**|Philhoon Oh et.al.|[2501.07523](http://arxiv.org/abs/2501.07523)|null|\n", "2412.21023": "|**2024-12-31**|**EdgeRAG: Online-Indexed RAG for Edge Devices**|Korakit Seemakhupt et.al.|[2412.21023](http://arxiv.org/abs/2412.21023)|null|\n", "2412.15605": "|**2025-02-23**|**Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks**|Brian J Chan et.al.|[2412.15605_(WWW)](http://arxiv.org/abs/2412.15605)|null|\n", "2412.14838": "|**2025-05-27**|**DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**|Xiabin Zhou et.al.|[2412.14838](http://arxiv.org/abs/2412.14838)|null|\n", "2412.15246": "|**2024-12-14**|**Accelerating Retrieval-Augmented Generation**|Derrick Quinn et.al.|[2412.15246](http://arxiv.org/abs/2412.15246)|null|\n", "2410.07590": "|**2024-10-10**|**TurboRAG: Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text**|Songshuo Lu et.al.|[2410.07590](http://arxiv.org/abs/2410.07590)|null|\n", "2410.05004": "|**2024-10-07**|**Fast State Restoration in LLM Serving with HCache**|Shiwei Gao et.al.|[2410.05004_(EuroSys)](http://arxiv.org/abs/2410.05004)|null|\n", "2410.03960": "|**2025-06-02**|**SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation**|Aurick Qiao et.al.|[2410.03960](http://arxiv.org/abs/2410.03960)|null|\n", "2409.13122": "|**2024-09-23**|**RepoGenReflex: Enhancing Repository-Level Code Completion with Verbal Reinforcement and Retrieval-Augmented Generation**|Jicheng Wang et.al.|[2409.13122](http://arxiv.org/abs/2409.13122)|null|\n", "2408.14906": "|**2024-08-27**|**Writing in the Margins: Better Inference Pattern for Long Context Retrieval**|Melisa Russak et.al.|[2408.14906](http://arxiv.org/abs/2408.14906)|null|\n", "2408.04870": "|**2024-10-23**|**ConfusedPilot: Confused Deputy Risks in RAG-based LLMs**|Ayush RoyChowdhury et.al.|[2408.04870](http://arxiv.org/abs/2408.04870)|null|\n", "2406.07467": "|**2025-08-08**|**LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs**|Fatemeh Hadadi et.al.|[2406.07467](http://arxiv.org/abs/2406.07467)|null|\n", "2405.16444": "|**2025-04-03**|**CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion**|Jiayi Yao et.al.|[2405.16444](http://arxiv.org/abs/2405.16444)|null|\n", "2405.16178": "|**2024-05-25**|**Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection**|Yun Zhu et.al.|[2405.16178](http://arxiv.org/abs/2405.16178)|null|\n", "2404.12457": "|**2024-04-25**|**RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**|Chao Jin et.al.|[2404.12457](http://arxiv.org/abs/2404.12457)|null|\n", "2404.08940": "|**2024-04-13**|**Introducing Super RAGs in Mistral 8x7B-v1**|Ayush Thakur et.al.|[2404.08940](http://arxiv.org/abs/2404.08940)|null|\n", "2402.14480": "|**2024-02-22**|**MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation**|Guanyu Wang et.al.|[2402.14480](http://arxiv.org/abs/2402.14480)|null|\n", "2506.14035": "|**2025-06-16**|**SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement**|Chelsi Jain et.al.|[2506.14035](http://arxiv.org/abs/2506.14035)|null|\n", "2506.13996": "|**2025-06-16**|**Arctic Long Sequence Training: Scalable And Efficient Training For Multi-Million Token Sequences**|Stas Bekman et.al.|[2506.13996](http://arxiv.org/abs/2506.13996)|null|\n", "2506.04565": "|**2025-06-05**|**From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems**|Jiayi Chen et.al.|[2506.04565](http://arxiv.org/abs/2506.04565)|null|\n", "2506.05370": "|**2025-05-28**|**Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems**|Kristy Wedel et.al.|[2506.05370](http://arxiv.org/abs/2506.05370)|null|\n", "2505.22101": "|**2025-05-28**|**MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models**|Zhiyu Li et.al.|[2505.22101](http://arxiv.org/abs/2505.22101)|null|\n", "2505.21969": "|**2025-06-06**|**DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation**|Tianjun Gu et.al.|[2505.21969](http://arxiv.org/abs/2505.21969)|null|\n", "2505.20625": "|**2025-07-10**|**Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration**|Sibo Xiao et.al.|[2505.20625](http://arxiv.org/abs/2505.20625)|null|\n", "2505.19847": "|**2025-05-26**|**DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems**|Wenqing Zhou et.al.|[2505.19847](http://arxiv.org/abs/2505.19847)|null|\n", "2505.19567": "|**2025-05-26**|**LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer**|Rasoul Zahedifar et.al.|[2505.19567](http://arxiv.org/abs/2505.19567)|null|\n", "2505.19509": "|**2025-05-26**|**Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models**|Yifan Jia et.al.|[2505.19509](http://arxiv.org/abs/2505.19509)|**[link](https://github.com/MLLMKCBENCH/MLLMKC)**|\n", "2505.17152": "|**2025-05-22**|**LSM-VEC: A Large-Scale Disk-Based System for Dynamic Vector Search**|Shurui Zhong et.al.|[2505.17152](http://arxiv.org/abs/2505.17152)|null|\n", "2505.16518": "|**2025-08-08**|**CUB: Benchmarking Context Utilisation Techniques for Language Models**|Lovisa Hagstr\u00f6m et.al.|[2505.16518](http://arxiv.org/abs/2505.16518)|null|\n", "2505.16096": "|**2025-05-22**|**Cosmos: A CXL-Based Full In-Memory System for Approximate Nearest Neighbor Search**|Seoyoung Ko et.al.|[2505.16096_(CHI)](http://arxiv.org/abs/2505.16096)|null|\n", "2505.11856": "|**2025-05-17**|**Telco-oRAG: Optimizing Retrieval-augmented Generation for Telecom Queries via Hybrid Retrieval and Neural Routing**|Andrei-Laurentiu Bornea et.al.|[2505.11856](http://arxiv.org/abs/2505.11856)|null|\n", "2505.10468": "|**2025-05-28**|**AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges**|Ranjan Sapkota et.al.|[2505.10468](http://arxiv.org/abs/2505.10468)|null|\n", "2505.03406": "|**2025-05-06**|**Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation**|Mohammad Shoaib Ansari et.al.|[2505.03406](http://arxiv.org/abs/2505.03406)|null|\n", "2505.01841": "|**2025-05-03**|**Harnessing the Power of LLMs, Informers and Decision Transformers for Intent-driven RAN Management in 6G**|Md Arafat Habib et.al.|[2505.01841](http://arxiv.org/abs/2505.01841)|null|\n", "2505.00105": "|**2025-04-30**|**Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques**|Naam\u00e1n Huerga-P\u00e9rez et.al.|[2505.00105](http://arxiv.org/abs/2505.00105)|null|\n", "2504.21716": "|**2025-04-30**|**LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics**|Marc Glocker et.al.|[2504.21716_(ICS)](http://arxiv.org/abs/2504.21716)|null|\n", "2504.19413": "|**2025-04-28**|**Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory**|Prateek Chhikara et.al.|[2504.19413](http://arxiv.org/abs/2504.19413)|null|\n", "2504.18070": "|**2025-04-25**|**PropRAG: Guiding Retrieval with Beam Search over Proposition Paths**|Jingjin Wang et.al.|[2504.18070](http://arxiv.org/abs/2504.18070)|**[link](https://github.com/ReLink-Inc/PropRAG)**|\n", "2504.15302": "|**2025-04-17**|**RAGDoll: Efficient Offloading-based Online RAG System on a Single GPU**|Weiping Yu et.al.|[2504.15302](http://arxiv.org/abs/2504.15302)|null|\n", "2504.12982": "|**2025-04-17**|**Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild**|Jiatai Wang et.al.|[2504.12982](http://arxiv.org/abs/2504.12982)|null|\n", "2504.09283": "|**2025-04-12**|**Semantic Commit: Helping Users Update Intent Specifications for AI Memory at Scale**|Priyan Vaithilingam et.al.|[2504.09283](http://arxiv.org/abs/2504.09283)|null|\n", "2504.08930": "|**2025-04-11**|**An Adaptive Vector Index Partitioning Scheme for Low-Latency RAG Pipeline**|Junkyum Kim et.al.|[2504.08930](http://arxiv.org/abs/2504.08930)|null|\n", "2504.08386": "|**2025-04-11**|**PCA-RAG: Principal Component Analysis for Efficient Retrieval-Augmented Generation**|Arman Khaledian et.al.|[2504.08386](http://arxiv.org/abs/2504.08386)|null|\n", "2504.06135": "|**2025-04-08**|**Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning**|Tooraj Helmi et.al.|[2504.06135](http://arxiv.org/abs/2504.06135)|null|\n", "2504.05573": "|**2025-04-08**|**MicroNN: An On-device Disk-resident Updatable Vector Database**|Jeffrey Pound et.al.|[2504.05573](http://arxiv.org/abs/2504.05573)|null|\n", "2504.00587": "|**2025-05-29**|**AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems**|Yingxuan Yang et.al.|[2504.00587](http://arxiv.org/abs/2504.00587)|null|\n", "2503.23095": "|**2025-03-29**|**Memory-Aware and Uncertainty-Guided Retrieval for Multi-Hop Question Answering**|Yuelyu Ji et.al.|[2503.23095](http://arxiv.org/abs/2503.23095)|null|\n", "2503.21760": "|**2025-07-31**|**MemInsight: Autonomous Memory Augmentation for LLM Agents**|Rana Salama et.al.|[2503.21760](http://arxiv.org/abs/2503.21760)|null|\n", "2503.21315": "|**2025-03-27**|**Tricking Retrievers with Influential Tokens: An Efficient Black-Box Corpus Poisoning Attack**|Cheng Wang et.al.|[2503.21315_(ACL)](http://arxiv.org/abs/2503.21315)|null|\n", "2503.17553": "|**2025-03-21**|**Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent**|Humza Nusrat et.al.|[2503.17553](http://arxiv.org/abs/2503.17553)|null|\n", "2504.06279": "|**2025-03-20**|**Financial Analysis: Intelligent Financial Data Analysis System Based on LLM-RAG**|Jingru Wang et.al.|[2504.06279](http://arxiv.org/abs/2504.06279)|null|\n", "2503.16071": "|**2025-03-20**|**Tuning LLMs by RAG Principles: Towards LLM-native Memory**|Jiale Wei et.al.|[2503.16071](http://arxiv.org/abs/2503.16071)|null|\n", "2503.15888": "|**2025-03-20**|**Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models**|Baolong Bi et.al.|[2503.15888](http://arxiv.org/abs/2503.15888)|null|\n", "2503.09149": "|**2025-06-20**|**Memory-enhanced Retrieval Augmentation for Long Video Understanding**|Huaying Yuan et.al.|[2503.09149](http://arxiv.org/abs/2503.09149)|null|\n", "2503.05150": "|**2025-03-07**|**Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History**|Bowen Wu et.al.|[2503.05150](http://arxiv.org/abs/2503.05150)|null|\n", "2502.20969": "|**2025-02-28**|**TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval**|Chien-Yu Lin et.al.|[2502.20969](http://arxiv.org/abs/2502.20969)|null|\n", "2502.18418": "|**2025-08-08**|**Rank1: Test-Time Compute for Reranking in Information Retrieval**|Orion Weller et.al.|[2502.18418](http://arxiv.org/abs/2502.18418)|null|\n", "2502.15543": "|**2025-06-21**|**ParamMute: Suppressing Knowledge-Critical FFNs for Faithful Retrieval-Augmented Generation**|Pengcheng Huang et.al.|[2502.15543](http://arxiv.org/abs/2502.15543)|null|\n", "2502.14802": "|**2025-06-19**|**From RAG to Memory: Non-Parametric Continual Learning for Large Language Models**|Bernal Jim\u00e9nez Guti\u00e9rrez et.al.|[2502.14802_(GROUP)](http://arxiv.org/abs/2502.14802)|**[link](https://github.com/OSU-NLP-Group/HippoRAG)**|\n", "2502.13847": "|**2025-02-19**|**DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue**|Feiyuan Zhang et.al.|[2502.13847](http://arxiv.org/abs/2502.13847)|null|\n", "2504.05312": "|**2025-06-27**|**Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation**|Qitao Qin et.al.|[2504.05312](http://arxiv.org/abs/2504.05312)|null|\n", "2502.12794": "|**2025-02-18**|**RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models**|Tanqiu Jiang et.al.|[2502.12794_(ICLR)](http://arxiv.org/abs/2502.12794)|null|\n", "2502.07972": "|**2025-03-09**|**Training Sparse Mixture Of Experts Text Embedding Models**|Zach Nussbaum et.al.|[2502.07972](http://arxiv.org/abs/2502.07972)|null|\n", "2502.06921": "|**2025-02-13**|**GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units**|Arghadip Das et.al.|[2502.06921](http://arxiv.org/abs/2502.06921)|null|\n", "2502.05233": "|**2025-02-07**|**Efficient Knowledge Feeding to Language Models: A Novel Integrated Encoder-Decoder Architecture**|S Santosh Kumar et.al.|[2502.05233](http://arxiv.org/abs/2502.05233)|null|\n", "2502.04644": "|**2025-07-14**|**Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools**|Junde Wu et.al.|[2502.04644](http://arxiv.org/abs/2502.04644)|**[link](https://github.com/theworldofagents/agentic-reasoning)**|\n", "2502.00848": "|**2025-05-12**|**RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning**|Yuanhuiyi Lyu et.al.|[2502.00848_(ICML)](http://arxiv.org/abs/2502.00848)|null|\n", "2501.13956": "|**2025-01-20**|**Zep: A Temporal Knowledge Graph Architecture for Agent Memory**|Preston Rasmussen et.al.|[2501.13956](http://arxiv.org/abs/2501.13956)|null|\n", "2501.10534": "|**2025-01-17**|**4bit-Quantization in Vector-Embedding for RAG**|Taehee Jeong et.al.|[2501.10534](http://arxiv.org/abs/2501.10534)|null|\n", "2501.08262": "|**2025-01-14**|**Addressing the sustainable AI trilemma: a case study on LLM agents and RAG**|Hui Wu et.al.|[2501.08262](http://arxiv.org/abs/2501.08262)|null|\n", "2501.07063": "|**2025-01-13**|**Research on the Online Update Method for Retrieval-Augmented Generation (RAG) Model with Incremental Learning**|Yuxin Fan et.al.|[2501.07063](http://arxiv.org/abs/2501.07063)|null|\n", "2412.19498": "|**2024-12-27**|**Casevo: A Cognitive Agents and Social Evolution Simulator**|Zexun Jiang et.al.|[2412.19498](http://arxiv.org/abs/2412.19498)|null|\n", "2412.18069": "|**2025-06-02**|**Improving Factuality with Explicit Working Memory**|Mingda Chen et.al.|[2412.18069_(ACL)](http://arxiv.org/abs/2412.18069)|null|\n", "2412.11854": "|**2024-12-16**|**Towards Understanding Systems Trade-offs in Retrieval-Augmented Generation Model Inference**|Michael Shen et.al.|[2412.11854](http://arxiv.org/abs/2412.11854)|null|\n", "2412.11536": "|**2024-12-16**|**Let your LLM generate a few tokens and you will reduce the need for retrieval**|Herv\u00e9 D\u00e9jean et.al.|[2412.11536](http://arxiv.org/abs/2412.11536)|null|\n", "2412.05447": "|**2025-04-01**|**TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG**|Savini Kashmira et.al.|[2412.05447](http://arxiv.org/abs/2412.05447)|null|\n", "2412.05187": "|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187](http://arxiv.org/abs/2412.05187)|null|\n", "2412.02987": "|**2024-12-04**|**Advancing Conversational Psychotherapy: Integrating Privacy, Dual-Memory, and Domain Expertise with Large Language Models**|XiuYu Zhang et.al.|[2412.02987_(NeurIPS)](http://arxiv.org/abs/2412.02987)|null|\n", "2411.11913": "|**2024-11-17**|**On-Board Vision-Language Models for Personalized Autonomous Vehicle Motion Control: System Design and Real-World Validation**|Can Cui et.al.|[2411.11913](http://arxiv.org/abs/2411.11913)|null|\n", "2411.07396": "|**2024-11-11**|**Toward Optimal Search and Retrieval for RAG**|Alexandria Leto et.al.|[2411.07396_(NeurIPS)](http://arxiv.org/abs/2411.07396)|null|\n", "2411.07238": "|**2025-02-25**|**OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model**|Sumeth Yuenyong et.al.|[2411.07238](http://arxiv.org/abs/2411.07238)|null|\n", "2411.06805": "|**2024-11-11**|**AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant**|Yujia Zhou et.al.|[2411.06805_(NeurIPS)](http://arxiv.org/abs/2411.06805)|null|\n", "2411.01751": "|**2024-11-04**|**RAGViz: Diagnose and Visualize Retrieval-Augmented Generation**|Tevin Wang et.al.|[2411.01751](http://arxiv.org/abs/2411.01751)|null|\n", "2410.23041": "|**2024-10-30**|**Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval**|Le Huang et.al.|[2410.23041](http://arxiv.org/abs/2410.23041)|null|\n", "2410.20753": "|**2025-02-04**|**Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753](http://arxiv.org/abs/2410.20753)|null|\n", "2410.18926": "|**2024-10-24**|**LoRANN: Low-Rank Matrix Factorization for Approximate Nearest Neighbor Search**|Elias J\u00e4\u00e4saari et.al.|[2410.18926_(NeurIPS)](http://arxiv.org/abs/2410.18926)|null|\n", "2410.15737": "|**2024-10-21**|**Who's Who: Large Language Models Meet Knowledge Conflicts in Practice**|Quang Hieu Pham et.al.|[2410.15737_(EMNLP)](http://arxiv.org/abs/2410.15737)|null|\n", "2410.15621": "|**2024-10-21**|**DRIM-ANN: An Approximate Nearest Neighbor Search Engine based on Commercial DRAM-PIMs**|Mingkai Chen et.al.|[2410.15621](http://arxiv.org/abs/2410.15621)|null|\n", "2410.14931": "|**2024-10-19**|**\"Ghost of the past\": identifying and resolving privacy leakage from LLM's memory through proactive user interaction**|Shuning Zhang et.al.|[2410.14931](http://arxiv.org/abs/2410.14931)|null|\n", "2410.13510": "|**2024-10-17**|**GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models**|Aditya Sharma et.al.|[2410.13510](http://arxiv.org/abs/2410.13510)|null|\n", "2410.13509": "|**2025-03-04**|**RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards**|Xinze Li et.al.|[2410.13509](http://arxiv.org/abs/2410.13509)|null|\n", "2410.12859": "|**2024-10-11**|**Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism**|Yimin Tang et.al.|[2410.12859](http://arxiv.org/abs/2410.12859)|null|\n", "2410.05162": "|**2024-10-07**|**Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models**|Mehrdad Farahani et.al.|[2410.05162_(EMNLP)](http://arxiv.org/abs/2410.05162)|null|\n", "2410.00857": "|**2024-10-01**|**Quantifying reliance on external information over parametric knowledge during Retrieval Augmented Generation (RAG) using mechanistic analysis**|Reshmi Ghosh et.al.|[2410.00857_(EMNLP)](http://arxiv.org/abs/2410.00857)|null|\n", "2409.19745": "|**2024-10-07**|**PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead**|Tao Tan et.al.|[2409.19745](http://arxiv.org/abs/2409.19745)|null|\n", "2409.19401": "|**2024-09-28**|**Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**|Zheng Wang et.al.|[2409.19401_(EMNLP)](http://arxiv.org/abs/2409.19401)|null|\n", "2409.18313": "|**2025-01-21**|**Embodied-RAG: General Non-parametric Embodied Memory for Retrieval and Generation**|Quanting Xie et.al.|[2409.18313](http://arxiv.org/abs/2409.18313)|**[link](https://quanting-xie.github.io/Embodied-RAG-web/)**|\n", "2409.15566": "|**2024-09-23**|**GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**|Brendan Hogan Rappazzo et.al.|[2409.15566](http://arxiv.org/abs/2409.15566)|null|\n", "2409.12524": "|**2024-09-19**|**Should RAG Chatbots Forget Unimportant Conversations? Exploring Importance and Forgetting with Psychological Insights**|Ryuichi Sumida et.al.|[2409.12524](http://arxiv.org/abs/2409.12524)|null|\n", "2409.12294": "|**2024-09-18**|**RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models**|Abhinav Jain et.al.|[2409.12294](http://arxiv.org/abs/2409.12294)|null|\n", "2409.10955": "|**2025-07-10**|**Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style**|Yuepei Li et.al.|[2409.10955_(ACL)](http://arxiv.org/abs/2409.10955)|null|\n", "2410.00004": "|**2025-03-26**|**Retro-li: Small-Scale Retrieval Augmented Generation Supporting Noisy Similarity Searches and Domain Shift Generalization**|Gentiana Rashiti et.al.|[2410.00004](http://arxiv.org/abs/2410.00004)|null|\n", "2409.08250": "|**2025-02-21**|**OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering**|Jiahao Nick Li et.al.|[2409.08250_(CHI)](http://arxiv.org/abs/2409.08250)|null|\n", "2409.07110": "|**2025-04-19**|**Bio-Eng-LMM AI Assist chatbot: A Comprehensive Tool for Research and Education**|Ali Forootani et.al.|[2409.07110](http://arxiv.org/abs/2409.07110)|null|\n", "2409.05591": "|**2025-04-09**|**MemoRAG: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation**|Hongjin Qian et.al.|[2409.05591_(TheWebConf)](http://arxiv.org/abs/2409.05591)|**[link](https://github.com/qhjqhj00/MemoRAG)**|\n", "2409.03258": "|**2024-12-16**|**GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**|Yukun Cao et.al.|[2409.03258](http://arxiv.org/abs/2409.03258)|null|\n", "2505.24803": "|**2025-06-02**|**Guiding Generative Storytelling with Knowledge Graphs**|Zhijun Pan et.al.|[2505.24803_(SC)](http://arxiv.org/abs/2505.24803)|null|\n", "2505.23495": "|**2025-05-29**|**Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking**|Liangliang Zhang et.al.|[2505.23495](http://arxiv.org/abs/2505.23495)|null|\n", "2505.23841": "|**2025-05-28**|**SkewRoute: Training-Free LLM Routing for Knowledge Graph Retrieval-Augmented Generation via Score Skewness of Retrieved Context**|Hairu Wang et.al.|[2505.23841](http://arxiv.org/abs/2505.23841)|null|\n", "2505.21291": "|**2025-05-27**|**Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework**|Saman Marandi et.al.|[2505.21291](http://arxiv.org/abs/2505.21291)|null|\n", "2505.17464": "|**2025-05-23**|**Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning**|Xingyu Tan et.al.|[2505.17464](http://arxiv.org/abs/2505.17464)|null|\n", "2505.16849": "|**2025-05-28**|**Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks**|Martin B\u00f6ckling et.al.|[2505.16849_(IR-RAG)](http://arxiv.org/abs/2505.16849)|null|\n", "2505.14101": "|**2025-05-20**|**MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations**|Ernests Lavrinovics et.al.|[2505.14101](http://arxiv.org/abs/2505.14101)|null|\n", "2505.14099": "|**2025-05-20**|**Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering**|Yihua Zhu et.al.|[2505.14099](http://arxiv.org/abs/2505.14099)|null|\n", "2505.12662": "|**2025-05-19**|**Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering**|Xukai Liu et.al.|[2505.12662](http://arxiv.org/abs/2505.12662)|null|\n", "2505.09945": "|**2025-05-15**|**Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph**|Deeksha Prahlad et.al.|[2505.09945_(WWW)](http://arxiv.org/abs/2505.09945)|null|\n", "2505.07618": "|**2025-05-12**|**KAQG: A Knowledge-Graph-Enhanced RAG for Difficulty-Controlled Question Generation**|Ching Han Chen et.al.|[2505.07618](http://arxiv.org/abs/2505.07618)|null|\n", "2505.05583": "|**2025-05-08**|**KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification**|Qianbo Zang et.al.|[2505.05583](http://arxiv.org/abs/2505.05583)|null|\n", "2504.10982": "|**2025-04-26**|**Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs**|Yingjian Chen et.al.|[2504.10982](http://arxiv.org/abs/2504.10982)|null|\n", "2504.08893": "|**2025-04-11**|**Knowledge Graph-extended Retrieval Augmented Generation for Question Answering**|Jasper Linders et.al.|[2504.08893](http://arxiv.org/abs/2504.08893)|null|\n", "2504.07624": "|**2025-04-10**|**ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in Large Language Models**|Joel Barmettler et.al.|[2504.07624](http://arxiv.org/abs/2504.07624)|null|\n", "2504.05478": "|**2025-04-07**|**GraphRAFT: Retrieval Augmented Fine-Tuning for Knowledge Graphs on Graph Databases**|Alfred Clemedtson et.al.|[2504.05478](http://arxiv.org/abs/2504.05478)|null|\n", "2504.05163": "|**2025-04-07**|**Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness**|Dongzhuoran Zhou et.al.|[2504.05163](http://arxiv.org/abs/2504.05163)|null|\n", "2503.24245": "|**2025-05-21**|**Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation**|Dun Yuan et.al.|[2503.24245_(ICC)](http://arxiv.org/abs/2503.24245)|null|\n", "2503.14234": "|**2025-05-19**|**Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval**|Ruiyi Yang et.al.|[2503.14234](http://arxiv.org/abs/2503.14234)|null|\n", "2503.11346": "|**2025-03-14**|**AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation**|Fengyu Li et.al.|[2503.11346](http://arxiv.org/abs/2503.11346)|null|\n", "2503.13514": "|**2025-03-14**|**RAG-KG-IL: A Multi-Agent Hybrid Framework for Reducing Hallucinations and Enhancing LLM Reasoning through RAG and Incremental Knowledge Graph Learning Integration**|Hong Qing Yu et.al.|[2503.13514](http://arxiv.org/abs/2503.13514)|null|\n", "2503.07584": "|**2025-06-24**|**Talking to GDELT Through Knowledge Graphs**|Audun Myers et.al.|[2503.07584](http://arxiv.org/abs/2503.07584)|null|\n", "2503.05203": "|**2025-05-27**|**Path Pooling: Training-Free Structure Enhancement for Efficient Knowledge Graph Retrieval-Augmented Generation**|Hairu Wang et.al.|[2503.05203](http://arxiv.org/abs/2503.05203)|null|\n", "2502.20854": "|**2025-05-17**|**A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation**|Xujie Yuan et.al.|[2502.20854](http://arxiv.org/abs/2502.20854)|null|\n", "2502.20364": "|**2025-05-09**|**Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization**|Ryan C. Barron et.al.|[2502.20364](http://arxiv.org/abs/2502.20364)|null|\n", "2502.18763": "|**2025-02-26**|**CommGPT: A Graph and Retrieval-Augmented Multimodal Communication Foundation Model**|Feibo Jiang et.al.|[2502.18763](http://arxiv.org/abs/2502.18763)|null|\n", "2502.15237": "|**2025-02-21**|**From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants**|Manisha Mukherjee et.al.|[2502.15237](http://arxiv.org/abs/2502.15237)|null|\n", "2502.09771": "|**2025-02-13**|**Knowledge-Enhanced Program Repair for Data Science Code**|Shuyin Ouyang et.al.|[2502.09771](http://arxiv.org/abs/2502.09771)|null|\n", "2502.06864": "|**2025-02-08**|**Knowledge Graph-Guided Retrieval Augmented Generation**|Xiangrong Zhu et.al.|[2502.06864_(ACL)](http://arxiv.org/abs/2502.06864)|null|\n", "2502.04413": "|**2025-06-27**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413](http://arxiv.org/abs/2502.04413)|null|\n", "2502.01298": "|**2025-02-03**|**Augmented Knowledge Graph Querying leveraging LLMs**|Marco Arazzi et.al.|[2502.01298](http://arxiv.org/abs/2502.01298)|null|\n", "2501.16382": "|**2025-01-24**|**GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**|Ziwen Li et.al.|[2501.16382_(ACL)](http://arxiv.org/abs/2501.16382)|null|\n", "2501.14300": "|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300](http://arxiv.org/abs/2501.14300)|null|\n", "2501.11560": "|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560](http://arxiv.org/abs/2501.11560)|null|\n", "2501.09957": "|**2025-01-22**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957](http://arxiv.org/abs/2501.09957)|null|\n", "2501.02226": "|**2025-05-28**|**Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation**|Shijie Wang et.al.|[2501.02226_(ACL)](http://arxiv.org/abs/2501.02226)|null|\n", "2501.00223": "|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223](http://arxiv.org/abs/2501.00223)|null|\n", "2412.20468": "|**2025-03-05**|**A Comprehensive Framework for Reliable Legal AI: Combining Specialized Expert Systems and Adaptive Refinement**|Sidra Nasir et.al.|[2412.20468](http://arxiv.org/abs/2412.20468)|null|\n", "2412.17690": "|**2024-12-25**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690](http://arxiv.org/abs/2412.17690)|null|\n", "2412.15272": "|**2025-05-29**|**SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**|Yuzheng Cai et.al.|[2412.15272_(ACL)](http://arxiv.org/abs/2412.15272)|null|\n", "2412.07412": "|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412](http://arxiv.org/abs/2412.07412)|null|\n", "2412.05547": "|**2025-05-05**|**KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**|Weijie Chen et.al.|[2412.05547](http://arxiv.org/abs/2412.05547)|null|\n", "2412.02788": "|**2024-12-05**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788](http://arxiv.org/abs/2412.02788)|null|\n", "2412.00608": "|**2024-12-10**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608](http://arxiv.org/abs/2412.00608)|null|\n", "2411.19539": "|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539](http://arxiv.org/abs/2411.19539)|null|\n", "2411.13773": "|**2025-06-14**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773](http://arxiv.org/abs/2411.13773)|null|\n", "2411.15203": "|**2024-11-20**|**Multimodal large language model for wheat breeding: a new exploration of smart breeding**|Guofeng Yang et.al.|[2411.15203](http://arxiv.org/abs/2411.15203)|null|\n", "2411.08449": "|**2024-11-18**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449_(SC)](http://arxiv.org/abs/2411.08449)|null|\n", "2411.13560": "|**2024-11-07**|**AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**|Yichen Shi et.al.|[2411.13560](http://arxiv.org/abs/2411.13560)|null|\n", "2410.22996": "|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996](http://arxiv.org/abs/2410.22996)|null|\n", "2411.08041": "|**2024-10-29**|**GraphAide: Advanced Graph-Assisted Query and Reasoning System**|Sumit Purohit et.al.|[2411.08041](http://arxiv.org/abs/2411.08041)|null|\n", "2410.21067": "|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067](http://arxiv.org/abs/2410.21067)|null|\n", "2410.20724": "|**2025-02-05**|**Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724_(ICLR)](http://arxiv.org/abs/2410.20724)|**[link](https://github.com/Graph-COM/SubgraphRAG)**|\n", "2410.17600": "|**2025-02-03**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600](http://arxiv.org/abs/2410.17600)|null|\n", "2410.16597": "|**2024-10-22**|**Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**|Prafulla Kumar Choubey et.al.|[2410.16597](http://arxiv.org/abs/2410.16597)|null|\n", "2410.16397": "|**2024-10-21**|**Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**|Oliver Bensch et.al.|[2410.16397](http://arxiv.org/abs/2410.16397)|null|\n", "2410.22353": "|**2025-02-16**|**RuleRAG: Rule-Guided Retrieval-Augmented Generation with Language Models for Question Answering**|Zhongwu Chen et.al.|[2410.22353](http://arxiv.org/abs/2410.22353)|null|\n", "2410.06121": "|**2024-10-08**|**Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**|Wenyu Huang et.al.|[2410.06121_(EMNLP)](http://arxiv.org/abs/2410.06121)|null|\n", "2410.06062": "|**2025-02-10**|**LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**|Vincent Emonet et.al.|[2410.06062](http://arxiv.org/abs/2410.06062)|null|\n", "2410.04749": "|**2024-12-19**|**LLaVA Needs More Knowledge: Retrieval Augmented Natural Language Generation with Knowledge Graph for Explaining Thoracic Pathologies**|Ameer Hamza et.al.|[2410.04749_(AAAI)](http://arxiv.org/abs/2410.04749)|null|\n", "2410.04585": "|**2025-04-20**|**Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**|Pengcheng Jiang et.al.|[2410.04585_(ICLR)](http://arxiv.org/abs/2410.04585)|null|\n", "2410.02721": "|**2024-10-03**|**Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**|Ryan C. Barron et.al.|[2410.02721_(ICML)](http://arxiv.org/abs/2410.02721)|null|\n", "2409.18924": "|**2025-07-29**|**Simulated patient systems are intelligent when powered by large language model-based AI agents**|Huizi Yu et.al.|[2409.18924](http://arxiv.org/abs/2409.18924)|null|\n", "2409.14206": "|**2024-09-21**|**AI Assistants for Spaceflight Procedures: Combining Generative Pre-Trained Transformer and Retrieval-Augmented Generation on Knowledge Graphs With Augmented Reality Cues**|Oliver Bensch et.al.|[2409.14206_(ESA)](http://arxiv.org/abs/2409.14206)|null|\n", "2409.12853": "|**2024-10-19**|**A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**|Hakan T. Otal et.al.|[2409.12853](http://arxiv.org/abs/2409.12853)|null|\n", "2409.07507": "|**2025-06-11**|**Traceable LLM-based validation of statements in knowledge graphs**|Daniel Adam et.al.|[2409.07507](http://arxiv.org/abs/2409.07507)|null|\n", "2409.13731": "|**2024-09-26**|**KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation**|Lei Liang et.al.|[2409.13731](http://arxiv.org/abs/2409.13731)|null|\n", "2409.13709": "|**2024-09-06**|**Column Vocabulary Association (CVA): semantic interpretation of dataless tables**|Margherita Martorana et.al.|[2409.13709](http://arxiv.org/abs/2409.13709)|null|\n", "2408.08535": "|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535](http://arxiv.org/abs/2408.08535)|null|\n", "2408.04948": "|**2024-08-09**|**HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**|Bhaskarjit Sarmah et.al.|[2408.04948](http://arxiv.org/abs/2408.04948)|null|\n", "2407.21276": "|**2025-02-21**|**Knowledge Pyramid Construction for Multi-Level Retrieval-Augmented Generation**|Rubing Chen et.al.|[2407.21276](http://arxiv.org/abs/2407.21276)|null|\n", "2407.13909": "|**2024-07-18**|**PRAGyan -- Connecting the Dots in Tweets**|Rahul Ravi et.al.|[2407.13909](http://arxiv.org/abs/2407.13909)|null|\n", "2407.12216": "|**2024-10-06**|**Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation**|Garima Agrawal et.al.|[2407.12216](http://arxiv.org/abs/2407.12216)|null|\n", "2407.10805": "|**2025-02-10**|**Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning with Knowledge-guided Retrieval Augmented Generation**|Shengjie Ma et.al.|[2407.10805](http://arxiv.org/abs/2407.10805)|null|\n", "2406.18114": "|**2025-03-28**|**Knowledge graph enhanced retrieval-augmented generation for failure mode and effects analysis**|Lukas Bahr et.al.|[2406.18114](http://arxiv.org/abs/2406.18114)|null|\n", "2406.14745": "|**2024-06-24**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745](http://arxiv.org/abs/2406.14745)|null|\n", "2406.11460": "|**2024-06-17**|**TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**|Jinyuan Fang et.al.|[2406.11460](http://arxiv.org/abs/2406.11460)|null|\n", "2406.04744": "|**2024-11-01**|**CRAG -- Comprehensive RAG Benchmark**|Xiao Yang et.al.|[2406.04744_(NeurIPS)](http://arxiv.org/abs/2406.04744)|null|\n", "2405.20455": "|**2024-10-22**|**DepsRAG: Towards Agentic Reasoning and Planning for Software Dependency Management**|Mohannad Alhanahnah et.al.|[2405.20455](http://arxiv.org/abs/2405.20455)|null|\n", "2405.20139": "|**2024-05-30**|**GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**|Costas Mavromatis et.al.|[2405.20139](http://arxiv.org/abs/2405.20139)|null|\n", "2406.00036": "|**2025-02-26**|**EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation**|Yinghao Zhu et.al.|[2406.00036_(CIKM)](http://arxiv.org/abs/2406.00036)|null|\n", "2405.13873": "|**2025-05-22**|**FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering**|Yuan Sui et.al.|[2405.13873_(ACL)](http://arxiv.org/abs/2405.13873)|null|\n", "2405.12035": "|**2024-05-20**|**KG-RAG: Bridging the Gap Between Knowledge and Creativity**|Diego Sanmartin et.al.|[2405.12035](http://arxiv.org/abs/2405.12035)|null|\n", "2405.02048": "|**2024-05-03**|**Comparative Analysis of Retrieval Systems in the Real World**|Dmytro Mozolevskyi et.al.|[2405.02048](http://arxiv.org/abs/2405.02048)|null|\n", "2405.00449": "|**2024-05-01**|**RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models**|Mohamed Manzour Hussien et.al.|[2405.00449](http://arxiv.org/abs/2405.00449)|null|\n", "2404.17723": "|**2024-05-06**|**Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering**|Zhentao Xu et.al.|[2404.17723](http://arxiv.org/abs/2404.17723)|null|\n", "2404.09296": "|**2024-09-07**|**Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT**|Tuan Bui et.al.|[2404.09296](http://arxiv.org/abs/2404.09296)|null|\n", "2403.08345": "|**2024-03-13**|**From human experts to machines: An LLM supported approach to ontology and knowledge graph construction**|Vamsi Krishna Kommineni et.al.|[2403.08345](http://arxiv.org/abs/2403.08345)|null|\n", "2402.07016": "|**2024-02-10**|**REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models**|Yinghao Zhu et.al.|[2402.07016](http://arxiv.org/abs/2402.07016)|null|\n", "2312.15883": "|**2024-04-19**|**HyKGE: A Hypothesis Knowledge Graph Enhanced Framework for Accurate and Reliable Medical LLMs Responses**|Xinke Jiang et.al.|[2312.15883](http://arxiv.org/abs/2312.15883)|null|\n", "2311.17696": "|**2025-02-12**|**How to Build an Adaptive AI Tutor for Any Course Using Knowledge Graph-Enhanced Retrieval-Augmented Generation (KG-RAG)**|Chenxi Dong et.al.|[2311.17696](http://arxiv.org/abs/2311.17696)|null|\n", "2311.17330": "|**2024-05-13**|**Biomedical knowledge graph-optimized prompt generation for large language models**|Karthik Soman et.al.|[2311.17330](http://arxiv.org/abs/2311.17330)|null|\n", "2104.08610": "|**2021-04-17**|**Zero-shot Slot Filling with DPR and RAG**|Michael Glass et.al.|[2104.08610](http://arxiv.org/abs/2104.08610)|null|\n", "2506.14529": "|**2025-06-17**|**Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution**|Xiaohan Zheng et.al.|[2506.14529](http://arxiv.org/abs/2506.14529)|null|\n", "2506.13782": "|**2025-06-10**|**XGraphRAG: Interactive Visual Analysis for Graph-based Retrieval-Augmented Generation**|Ke Wang et.al.|[2506.13782](http://arxiv.org/abs/2506.13782)|null|\n", "2506.08364": "|**2025-08-11**|**Structure-Augmented Reasoning Generation**|Jash Rajesh Parekh et.al.|[2506.08364](http://arxiv.org/abs/2506.08364)|null|\n", "2506.08276": "|**2025-06-09**|**LEANN: A Low-Storage Vector Index**|Yichuan Wang et.al.|[2506.08276](http://arxiv.org/abs/2506.08276)|null|\n", "2506.08074": "|**2025-06-09**|**Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval**|Abdellah Ghassel et.al.|[2506.08074_(KDD)](http://arxiv.org/abs/2506.08074)|null|\n", "2506.07600": "|**2025-06-09**|**SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding**|Nianbo Zeng et.al.|[2506.07600](http://arxiv.org/abs/2506.07600)|null|\n", "2506.07449": "|**2025-06-09**|**LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking**|Vahid Azizi et.al.|[2506.07449](http://arxiv.org/abs/2506.07449)|null|\n", "2506.07042": "|**2025-06-15**|**Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants**|Stergios Chatzikyriakidis et.al.|[2506.07042](http://arxiv.org/abs/2506.07042)|null|\n", "2506.07037": "|**2025-06-08**|**KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering**|Zhongze Luo et.al.|[2506.07037](http://arxiv.org/abs/2506.07037)|null|\n", "2506.11106": "|**2025-06-07**|**Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking**|Ningyuan Li et.al.|[2506.11106](http://arxiv.org/abs/2506.11106)|null|\n", "2506.06208": "|**2025-06-06**|**Building Models of Neurological Language**|Henry Watkins et.al.|[2506.06208](http://arxiv.org/abs/2506.06208)|null|\n", "2506.05725": "|**2025-06-06**|**Large Language Models are Good Relational Learners**|Fang Wu et.al.|[2506.05725](http://arxiv.org/abs/2506.05725)|null|\n", "2506.05690": "|**2025-06-06**|**When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation**|Zhishang Xiang et.al.|[2506.05690](http://arxiv.org/abs/2506.05690)|null|\n", "2506.05386": "|**2025-08-09**|**Leaps Beyond the Seen: Reinforced Reasoning Augmented Generation for Clinical Notes**|Lo Pang-Yun Ting et.al.|[2506.05386](http://arxiv.org/abs/2506.05386)|null|\n", "2506.02661": "|**2025-06-03**|**MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation**|Mingyang Huang et.al.|[2506.02661](http://arxiv.org/abs/2506.02661)|null|\n", "2506.01954": "|**2025-06-02**|**DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation**|Jennifer Chen et.al.|[2506.01954_(ACL)](http://arxiv.org/abs/2506.01954)|**[link](https://github.com/VILA-Lab/DRAG)**|\n", "2506.01232": "|**2025-06-02**|**Retrieval-Augmented Generation of Ontologies from Relational Databases**|Mojtaba Nayyeri et.al.|[2506.01232](http://arxiv.org/abs/2506.01232)|null|\n", "2506.04252": "|**2025-06-01**|**A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy**|Yang Zhao et.al.|[2506.04252](http://arxiv.org/abs/2506.04252)|null|\n", "2506.00789": "|**2025-06-01**|**RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems**|Yixiao Zeng et.al.|[2506.00789](http://arxiv.org/abs/2506.00789)|null|\n", "2506.00664": "|**2025-05-31**|**OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases**|Yash Tiwari et.al.|[2506.00664](http://arxiv.org/abs/2506.00664)|null|\n", "2505.24226": "|**2025-06-06**|**E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness**|Yibo Zhao et.al.|[2505.24226](http://arxiv.org/abs/2505.24226)|null|\n", "2505.23944": "|**2025-05-29**|**Retrieval Augmented Generation based Large Language Models for Causality Mining**|Thushara Manjari Naduvilakandy et.al.|[2505.23944_(ACL)](http://arxiv.org/abs/2505.23944)|null|\n", "2506.00049": "|**2025-05-28**|**Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models**|Arjun Rao et.al.|[2506.00049](http://arxiv.org/abs/2506.00049)|null|\n", "2505.20245": "|**2025-05-26**|**KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing**|Rui Li et.al.|[2505.20245_(KDD)](http://arxiv.org/abs/2505.20245)|null|\n", "2505.18450": "|**2025-05-24**|**BRIT: Bidirectional Retrieval over Unified Image-Text Graph**|Ainulla Khan et.al.|[2505.18450](http://arxiv.org/abs/2505.18450)|null|\n", "2505.16901": "|**2025-06-23**|**Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks**|Hongyuan Tao et.al.|[2505.16901](http://arxiv.org/abs/2505.16901)|null|\n", "2505.16237": "|**2025-05-22**|**Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation**|Derong Xu et.al.|[2505.16237](http://arxiv.org/abs/2505.16237)|null|\n", "2505.15701": "|**2025-05-21**|**HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases**|Pingqing Zheng et.al.|[2505.15701](http://arxiv.org/abs/2505.15701)|null|\n", "2505.15444": "|**2025-05-21**|**Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization**|Yutao Zhu et.al.|[2505.15444](http://arxiv.org/abs/2505.15444)|null|\n", "2505.14528": "|**2025-05-29**|**BugRepro: Enhancing Android Bug Reproduction with Domain-Specific Knowledge Integration**|Hongrong Yin et.al.|[2505.14528](http://arxiv.org/abs/2505.14528)|null|\n", "2505.13994": "|**2025-05-20**|**Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning**|Ruiyi Yang et.al.|[2505.13994](http://arxiv.org/abs/2505.13994)|null|\n", "2505.13129": "|**2025-05-19**|**Optimizing Retrieval Augmented Generation for Object Constraint Language**|Kevin Chenhao Li et.al.|[2505.13129](http://arxiv.org/abs/2505.13129)|null|\n", "2505.13006": "|**2025-05-19**|**Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain**|Yuyang Li et.al.|[2505.13006_(ACL)](http://arxiv.org/abs/2505.13006)|null|\n", "2505.11946": "|**2025-05-17**|**Let's have a chat with the EU AI Act**|Adam Kovari et.al.|[2505.11946](http://arxiv.org/abs/2505.11946)|null|\n", "2505.11908": "|**2025-05-17**|**ELITE: Embedding-Less retrieval with Iterative Text Exploration**|Zhangyu Wang et.al.|[2505.11908](http://arxiv.org/abs/2505.11908)|null|\n", "2505.17058": "|**2025-05-17**|**DO-RAG: A Domain-Specific QA Framework Using Knowledge Graph-Enhanced Retrieval-Augmented Generation**|David Osei Opoku et.al.|[2505.17058](http://arxiv.org/abs/2505.17058)|null|\n", "2505.11180": "|**2025-05-16**|**mmRAG: A Modular Benchmark for Retrieval-Augmented Generation over Text, Tables, and Knowledge Graphs**|Chuan Xu et.al.|[2505.11180](http://arxiv.org/abs/2505.11180)|null|\n", "2505.10143": "|**2025-05-15**|**GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs**|Longchao Da et.al.|[2505.10143_(IJCAI)](http://arxiv.org/abs/2505.10143)|null|\n", "2505.10074": "|**2025-05-16**|**Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs**|Mohamed Abdelmagied et.al.|[2505.10074](http://arxiv.org/abs/2505.10074)|null|\n", "2505.07546": "|**2025-05-12**|**GRADA: Graph-based Reranker against Adversarial Documents Attack**|Jingjie Zheng et.al.|[2505.07546](http://arxiv.org/abs/2505.07546)|null|\n", "2505.06020": "|**2025-05-09**|**ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding**|Shuai Wang et.al.|[2505.06020](http://arxiv.org/abs/2505.06020)|null|\n", "2505.02271": "|**2025-05-04**|**Real-time Spatial Retrieval Augmented Generation for Urban Environments**|David Nazareno Campo et.al.|[2505.02271](http://arxiv.org/abs/2505.02271)|null|\n", "2505.02164": "|**2025-05-04**|**Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use**|Justin Ho et.al.|[2505.02164](http://arxiv.org/abs/2505.02164)|null|\n", "2505.00254": "|**2025-05-16**|**Empowering Agentic Video Analytics Systems with Video Language Models**|Yuxuan Yan et.al.|[2505.00254](http://arxiv.org/abs/2505.00254)|null|\n", "2505.00039": "|**2025-06-17**|**Graph RAG for Legal Norms: A Hierarchical, Temporal and Deterministic Approach**|Hudson de Martim et.al.|[2505.00039](http://arxiv.org/abs/2505.00039)|null|\n", "2504.18793": "|**2025-04-26**|**Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations**|Santosh Bhupathi et.al.|[2504.18793](http://arxiv.org/abs/2504.18793)|null|\n", "2504.16813": "|**2025-04-23**|**LLM-assisted Graph-RAG Information Extraction from IFC Data**|Sima Iranmanesh et.al.|[2504.16813](http://arxiv.org/abs/2504.16813)|null|\n", "2504.15909": "|**2025-04-24**|**Synergizing RAG and Reasoning: A Systematic Review**|Yunfan Gao et.al.|[2504.15909](http://arxiv.org/abs/2504.15909)|null|\n", "2504.14955": "|**2025-04-21**|**Efficient Document Retrieval with G-Retriever**|Manthankumar Solanki et.al.|[2504.14955_(NeurIPS)](http://arxiv.org/abs/2504.14955)|null|\n", "2504.13534": "|**2025-05-19**|**CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models**|Feiyang Li et.al.|[2504.13534](http://arxiv.org/abs/2504.13534)|null|\n", "2504.13032": "|**2025-04-17**|**InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning**|Zheng Wang et.al.|[2504.13032_(SIGIR)](http://arxiv.org/abs/2504.13032)|null|\n", "2504.12560": "|**2025-04-17**|**CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation**|Elahe Khatibi et.al.|[2504.12560](http://arxiv.org/abs/2504.12560)|null|\n", "2504.11544": "|**2025-04-15**|**NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes**|Tianyang Xu et.al.|[2504.11544](http://arxiv.org/abs/2504.11544)|null|\n", "2504.11502": "|**2025-04-15**|**Timing Analysis Agent: Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug Relation Graph**|Jatin Nainani et.al.|[2504.11502](http://arxiv.org/abs/2504.11502)|null|\n", "2504.10240": "|**2025-07-24**|**GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction**|Guanyuan Pan et.al.|[2504.10240_(DATE)](http://arxiv.org/abs/2504.10240)|null|\n", "2504.10063": "|**2025-05-22**|**Hallucination Detection in LLMs with Topological Divergence on Attention Graphs**|Alexandra Bazarova et.al.|[2504.10063](http://arxiv.org/abs/2504.10063)|null|\n", "2504.10046": "|**2025-04-14**|**CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation**|Jia Li et.al.|[2504.10046](http://arxiv.org/abs/2504.10046)|null|\n", "2504.10036": "|**2025-04-14**|**DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics through Extract-Reason-Verify**|Zhengxuan Zhang et.al.|[2504.10036](http://arxiv.org/abs/2504.10036)|null|\n", "2504.09910": "|**2025-04-14**|**Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models**|Yujing Wang et.al.|[2504.09910](http://arxiv.org/abs/2504.09910)|null|\n", "2504.09823": "|**2025-04-14**|**RAKG:Document-level Retrieval Augmented Knowledge Graph Construction**|Hairong Zhang et.al.|[2504.09823](http://arxiv.org/abs/2504.09823)|null|\n", "2504.12330": "|**2025-04-13**|**HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation**|Pei Liu et.al.|[2504.12330](http://arxiv.org/abs/2504.12330)|null|\n", "2504.08912": "|**2025-04-11**|**HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules**|Neil He et.al.|[2504.08912](http://arxiv.org/abs/2504.08912)|null|\n", "2504.10499": "|**2025-04-08**|**Graph-based Approaches and Functionalities in Retrieval-Augmented Generation: A Comprehensive Survey**|Zulun Zhu et.al.|[2504.10499](http://arxiv.org/abs/2504.10499)|null|\n", "2504.05634": "|**2025-05-25**|**Simplifying Data Integration: SLM-Driven Systems for Unified Semantic Queries Across Heterogeneous Databases**|Teng Lin et.al.|[2504.05634](http://arxiv.org/abs/2504.05634)|null|\n", "2504.04578": "|**2025-04-06**|**Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification**|Cristina Cornelio et.al.|[2504.04578](http://arxiv.org/abs/2504.04578)|null|\n", "2504.04419": "|**2025-04-06**|**Driving-RAG: Driving Scenarios Embedding, Search, and RAG Applications**|Cheng Chang et.al.|[2504.04419](http://arxiv.org/abs/2504.04419)|null|\n", "2504.03241": "|**2025-04-04**|**Rotation Invariance in Floor Plan Digitization using Zernike Moments**|Marius Graumann et.al.|[2504.03241](http://arxiv.org/abs/2504.03241)|null|\n", "2504.02458": "|**2025-04-03**|**Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation**|Liangbo Ning et.al.|[2504.02458](http://arxiv.org/abs/2504.02458)|null|\n", "2504.01346": "|**2025-05-26**|**GTR: Graph-Table-RAG for Cross-Table Question Answering**|Jiaru Zou et.al.|[2504.01346](http://arxiv.org/abs/2504.01346)|null|\n", "2504.01309": "|**2025-04-02**|**Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph**|Lingxiao Guan et.al.|[2504.01309](http://arxiv.org/abs/2504.01309)|null|\n", "2506.15241": "|**2025-06-18**|**Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs**|Yang Fan et.al.|[2506.15241](http://arxiv.org/abs/2506.15241)|null|\n", "2506.18559": "|**2025-06-23**|**T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent**|Hong Qing Yu et.al.|[2506.18559](http://arxiv.org/abs/2506.18559)|null|\n", "2506.18027": "|**2025-06-22**|**PDF Retrieval Augmented Question Answering**|Thi Thu Uyen Hoang et.al.|[2506.18027](http://arxiv.org/abs/2506.18027)|null|\n", "2506.17951": "|**2025-06-22**|**A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment**|Quanwei Tang et.al.|[2506.17951_(ACL)](http://arxiv.org/abs/2506.17951)|null|\n", "2506.17288": "|**2025-06-15**|**SlimRAG: Retrieval without Graphs via Entity-Aware Context Selection**|Jiale Zhang et.al.|[2506.17288](http://arxiv.org/abs/2506.17288)|null|\n", "2506.18952": "|**2025-06-23**|**LLMs on a Budget? Say HOLA**|Zohaib Hasan Siddiqui et.al.|[2506.18952](http://arxiv.org/abs/2506.18952)|null|\n", "2506.19385": "|**2025-06-24**|**Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics**|Ziqi Zhu et.al.|[2506.19385](http://arxiv.org/abs/2506.19385)|null|\n", "2506.19967": "|**2025-06-24**|**Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs**|Travis Thompson et.al.|[2506.19967](http://arxiv.org/abs/2506.19967)|null|\n", "2506.21536": "|**2025-06-26**|**PsyLite Technical Report**|Fangjun Ding et.al.|[2506.21536](http://arxiv.org/abs/2506.21536)|null|\n", "2506.20963": "|**2025-07-04**|**EraRAG: Efficient and Incremental Retrieval Augmented Generation for Growing Corpora**|Fangyuan Zhang et.al.|[2506.20963](http://arxiv.org/abs/2506.20963)|null|\n", "2506.21593": "|**2025-06-18**|**PentaRAG: Large-Scale Intelligent Knowledge Retrieval for Enterprise LLM Applications**|Abu Hanif Muhammad Syarubany et.al.|[2506.21593_(ICS)](http://arxiv.org/abs/2506.21593)|null|\n", "2506.21568": "|**2025-06-12**|**Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion**|Andrejs Sorstkins et.al.|[2506.21568](http://arxiv.org/abs/2506.21568)|null|\n", "2506.21556": "|**2025-06-11**|**VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation**|Hyeongcheol Park et.al.|[2506.21556](http://arxiv.org/abs/2506.21556)|**[link](https://vatkg.github.io/)**|\n", "2506.22518": "|**2025-06-26**|**Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation**|Deyu Zou et.al.|[2506.22518](http://arxiv.org/abs/2506.22518)|null|\n", "2507.01297": "|**2025-07-05**|**Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks**|Xinxi Lyu et.al.|[2507.01297](http://arxiv.org/abs/2507.01297)|null|\n", "2507.00951": "|**2025-07-12**|**Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact**|Rizwan Qureshi et.al.|[2507.00951](http://arxiv.org/abs/2507.00951)|null|\n", "2507.01079": "|**2025-07-01**|**MobileRAG: A Fast, Memory-Efficient, and Energy-Efficient Method for On-Device RAG**|Taehwan Park et.al.|[2507.01079](http://arxiv.org/abs/2507.01079)|null|\n", "2507.00521": "|**2025-07-02**|**WebANNS: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers**|Mugeng Liu et.al.|[2507.00521_(SIGIR)](http://arxiv.org/abs/2507.00521)|null|\n", "2507.05257": "|**2025-07-07**|**Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions**|Yuanzhe Hu et.al.|[2507.05257](http://arxiv.org/abs/2507.05257)|null|\n", "2507.04661": "|**2025-07-07**|**DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics**|Yayu Long et.al.|[2507.04661_(ACL)](http://arxiv.org/abs/2507.04661)|null|\n", "2507.04377": "|**2025-08-11**|**Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions**|Xiao Zhang et.al.|[2507.04377](http://arxiv.org/abs/2507.04377)|null|\n", "2507.03724": "|**2025-08-05**|**MemOS: A Memory OS for AI System**|Zhiyu Li et.al.|[2507.03724](http://arxiv.org/abs/2507.03724)|null|\n", "2507.04127": "|**2025-07-05**|**BYOKG-RAG: Multi-Strategy Graph Retrieval for Knowledge Graph Question Answering**|Costas Mavromatis et.al.|[2507.04127](http://arxiv.org/abs/2507.04127)|null|\n", "2507.03608": "|**2025-07-04**|**Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)**|Sarat Ahmad et.al.|[2507.03608](http://arxiv.org/abs/2507.03608)|null|\n", "2507.03329": "|**2025-07-04**|**NDAI-NeuroMAP: A Neuroscience-Specific Embedding Model for Domain-Specific Retrieval**|Devendra Patel et.al.|[2507.03329](http://arxiv.org/abs/2507.03329)|null|\n", "2507.03226": "|**2025-08-07**|**Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems**|Congmin Min et.al.|[2507.03226](http://arxiv.org/abs/2507.03226)|null|\n", "2507.05863": "|**2025-07-08**|**KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation**|Zeyuan Meng et.al.|[2507.05863](http://arxiv.org/abs/2507.05863)|null|\n", "2507.05713": "|**2025-07-15**|**DRAGON: Dynamic RAG Benchmark On News**|Fedor Chernogorskii et.al.|[2507.05713](http://arxiv.org/abs/2507.05713)|null|\n", "2507.05279": "|**2025-07-04**|**ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy**|Virgile Boraud et.al.|[2507.05279](http://arxiv.org/abs/2507.05279)|null|\n", "2507.07957": "|**2025-07-10**|**MIRIX: Multi-Agent Memory System for LLM-Based Agents**|Yu Wang et.al.|[2507.07957](http://arxiv.org/abs/2507.07957)|null|\n", "2507.07223": "|**2025-07-13**|**Compute Can't Handle the Truth: Why Communication Tax Prioritizes Memory and Interconnects in Modern AI Infrastructure**|Myoungsoo Jung et.al.|[2507.07223](http://arxiv.org/abs/2507.07223)|null|\n", "2507.07695": "|**2025-07-31**|**KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities**|Hruday Markondapatnaikuni et.al.|[2507.07695](http://arxiv.org/abs/2507.07695)|null|\n", "2507.08432": "|**2025-07-11**|**xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models**|Gustavo Correa Publio et.al.|[2507.08432_(VLDB)](http://arxiv.org/abs/2507.08432)|null|\n", "2507.08443": "|**2025-07-11**|**KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations**|Georgios Balanos et.al.|[2507.08443](http://arxiv.org/abs/2507.08443)|null|\n", "2507.08445": "|**2025-08-03**|**Clue-RAG: Towards Accurate and Cost-Efficient Graph-based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval**|Yaodong Su et.al.|[2507.08445](http://arxiv.org/abs/2507.08445)|null|\n", "2507.08862": "|**2025-07-09**|**RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation**|Tianzhe Zhao et.al.|[2507.08862](http://arxiv.org/abs/2507.08862)|null|\n", "2507.10156": "|**2025-07-14**|**Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation**|Lubnaa Abdur Rahman et.al.|[2507.10156](http://arxiv.org/abs/2507.10156)|null|\n", "2507.10070": "|**2025-07-14**|**Breaking the Storage-Compute Bottleneck in Billion-Scale ANNS: A GPU-Driven Asynchronous I/O Framework**|Yang Xiao et.al.|[2507.10070](http://arxiv.org/abs/2507.10070)|null|\n", "2507.09138": "|**2025-07-12**|**HedraRAG: Coordinating LLM Generation and Database Retrieval in Heterogeneous RAG Serving**|Zhengding Hu et.al.|[2507.09138_(SOSP)](http://arxiv.org/abs/2507.09138)|null|\n", "2507.08945": "|**2025-07-11**|**GraphRunner: A Multi-Stage Framework for Efficient and Accurate Graph-Based Retrieval**|Savini Kashmira et.al.|[2507.08945](http://arxiv.org/abs/2507.08945)|null|\n", "2507.12425": "|**2025-07-16**|**Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data**|Chandana Cheerla et.al.|[2507.12425](http://arxiv.org/abs/2507.12425)|null|\n", "2507.13334": "|**2025-07-21**|**A Survey of Context Engineering for Large Language Models**|Lingrui Mei et.al.|[2507.13334](http://arxiv.org/abs/2507.13334)|null|\n", "2507.13625": "|**2025-07-18**|**BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety**|Yuxin Zhang et.al.|[2507.13625](http://arxiv.org/abs/2507.13625)|null|\n", "2507.13396": "|**2025-07-16**|**DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning**|Qingyun Sun et.al.|[2507.13396](http://arxiv.org/abs/2507.13396)|null|\n", "2507.15221": "|**2025-07-21**|**EchoVoices: Preserving Generational Voices and Memories for Seniors and Children**|Haiying Xu et.al.|[2507.15221](http://arxiv.org/abs/2507.15221)|null|\n", "2507.14791": "|**2025-07-20**|**Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context**|Yang Liu et.al.|[2507.14791](http://arxiv.org/abs/2507.14791)|null|\n", "2507.16713": "|**2025-07-22**|**Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory**|Guowei Lan et.al.|[2507.16713](http://arxiv.org/abs/2507.16713)|null|\n", "2507.16507": "|**2025-07-22**|**Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications**|Jean Lelong et.al.|[2507.16507](http://arxiv.org/abs/2507.16507)|null|\n", "2507.16011": "|**2025-07-21**|**mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages**|Hellina Hailu Nigatu et.al.|[2507.16011_(ACL)](http://arxiv.org/abs/2507.16011)|null|\n", "2507.17209": "|**2025-07-23**|**HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery**|Haoran Jiang et.al.|[2507.17209](http://arxiv.org/abs/2507.17209)|null|\n", "2507.16826": "|**2025-07-07**|**A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented Generation in Large Language Models**|Qikai Wei et.al.|[2507.16826](http://arxiv.org/abs/2507.16826)|null|\n", "2507.17399": "|**2025-07-23**|**Millions of $\\text{GeAR}$-s: Extending GraphRAG to Millions of Documents**|Zhili Shen et.al.|[2507.17399_(SIGIR)](http://arxiv.org/abs/2507.17399)|null|\n", "2507.17199": "|**2025-07-23**|**Threshold-Protected Searchable Sharing: Privacy Preserving Aggregated-ANN Search for Collaborative RAG**|Ruoyang Rykie Guo et.al.|[2507.17199](http://arxiv.org/abs/2507.17199)|null|\n", "2508.03793": "|**2025-08-05**|**AttnTrace: Attention-based Context Traceback for Long-Context LLMs**|Yanting Wang et.al.|[2508.03793](http://arxiv.org/abs/2508.03793)|**[link](https://github.com/Wang-Yanting/AttnTrace.)**|\n", "2508.04390": "|**2025-08-05**|**AIC CTU@FEVER 8: On-premise fact checking through long context RAG**|Herbert Ullrich et.al.|[2508.04390](http://arxiv.org/abs/2508.04390)|null|\n", "2508.01918": "|**2025-08-03**|**Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language**|Jaskaranjeet Singh et.al.|[2508.01918](http://arxiv.org/abs/2508.01918)|null|\n", "2508.01832": "|**2025-08-03**|**MLP Memory: Language Modeling with Retriever-pretrained External Memory**|Rubin Wei et.al.|[2508.01832](http://arxiv.org/abs/2508.01832)|null|\n", "2508.01405": "|**2025-08-02**|**Balancing the Blend: An Experimental Analysis of Trade-offs in Hybrid Search**|Mengzhao Wang et.al.|[2508.01405](http://arxiv.org/abs/2508.01405)|null|\n", "2508.00429": "|**2025-08-11**|**ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network**|Minghao Guo et.al.|[2508.00429](http://arxiv.org/abs/2508.00429)|null|\n", "2507.19715": "|**2025-07-25**|**Beyond Nearest Neighbors: Semantic Compression and Graph-Augmented Retrieval for Enhanced Vector Search**|Rahul Raja et.al.|[2507.19715](http://arxiv.org/abs/2507.19715)|null|\n", "2409.01344": "|**2024-10-21**|**Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&A**|K Roth et.al.|[2409.01344](http://arxiv.org/abs/2409.01344)|null|\n", "2408.15710": "|**2024-08-29**|**Conan-embedding: General Text Embedding with More and Better Negative Samples**|Shiyu Li et.al.|[2408.15710](http://arxiv.org/abs/2408.15710)|null|\n", "2408.09199": "|**2024-08-17**|**TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems**|Xinke Jiang et.al.|[2408.09199](http://arxiv.org/abs/2408.09199)|null|\n", "2408.03841": "|**2024-08-07**|**MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**|Yuchen Dong et.al.|[2408.03841](http://arxiv.org/abs/2408.03841)|null|\n", "2407.21300": "|**2025-05-15**|**SAKR: Enhancing Retrieval-Augmented Generation via Streaming Algorithm and K-Means Clustering**|Haoyu Kang et.al.|[2407.21300](http://arxiv.org/abs/2407.21300)|null|\n", "2407.14717": "|**2024-10-15**|**Differential Privacy of Cross-Attention with Provable Guarantee**|Yingyu Liang et.al.|[2407.14717](http://arxiv.org/abs/2407.14717)|null|\n", "2407.12784": "|**2024-07-17**|**AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases**|Zhaorun Chen et.al.|[2407.12784](http://arxiv.org/abs/2407.12784)|null|\n", "2407.12101": "|**2025-02-12**|**Better RAG using Relevant Information Gain**|Marc Pickett et.al.|[2407.12101_(EMNLP)](http://arxiv.org/abs/2407.12101)|null|\n", "2407.10670": "|**2024-07-15**|**Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems**|Yunxiao Shi et.al.|[2407.10670](http://arxiv.org/abs/2407.10670)|null|\n", "2407.09450": "|**2024-10-25**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450](http://arxiv.org/abs/2407.09450)|null|\n", "2407.08495": "|**2024-10-04**|**Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024**|Ilias Chalkidis et.al.|[2407.08495_(EMNLP)](http://arxiv.org/abs/2407.08495)|null|\n", "2407.03627": "|**2024-09-08**|**DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation**|Taeho Hwang et.al.|[2407.03627](http://arxiv.org/abs/2407.03627)|null|\n", "2407.01178": "|**2024-07-01**|**$\\text{Memory}^3$: Language Modeling with Explicit Memory**|Hongkang Yang et.al.|[2407.01178](http://arxiv.org/abs/2407.01178)|null|\n", "2406.18312": "|**2024-08-28**|**AI-native Memory: A Pathway from LLMs Towards AGI**|Jingbo Shang et.al.|[2406.18312](http://arxiv.org/abs/2406.18312)|null|\n", "2406.12824": "|**2024-06-18**|**From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries**|Hitesh Wadhwa et.al.|[2406.12824](http://arxiv.org/abs/2406.12824)|null|\n", "2406.00057": "|**2024-06-04**|**Toward Conversational Agents with Context and Time Sensitive Long-term Memory**|Nick Alonso et.al.|[2406.00057](http://arxiv.org/abs/2406.00057)|null|\n", "2405.16420": "|**2024-05-26**|**M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions**|Zheng Wang et.al.|[2405.16420_(ACL)](http://arxiv.org/abs/2405.16420)|null|\n", "2405.14831": "|**2025-01-14**|**HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**|Bernal Jim\u00e9nez Guti\u00e9rrez et.al.|[2405.14831_(GROUP)](http://arxiv.org/abs/2405.14831)|**[link](https://github.com/OSU-NLP-Group/HippoRAG)**|\n", "2406.07561": "|**2024-05-09**|**Artificial Intelligence as the New Hacker: Developing Agents for Offensive Security**|Leroy Jacob Valencia et.al.|[2406.07561](http://arxiv.org/abs/2406.07561)|null|\n", "2405.04700": "|**2024-05-07**|**Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures**|Ruiyang Qin et.al.|[2405.04700](http://arxiv.org/abs/2405.04700)|null|\n", "2405.03267": "|**2024-05-07**|**Characterizing the Dilemma of Performance and Index Size in Billion-Scale Vector Search and Breaking It with Second-Tier Memory**|Rongxin Cheng et.al.|[2405.03267](http://arxiv.org/abs/2405.03267)|null|\n", "2404.16032": "|**2024-10-08**|**Studying Large Language Model Behaviors Under Context-Memory Conflicts With Real Documents**|Evgenii Kortukov et.al.|[2404.16032](http://arxiv.org/abs/2404.16032)|null|\n", "2404.13781": "|**2024-04-21**|**Evaluating Retrieval Quality in Retrieval-Augmented Generation**|Alireza Salemi et.al.|[2404.13781](http://arxiv.org/abs/2404.13781)|null|\n", "2404.12045": "|**2024-07-05**|**RAM: Towards an Ever-Improving Memory System by Learning from Communications**|Jiaqi Li et.al.|[2404.12045](http://arxiv.org/abs/2404.12045)|null|\n", "2404.06004": "|**2025-02-26**|**AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free Information Retrieval**|Kento Tatsuno et.al.|[2404.06004](http://arxiv.org/abs/2404.06004)|null|\n", "2404.00486": "|**2024-03-30**|**Dialectical Alignment: Resolving the Tension of 3H and Security Threats of LLMs**|Shu Yang et.al.|[2404.00486](http://arxiv.org/abs/2404.00486)|null|\n", "2403.11366": "|**2024-03-19**|**JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning**|Anique Tahir et.al.|[2403.11366](http://arxiv.org/abs/2403.11366)|null|\n", "2403.04317": "|**2024-11-04**|**Online Adaptation of Language Models with a Memory of Amortized Contexts**|Jihoon Tack et.al.|[2403.04317_(NeurIPS)](http://arxiv.org/abs/2403.04317)|null|\n", "2402.18510": "|**2024-12-06**|**RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval**|Kaiyue Wen et.al.|[2402.18510](http://arxiv.org/abs/2402.18510)|null|\n", "2402.17753": "|**2024-02-27**|**Evaluating Very Long-Term Conversational Memory of LLM Agents**|Adyasha Maharana et.al.|[2402.17753](http://arxiv.org/abs/2402.17753)|**[link](https://snap-research.github.io/locomo/)**|\n", "2402.17081": "|**2024-02-26**|**A Fine-tuning Enhanced RAG System with Quantized Influence Measure as AI Judge**|Keshav Rangan et.al.|[2402.17081](http://arxiv.org/abs/2402.17081)|null|\n", "2402.13547": "|**2024-10-17**|**ActiveRAG: Autonomously Knowledge Assimilation and Accommodation through Retrieval-Augmented Agents**|Zhipeng Xu et.al.|[2402.13547](http://arxiv.org/abs/2402.13547)|null|\n", "2402.10790": "|**2024-02-21**|**In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss**|Yuri Kuratov et.al.|[2402.10790](http://arxiv.org/abs/2402.10790)|null|\n", "2401.17244": "|**2024-10-09**|**LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation**|Yuan Chiang et.al.|[2401.17244](http://arxiv.org/abs/2401.17244)|null|\n", "2401.11391": "|**2024-01-21**|**Interactive AI with Retrieval-Augmented Generation for Next Generation Networking**|Ruichen Zhang et.al.|[2401.11391](http://arxiv.org/abs/2401.11391)|null|\n", "2401.07483": "|**2024-01-15**|**Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management**|Partha Sen et.al.|[2401.07483](http://arxiv.org/abs/2401.07483)|null|\n", "2312.03141": "|**2024-05-28**|**NDSEARCH: Accelerating Graph-Traversal-Based Approximate Nearest Neighbor Search through Near Data Processing**|Yitu Wang et.al.|[2312.03141](http://arxiv.org/abs/2312.03141)|null|\n", "2311.18397": "|**2023-11-30**|**IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions**|Zhebin Zhang et.al.|[2311.18397](http://arxiv.org/abs/2311.18397)|null|\n", "2311.04177": "|**2023-11-07**|**Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation**|Eric Melz et.al.|[2311.04177](http://arxiv.org/abs/2311.04177)|null|\n", "2309.17415": "|**2024-02-20**|**Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts**|Jiahao Ying et.al.|[2309.17415](http://arxiv.org/abs/2309.17415)|null|\n", "2308.10462": "|**2024-12-27**|**Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models**|Martin Weyssow et.al.|[2308.10462](http://arxiv.org/abs/2308.10462)|null|\n", "2308.09564": "|**2023-08-18**|**Deep Equilibrium Object Detection**|Shuai Wang et.al.|[2308.09564](http://arxiv.org/abs/2308.09564)|null|\n", "2210.02928": "|**2022-10-20**|**MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text**|Wenhu Chen et.al.|[2210.02928_(EMNLP)](http://arxiv.org/abs/2210.02928)|null|\n", "2207.06300": "|**2022-07-13**|**Re2G: Retrieve, Rerank, Generate**|Michael Glass et.al.|[2207.06300_(ACL)](http://arxiv.org/abs/2207.06300)|null|\n", "2005.11401": "|**2021-04-12**|**Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**|Patrick Lewis et.al.|[2005.11401_(NeurIPS)](http://arxiv.org/abs/2005.11401)|null|\n", "2001.05293": "|**2020-01-09**|**Lazy object copy as a platform for population-based probabilistic programming**|Lawrence M. Murray et.al.|[2001.05293](http://arxiv.org/abs/2001.05293)|null|\n", "2508.05318": "|**2025-08-07**|**mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering**|Xu Yuan et.al.|[2508.05318](http://arxiv.org/abs/2508.05318)|null|\n", "2508.01290": "|**2025-08-02**|**Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities**|Zhichao Yan et.al.|[2508.01290](http://arxiv.org/abs/2508.01290)|null|\n", "2507.21544": "|**2025-07-29**|**MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation**|Jungyeon Lee et.al.|[2507.21544](http://arxiv.org/abs/2507.21544)|null|\n", "2507.20804": "|**2025-07-28**|**MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs**|Xueyao Wan et.al.|[2507.20804](http://arxiv.org/abs/2507.20804)|null|\n", "2508.05498": "|**2025-08-07**|**GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning**|Ge Chang et.al.|[2508.05498](http://arxiv.org/abs/2508.05498)|null|\n", "2508.04604": "|**2025-08-06**|**TURA: Tool-Augmented Unified Retrieval Agent for AI Search**|Zhejun Zhao et.al.|[2508.04604](http://arxiv.org/abs/2508.04604)|null|\n", "2508.03553": "|**2025-08-05**|**MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation**|Wenlong Wu et.al.|[2508.03553_(ICDE)](http://arxiv.org/abs/2508.03553)|null|\n", "2508.02532": "|**2025-08-04**|**Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction**|Karan Reddy et.al.|[2508.02532](http://arxiv.org/abs/2508.02532)|null|\n", "2508.02435": "|**2025-08-04**|**Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking**|Shengbo Gong et.al.|[2508.02435](http://arxiv.org/abs/2508.02435)|null|\n", "2508.01680": "|**2025-08-03**|**T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval**|Dong Li et.al.|[2508.01680](http://arxiv.org/abs/2508.01680)|null|\n", "2508.01136": "|**2025-08-02**|**DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs**|Wei Zhou et.al.|[2508.01136_(ALT)](http://arxiv.org/abs/2508.01136)|**[link](https://github.com/weAIDB/DBAIOps/)**|\n", "2508.00961": "|**2025-08-01**|**FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph**|Xiang Li et.al.|[2508.00961](http://arxiv.org/abs/2508.00961)|null|\n", "2507.22533": "|**2025-07-30**|**CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records**|Dongchen Li et.al.|[2507.22533](http://arxiv.org/abs/2507.22533)|null|\n", "2507.21892": "|**2025-07-29**|**Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning**|Haoran Luo et.al.|[2507.21892](http://arxiv.org/abs/2507.21892)|null|\n", "2507.21585": "|**2025-07-29**|**SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation**|Hao Ye et.al.|[2507.21585](http://arxiv.org/abs/2507.21585)|null|\n", "2507.20370": "|**2025-07-27**|**Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation**|Michele Grimaldi et.al.|[2507.20370](http://arxiv.org/abs/2507.20370)|null|\n", "2507.22938": "|**2025-07-25**|**A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents**|Sumit Soman et.al.|[2507.22938_(KDD)](http://arxiv.org/abs/2507.22938)|null|\n", "2507.21110": "|**2025-07-10**|**SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering**|Kezhen Zhong et.al.|[2507.21110](http://arxiv.org/abs/2507.21110)|null|\n", "2505.19288": "|**2025-08-04**|**Hypercube-Based Retrieval-Augmented Generation for Scientific Question-Answering**|Jimeng Shi et.al.|[2505.19288](http://arxiv.org/abs/2505.19288)|null|\n", "2508.00827": "|**2025-08-05**|**A Foundational Schema.org Mapping for a Legal Knowledge Graph: Representing Brazilian Legal Norms as FRBR Works**|Hudson de Martim et.al.|[2508.00827_(SC)](http://arxiv.org/abs/2508.00827)|null|\n", "2504.07724": "|**2025-08-05**|**The Multi-Round Diagnostic RAG Framework for Emulating Clinical Reasoning**|Penglei Sun et.al.|[2504.07724](http://arxiv.org/abs/2504.07724)|null|\n", "2504.00409": "|**2025-04-01**|**Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding**|Mohanakrishnan Hariharan et.al.|[2504.00409](http://arxiv.org/abs/2504.00409)|null|\n", "2504.08758": "|**2025-03-30**|**Hyper-RAG: Combating LLM Hallucinations using Hypergraph-Driven Retrieval-Augmented Generation**|Yifan Feng et.al.|[2504.08758](http://arxiv.org/abs/2504.08758)|null|\n", "2503.21322": "|**2025-05-22**|**HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation**|Haoran Luo et.al.|[2503.21322](http://arxiv.org/abs/2503.21322)|null|\n", "2503.19878": "|**2025-04-29**|**CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation**|Nengbo Wang et.al.|[2503.19878](http://arxiv.org/abs/2503.19878)|null|\n", "2503.19314": "|**2025-03-25**|**RGL: A Graph-Centric, Modular Framework for Efficient Retrieval-Augmented Generation on Graphs**|Yuan Li et.al.|[2503.19314](http://arxiv.org/abs/2503.19314)|null|\n", "2503.14802": "|**2025-03-19**|**Graph-Based Re-ranking: Emerging Techniques, Limitations, and Opportunities**|Md Shahir Zaoad et.al.|[2503.14802](http://arxiv.org/abs/2503.14802)|null|\n", "2503.16530": "|**2025-03-18**|**Enhancing LLM Generation with Knowledge Hypergraph for Evidence-Based Medicine**|Chengfeng Dou et.al.|[2503.16530](http://arxiv.org/abs/2503.16530)|null|\n", "2503.14000": "|**2025-03-18**|**LLM-based Unit Test Generation for Dynamically-Typed Programs**|Runlin Liu et.al.|[2503.14000](http://arxiv.org/abs/2503.14000)|null|\n", "2504.07103": "|**2025-03-13**|**FG-RAG: Enhancing Query-Focused Summarization with Context-Aware Fine-Grained Graph RAG**|Yubin Hong et.al.|[2504.07103](http://arxiv.org/abs/2504.07103)|null|\n", "2503.10150": "|**2025-06-23**|**HiRAG: Retrieval-Augmented Generation with Hierarchical Knowledge**|Haoyu Huang et.al.|[2503.10150](http://arxiv.org/abs/2503.10150)|null|\n", "2503.10702": "|**2025-03-12**|**ClaimTrust: Propagation Trust Scoring for RAG Systems**|Hangkai Qian et.al.|[2503.10702](http://arxiv.org/abs/2503.10702)|null|\n", "2503.08323": "|**2025-03-11**|**Towards Scalable and Cross-Lingual Specialist Language Models for Oncology**|Morteza Rohanian et.al.|[2503.08323](http://arxiv.org/abs/2503.08323)|null|\n", "2503.06567": "|**2025-03-09**|**Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving**|Yao Cheng et.al.|[2503.06567](http://arxiv.org/abs/2503.06567)|null|\n", "2503.05185": "|**2025-08-03**|**Towards Temporal-Aware Multi-Modal Retrieval Augmented Generation in Finance**|Fengbin Zhu et.al.|[2503.05185](http://arxiv.org/abs/2503.05185)|null|\n", "2503.04338": "|**2025-03-06**|**In-depth Analysis of Graph-based RAG in a Unified Framework**|Yingli Zhou et.al.|[2503.04338](http://arxiv.org/abs/2503.04338)|null|\n", "2503.03108": "|**2025-07-22**|**OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting**|Wenrui Cheng et.al.|[2503.03108](http://arxiv.org/abs/2503.03108)|null|\n", "2503.02922": "|**2025-03-04**|**Optimizing open-domain question answering with graph-based retrieval augmented generation**|Joyce Cahoon et.al.|[2503.02922](http://arxiv.org/abs/2503.02922)|null|\n", "2503.01346": "|**2025-03-06**|**SRAG: Structured Retrieval-Augmented Generation for Multi-Entity Question Answering over Wikipedia Graph**|Teng Lin et.al.|[2503.01346](http://arxiv.org/abs/2503.01346)|null|\n", "2504.06271": "|**2025-03-02**|**ER-RAG: Enhance RAG with ER-Based Unified Modeling of Heterogeneous Data Sources**|Yikuan Xia et.al.|[2504.06271](http://arxiv.org/abs/2504.06271)|null|\n", "2503.00309": "|**2025-03-01**|**Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for RAG-Equipped LLM**|Yuxin Yang et.al.|[2503.00309](http://arxiv.org/abs/2503.00309)|null|\n", "2502.21087": "|**2025-02-28**|**PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information**|Hansi Yang et.al.|[2502.21087](http://arxiv.org/abs/2502.21087)|null|\n", "2503.04790": "|**2025-02-28**|**SuperRAG: Beyond RAG with Layout-Aware Graph Modeling**|Jeff Yang et.al.|[2503.04790_(ACL)](http://arxiv.org/abs/2503.04790)|null|\n", "2502.18992": "|**2025-02-26**|**OntologyRAG: Better and Faster Biomedical Code Mapping with Retrieval-Augmented Generation (RAG) Leveraging Ontology Knowledge Graphs and Large Language Models**|Hui Feng et.al.|[2502.18992_(ECIR)](http://arxiv.org/abs/2502.18992)|null|\n", "2502.18928": "|**2025-02-26**|**Talking like Piping and Instrumentation Diagrams (P&IDs)**|Achmad Anggawirya Alimin et.al.|[2502.18928](http://arxiv.org/abs/2502.18928)|null|\n", "2502.16868": "|**2025-02-24**|**Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data**|Longbin Lai et.al.|[2502.16868](http://arxiv.org/abs/2502.16868)|null|\n", "2502.15005": "|**2025-02-20**|**A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems**|Lew Lefton et.al.|[2502.15005_(AAAI)](http://arxiv.org/abs/2502.15005)|null|\n", "2508.06401": "|**2025-08-08**|**A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges**|Andrew Brown et.al.|[2508.06401](http://arxiv.org/abs/2508.06401)|null|\n", "2508.05662": "|**2025-07-31**|**From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base**|Yuzhou Zhu et.al.|[2508.05662](http://arxiv.org/abs/2508.05662)|null|\n", "2502.13826": "|**2025-02-19**|**In-Place Updates of a Graph Index for Streaming Approximate Nearest Neighbor Search**|Haike Xu et.al.|[2502.13826](http://arxiv.org/abs/2502.13826)|null|\n", "2502.13562": "|**2025-02-19**|**Are Large Language Models In-Context Graph Learners?**|Jintang Li et.al.|[2502.13562](http://arxiv.org/abs/2502.13562)|null|\n", "2502.13010": "|**2025-06-29**|**Agentic Medical Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge**|Mohammad Reza Rezaei et.al.|[2502.13010](http://arxiv.org/abs/2502.13010)|null|\n", "2502.14902": "|**2025-02-18**|**PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths**|Boyu Chen et.al.|[2502.14902](http://arxiv.org/abs/2502.14902)|null|\n", "2502.12442": "|**2025-05-26**|**HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation**|Hao Liu et.al.|[2502.12442](http://arxiv.org/abs/2502.12442)|null|\n", "2502.11371": "|**2025-02-17**|**RAG vs. GraphRAG: A Systematic Evaluation and Key Insights**|Haoyu Han et.al.|[2502.11371](http://arxiv.org/abs/2502.11371)|null|\n", "2502.10996": "|**2025-05-17**|**RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation**|Pengcheng Jiang et.al.|[2502.10996](http://arxiv.org/abs/2502.10996)|null|\n", "2502.09891": "|**2025-08-08**|**ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**|Shu Wang et.al.|[2502.09891](http://arxiv.org/abs/2502.09891)|null|\n", "2502.09304": "|**2025-06-03**|**KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG**|Yiqian Huang et.al.|[2502.09304](http://arxiv.org/abs/2502.09304)|null|\n", "2502.07223": "|**2025-02-11**|**Graph RAG-Tool Fusion**|Elias Lumer et.al.|[2502.07223](http://arxiv.org/abs/2502.07223)|null|\n", "2502.01549": "|**2025-02-03**|**VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**|Xubin Ren et.al.|[2502.01549](http://arxiv.org/abs/2502.01549)|null|\n", "2502.01113": "|**2025-02-03**|**GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**|Linhao Luo et.al.|[2502.01113](http://arxiv.org/abs/2502.01113)|null|\n", "2502.01059": "|**2025-02-03**|**Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**|Seungri Yoon et.al.|[2502.01059](http://arxiv.org/abs/2502.01059)|null|\n", "2501.18320": "|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320](http://arxiv.org/abs/2501.18320)|null|\n", "2501.16191": "|**2025-01-27**|**Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**|Antony Bartlett et.al.|[2501.16191_(ISS)](http://arxiv.org/abs/2501.16191)|null|\n", "2501.15067": "|**2025-01-25**|**CG-RAG: Research Question Answering by Citation Graph Retrieval-Augmented LLMs**|Yuntong Hu et.al.|[2501.15067](http://arxiv.org/abs/2501.15067)|null|\n", "2501.17181": "|**2025-01-25**|**An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis**|Arya Rahgozar et.al.|[2501.17181](http://arxiv.org/abs/2501.17181)|null|\n", "2501.14892": "|**2025-03-17**|**Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**|Hang Luo et.al.|[2501.14892](http://arxiv.org/abs/2501.14892)|null|\n", "2501.14101": "|**2025-01-23**|**StreamingRAG: Real-time Contextual Retrieval and Generation Framework**|Murugan Sankaradas et.al.|[2501.14101_(HPDC)](http://arxiv.org/abs/2501.14101)|null|\n", "2501.14050": "|**2025-06-07**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050](http://arxiv.org/abs/2501.14050)|null|\n", "2501.13993": "|**2025-01-23**|**CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**|Hamza Landolsi et.al.|[2501.13993](http://arxiv.org/abs/2501.13993)|null|\n", "2501.13958": "|**2025-01-21**|**A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**|Qinggang Zhang et.al.|[2501.13958](http://arxiv.org/abs/2501.13958)|null|\n", "2501.11849": "|**2025-02-18**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849](http://arxiv.org/abs/2501.11849)|null|\n", "2501.11216": "|**2025-05-03**|**TigerVector: Supporting Vector Search in Graph Databases for Advanced RAGs**|Shige Liu et.al.|[2501.11216](http://arxiv.org/abs/2501.11216)|null|\n", "2501.06713": "|**2025-01-26**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713](http://arxiv.org/abs/2501.06713)|null|\n", "2501.04258": "|**2025-01-08**|**How Large is the Universe of RNA-Like Motifs? A Clustering Analysis of RNA Graph Motifs Using Topological Descriptors**|Rui Wang et.al.|[2501.04258](http://arxiv.org/abs/2501.04258)|null|\n", "2502.15698": "|**2025-01-06**|**Developing an Artificial Intelligence Tool for Personalized Breast Cancer Treatment Plans based on the NCCN Guidelines**|Abdul M. Mohammed et.al.|[2502.15698](http://arxiv.org/abs/2502.15698)|null|\n", "2501.02173": "|**2025-01-04**|**The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit**|Huixue Zhou et.al.|[2501.02173](http://arxiv.org/abs/2501.02173)|null|\n", "2501.00309": "|**2025-01-08**|**Retrieval-Augmented Generation with Graphs (GraphRAG)**|Haoyu Han et.al.|[2501.00309](http://arxiv.org/abs/2501.00309)|null|\n", "2412.20927": "|**2024-12-30**|**Enhanced Multimodal RAG-LLM for Accurate Visual Question Answering**|Junxiao Xue et.al.|[2412.20927](http://arxiv.org/abs/2412.20927)|null|\n", "2412.18644": "|**2025-01-28**|**DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation**|Karishma Thakrar et.al.|[2412.18644](http://arxiv.org/abs/2412.18644)|null|\n", "2412.18431": "|**2025-06-22**|**GeAR: Graph-enhanced Agent for Retrieval-augmented Generation**|Zhili Shen et.al.|[2412.18431_(ACL)](http://arxiv.org/abs/2412.18431)|null|\n", "2412.16311": "|**2025-06-02**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311_(ACL)](http://arxiv.org/abs/2412.16311)|null|\n", "2412.18627": "|**2024-12-20**|**KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**|Xingyu Xiao et.al.|[2412.18627](http://arxiv.org/abs/2412.18627)|null|\n", "2412.15443": "|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443_(COLING)](http://arxiv.org/abs/2412.15443)|null|\n", "2412.09614": "|**2024-12-12**|**Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG**|Kavana Venkatesh et.al.|[2412.09614](http://arxiv.org/abs/2412.09614)|**[link](https://context-canvas.github.io/)**|\n", "2412.08593": "|**2024-12-11**|**Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based Automated Requirement Traceability and Compliance Checks**|Arsalan Masoudifard et.al.|[2412.08593](http://arxiv.org/abs/2412.08593)|null|\n", "2412.14191": "|**2024-12-10**|**Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education**|Chengshuai Zhao et.al.|[2412.14191](http://arxiv.org/abs/2412.14191)|null|\n", "2412.07618": "|**2024-12-20**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618_(AAAI)](http://arxiv.org/abs/2412.07618)|null|\n", "2412.07420": "|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420](http://arxiv.org/abs/2412.07420)|null|\n", "2412.07189": "|**2024-12-10**|**When Graph Meets Retrieval Augmented Generation for Wireless Networks: A Tutorial and Case Study**|Yang Xiong et.al.|[2412.07189](http://arxiv.org/abs/2412.07189)|null|\n", "2412.06078": "|**2024-12-08**|**Mixture-of-PageRanks: Replacing Long-Context with Real-Time, Sparse GraphRAG**|Nicholas Alonso et.al.|[2412.06078](http://arxiv.org/abs/2412.06078)|null|\n", "2412.05937": "|**2024-12-08**|**Accelerating Manufacturing Scale-Up from Material Discovery Using Agentic Web Navigation and Retrieval-Augmented AI for Process Engineering Schematics Design**|Sakhinana Sagar Srinivas et.al.|[2412.05937](http://arxiv.org/abs/2412.05937)|null|\n", "2412.05838": "|**2024-12-08**|**A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**|Aniruddha Salve et.al.|[2412.05838](http://arxiv.org/abs/2412.05838)|null|\n", "2412.04342": "|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342](http://arxiv.org/abs/2412.04342)|null|\n", "2411.16495": "|**2025-02-13**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495](http://arxiv.org/abs/2411.16495)|null|\n", "2411.14592": "|**2024-12-01**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592](http://arxiv.org/abs/2411.14592)|null|\n", "2411.12759": "|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759](http://arxiv.org/abs/2411.12759)|null|\n", "2411.07264": "|**2024-11-08**|**Multi-Document Financial Question Answering using LLMs**|Shalin Shah et.al.|[2411.07264](http://arxiv.org/abs/2411.07264)|null|\n", "2411.03572": "|**2024-11-06**|**Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge Reasoning and Text Generation**|Yuxin Dong et.al.|[2411.03572](http://arxiv.org/abs/2411.03572)|null|\n", "2411.08724": "|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724](http://arxiv.org/abs/2411.08724)|null|\n", "2411.01807": "|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807](http://arxiv.org/abs/2411.01807)|null|\n", "2410.23968": "|**2024-10-31**|**EmbodiedRAG: Dynamic 3D Scene Graph Retrieval for Efficient and Scalable Robot Task Planning**|Meghan Booker et.al.|[2410.23968](http://arxiv.org/abs/2410.23968)|null|\n", "2410.20299": "|**2025-02-14**|**EACO-RAG: Towards Distributed Tiered LLM Deployment using Edge-Assisted and Collaborative RAG with Adaptive Knowledge Update**|Jiaxing Li et.al.|[2410.20299](http://arxiv.org/abs/2410.20299)|null|\n", "2410.19727": "|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727](http://arxiv.org/abs/2410.19727)|null|\n", "2410.13542": "|**2024-10-17**|**LLM-based Unit Test Generation via Property Retrieval**|Zhe Zhang et.al.|[2410.13542](http://arxiv.org/abs/2410.13542)|null|\n", "2410.11001": "|**2025-05-29**|**Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**|Haozhen Zhang et.al.|[2410.11001_(ACL)](http://arxiv.org/abs/2410.11001)|**[link](https://github.com/ulab-uiuc/GoR)**|\n", "2410.09699": "|**2024-10-13**|**Honest AI: Fine-Tuning \"Small\" Language Models to Say \"I Don't Know\", and Reducing Hallucination in RAG**|Xinxi Chen et.al.|[2410.09699](http://arxiv.org/abs/2410.09699)|null|\n", "2410.07551": "|**2024-10-10**|**KRAG Framework for Enhancing LLMs in the Legal Domain**|Nguyen Ha Thanh et.al.|[2410.07551](http://arxiv.org/abs/2410.07551)|null|\n", "2410.18251": "|**2025-06-13**|**Context-Augmented Code Generation Using Programming Knowledge Graphs**|Iman Saberi et.al.|[2410.18251](http://arxiv.org/abs/2410.18251)|null|\n", "2410.05779": "|**2025-04-28**|**LightRAG: Simple and Fast Retrieval-Augmented Generation**|Zirui Guo et.al.|[2410.05779](http://arxiv.org/abs/2410.05779)|null|\n", "2410.04790": "|**2025-06-08**|**PECAN: LLM-Guided Dynamic Progress Control with Attention-Guided Hierarchical Weighted Graph for Long-Document QA**|Xinyu Wang et.al.|[2410.04790](http://arxiv.org/abs/2410.04790)|null|\n", "2410.01066": "|**2025-02-04**|**From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**|Ali Mohammadjafari et.al.|[2410.01066](http://arxiv.org/abs/2410.01066)|null|\n", "2409.19753": "|**2025-03-19**|**CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**|Yike Wu et.al.|[2409.19753](http://arxiv.org/abs/2409.19753)|null|\n", "2409.16176": "|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176](http://arxiv.org/abs/2409.16176)|null|\n", "2409.13537": "|**2024-09-20**|**ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**|Shuting Yang et.al.|[2409.13537_(WISE)](http://arxiv.org/abs/2409.13537)|null|\n", "2409.08820": "|**2025-02-11**|**A RAG Approach for Generating Competency Questions in Ontology Engineering**|Xueli Pan et.al.|[2409.08820](http://arxiv.org/abs/2409.08820)|null|\n", "2410.00005": "|**2024-09-13**|**Winning Solution For Meta KDD Cup' 24**|Yikuan Xia et.al.|[2410.00005](http://arxiv.org/abs/2410.00005)|null|\n", "2409.09046": "|**2025-02-25**|**HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications**|Rishi Kalra et.al.|[2409.09046_(ACL)](http://arxiv.org/abs/2409.09046)|null|\n", "2408.13273": "|**2024-08-18**|**Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach for Temporal Knowledge Graph Forecasting**|Geethan Sannidhi et.al.|[2408.13273_(KDD)](http://arxiv.org/abs/2408.13273)|**[link](https://kdd2024.kdd.org/undergraduate-consortium/)**|\n", "2408.08921": "|**2024-09-10**|**Graph Retrieval-Augmented Generation: A Survey**|Boci Peng et.al.|[2408.08921](http://arxiv.org/abs/2408.08921)|null|\n", "2408.07611": "|**2024-08-28**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611_(KDD)](http://arxiv.org/abs/2408.07611)|null|\n", "2408.05141": "|**2024-09-02**|**A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**|Ye Yuan et.al.|[2408.05141_(KDD)](http://arxiv.org/abs/2408.05141)|null|\n", "2408.04187": "|**2024-10-15**|**Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval-Augmented Generation**|Junde Wu et.al.|[2408.04187](http://arxiv.org/abs/2408.04187)|null|\n", "2407.19994": "|**2024-09-13**|**A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph**|Cheonsu Jeong et.al.|[2407.19994](http://arxiv.org/abs/2407.19994)|null|\n", "2407.16252": "|**2024-12-16**|**LawLuo: A Multi-Agent Collaborative Framework for Multi-Round Chinese Legal Consultation**|Jingyun Sun et.al.|[2407.16252](http://arxiv.org/abs/2407.16252)|null|\n", "2407.12888": "|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888](http://arxiv.org/abs/2407.12888)|null|\n", "2407.11638": "|**2025-05-21**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638](http://arxiv.org/abs/2407.11638)|null|\n", "2407.00466": "|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466](http://arxiv.org/abs/2407.00466)|null|\n", "2406.16252": "|**2024-06-25**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252](http://arxiv.org/abs/2406.16252)|null|\n", "2406.02110": "|**2024-06-04**|**UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models**|Zhuoyang Li et.al.|[2406.02110](http://arxiv.org/abs/2406.02110)|null|\n", "2406.06566": "|**2024-08-16**|**Natural Language Interaction with a Household Electricity Knowledge-based Digital Twin**|Carolina Fortuna et.al.|[2406.06566](http://arxiv.org/abs/2406.06566)|null|\n", "2406.00456": "|**2025-01-26**|**Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation**|Zijie Zhong et.al.|[2406.00456_(COLING)](http://arxiv.org/abs/2406.00456)|null|\n", "2405.18414": "|**2024-05-28**|**Don't Forget to Connect! Improving RAG with Graph-based Reranking**|Jialin Dong et.al.|[2405.18414](http://arxiv.org/abs/2405.18414)|null|\n", "2405.17602": "|**2024-05-27**|**Augmenting Textual Generation via Topology Aware Retrieval**|Yu Wang et.al.|[2405.17602](http://arxiv.org/abs/2405.17602)|null|\n", "2405.16933": "|**2024-05-27**|**Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**|Xun Liang et.al.|[2405.16933](http://arxiv.org/abs/2405.16933)|null|\n", "2405.16506": "|**2025-07-12**|**GRAG: Graph Retrieval-Augmented Generation**|Yuntong Hu et.al.|[2405.16506](http://arxiv.org/abs/2405.16506)|null|\n", "2405.16072": "|**2024-09-23**|**SynthAI: A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation**|Seyed Arash Sheikholeslam et.al.|[2405.16072](http://arxiv.org/abs/2405.16072)|null|\n", "2405.13401": "|**2024-07-07**|**TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models**|Pengzhou Cheng et.al.|[2405.13401](http://arxiv.org/abs/2405.13401)|null|\n", "2404.16130": "|**2025-02-19**|**From Local to Global: A Graph RAG Approach to Query-Focused Summarization**|Darren Edge et.al.|[2404.16130](http://arxiv.org/abs/2404.16130)|null|\n", "2404.05587": "|**2024-04-19**|**Enhancing Software-Related Information Extraction via Single-Choice Question Answering with Large Language Models**|Wolfgang Otto et.al.|[2404.05587_(SC)](http://arxiv.org/abs/2404.05587)|null|\n", "2402.12352": "|**2024-02-19**|**Graph-Based Retriever Captures the Long Tail of Biomedical Knowledge**|Julien Delile et.al.|[2402.12352](http://arxiv.org/abs/2402.12352)|null|\n", "2402.11034": "|**2024-06-03**|**PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering**|Jannat Ara Meem et.al.|[2402.11034_(ACL)](http://arxiv.org/abs/2402.11034)|null|\n", "2402.07630": "|**2024-05-27**|**G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering**|Xiaoxin He et.al.|[2402.07630](http://arxiv.org/abs/2402.07630)|null|\n", "2312.15591": "|**2024-06-18**|**Privacy-Preserved Neural Graph Databases**|Qi Hu et.al.|[2312.15591](http://arxiv.org/abs/2312.15591)|null|\n", "2310.13848": "|**2024-06-01**|**FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction**|Priyanka Ranade et.al.|[2310.13848](http://arxiv.org/abs/2310.13848)|null|\n", "2310.09089": "|**2024-04-17**|**Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model**|Qichen Ye et.al.|[2310.09089](http://arxiv.org/abs/2310.09089)|null|\n", "2310.05628": "|**2024-01-16**|**Glitter or Gold? Deriving Structured Insights from Sustainability Reports via Large Language Models**|Marco Bronzini et.al.|[2310.05628](http://arxiv.org/abs/2310.05628)|null|\n", "2310.03812": "|**2024-06-28**|**Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs**|T. Lucas Makinen et.al.|[2310.03812](http://arxiv.org/abs/2310.03812)|null|\n", "2305.19787": "|**2024-01-05**|**DeepMerge: Deep-Learning-Based Region-Merging for Image Segmentation**|Xianwei Lv et.al.|[2305.19787](http://arxiv.org/abs/2305.19787)|null|\n", "2303.14322": "|**2023-03-25**|**Spatio-Temporal driven Attention Graph Neural Network with Block Adjacency matrix (STAG-NN-BA)**|U. Nazir et.al.|[2303.14322](http://arxiv.org/abs/2303.14322)|null|\n", "2302.05598": "|**2023-02-11**|**Multi-class Brain Tumor Segmentation using Graph Attention Network**|Dhrumil Patel et.al.|[2302.05598](http://arxiv.org/abs/2302.05598)|null|\n", "2206.01356": "|**2022-12-04**|**Structure Learning for Hybrid Bayesian Networks**|Wanchuang Zhu et.al.|[2206.01356](http://arxiv.org/abs/2206.01356)|null|\n", "2112.04744": "|**2025-01-19**|**Superpixel-Based Building Damage Detection from Post-earthquake Imagery Using Deep Neural Networks**|Jun Wang et.al.|[2112.04744](http://arxiv.org/abs/2112.04744)|null|\n", "2002.05544": "|**2020-11-15**|**Superpixel Image Classification with Graph Attention Networks**|Pedro H. C. Avelar et.al.|[2002.05544](http://arxiv.org/abs/2002.05544)|null|\n", "1904.12577": "|**2019-07-09**|**Table understanding in structured documents**|Martin Hole\u010dek et.al.|[1904.12577_(AVI)](http://arxiv.org/abs/1904.12577)|null|\n", "1305.5756": "|**2013-05-24**|**Flooding edge or node weighted graphs**|Fernand Meyer et.al.|[1305.5756](http://arxiv.org/abs/1305.5756)|null|\n", "1206.6410": "|**2012-06-27**|**On the Partition Function and Random Maximum A-Posteriori Perturbations**|Tamir Hazan et.al.|[1206.6410_(CHI)](http://arxiv.org/abs/1206.6410)|null|\n", "1007.1378": "|**2013-04-09**|**On independent sets in random graphs**|Amin Coja-Oghlan et.al.|[1007.1378](http://arxiv.org/abs/1007.1378)|null|\n", "2508.05660": "|**2025-07-30**|**Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review**|Aditya Nagori et.al.|[2508.05660](http://arxiv.org/abs/2508.05660)|null|\n", "2508.06105": "|**2025-08-08**|**You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures**|Shengyuan Chen et.al.|[2508.06105](http://arxiv.org/abs/2508.06105)|null|\n", "2508.05666": "|**2025-08-01**|**HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis**|Alejandro Godinez et.al.|[2508.05666](http://arxiv.org/abs/2508.05666)|**[link](https://github.com/agodinezmm2007/docling_mod.)**|\n", "2508.05664": "|**2025-08-01**|**Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support**|Hei Yu Chan et.al.|[2508.05664](http://arxiv.org/abs/2508.05664)|null|\n", "2508.05647": "|**2025-07-25**|**Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation**|Vibhor Agrawal et.al.|[2508.05647](http://arxiv.org/abs/2508.05647)|null|\n", "2508.07664": "|**2025-08-11**|**Understanding Users' Privacy Perceptions Towards LLM's RAG-based Memory**|Shuning Zhang et.al.|[2508.07664](http://arxiv.org/abs/2508.07664)|null|\n", "2508.06915": "|**2025-08-09**|**QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting**|Shichao Ma et.al.|[2508.06915](http://arxiv.org/abs/2508.06915)|null|\n", "2508.06729": "|**2025-08-08**|**Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis**|Komala Subramanyam Cherukuri et.al.|[2508.06729](http://arxiv.org/abs/2508.06729)|null|\n", "2506.17001": "|**2025-08-11**|**PersonalAI: A Systematic Comparison of Knowledge Graph Storage and Retrieval Approaches for Personalized LLM agents**|Mikhail Menschikov et.al.|[2506.17001](http://arxiv.org/abs/2506.17001)|null|\n", "2508.07185": "|**2025-08-10**|**DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention**|Kabir Khan et.al.|[2508.07185](http://arxiv.org/abs/2508.07185)|null|\n", "2506.13380": "|**2025-08-11**|**DAGR: Decomposition Augmented Graph Retrieval with LLMs**|Valentin Six et.al.|[2506.13380](http://arxiv.org/abs/2506.13380)|null|\n", "2502.20988": "|**2025-08-11**|**Reviewing Clinical Knowledge in Medical Large Language Models: Training and Beyond**|Qiyuan Li et.al.|[2502.20988](http://arxiv.org/abs/2502.20988)|null|\n", "2508.06496": "|**2025-07-20**|**Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG**|Rakesh Raj Madavan et.al.|[2508.06496](http://arxiv.org/abs/2508.06496)|null|\n", "2508.08469": "|**2025-08-11**|**Vector-Centric Machine Learning Systems: A Cross-Stack Approach**|Wenqi Jiang et.al.|[2508.08469](http://arxiv.org/abs/2508.08469)|null|\n", "2508.08785": "|**2025-08-12**|**Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering**|Yunfeng Ning et.al.|[2508.08785](http://arxiv.org/abs/2508.08785)|null|\n", "2508.08344": "|**2025-08-11**|**What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge**|Dongzhuoran Zhou et.al.|[2508.08344](http://arxiv.org/abs/2508.08344)|null|\n", "2508.08632": "|**2025-08-12**|**AgriGPT: a Large Language Model Ecosystem for Agriculture**|Bo Yang et.al.|[2508.08632](http://arxiv.org/abs/2508.08632)|null|\n"}, "LLM": {"2506.12708": "|**2025-06-19**|**Serving Large Language Models on Huawei CloudMatrix384**|Pengfei Zuo et.al.|[2506.12708](http://arxiv.org/abs/2506.12708)|null|\n", "2506.11886": "|**2025-06-13**|**Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache**|Xiaoran Liu et.al.|[2506.11886](http://arxiv.org/abs/2506.11886)|null|\n", "2506.11498": "|**2025-06-13**|**Lag-Relative Sparse Attention In Long Context Training**|Manlai Liang et.al.|[2506.11498](http://arxiv.org/abs/2506.11498)|null|\n", "2506.11309": "|**2025-06-12**|**SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding**|Ziyi Zhang et.al.|[2506.11309](http://arxiv.org/abs/2506.11309)|null|\n", "2506.02634": "|**2025-07-23**|**KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider**|Jiahao Wang et.al.|[2506.02634_(ATC)](http://arxiv.org/abs/2506.02634)|null|\n", "2506.11418": "|**2025-06-13**|**Efficient Long-Context LLM Inference via KV Cache Clustering**|Jie Hu et.al.|[2506.11418](http://arxiv.org/abs/2506.11418)|null|\n", "2506.13752": "|**2025-06-16**|**Steering LLM Thinking with Budget Guidance**|Junyan Li et.al.|[2506.13752](http://arxiv.org/abs/2506.13752)|**[link](https://github.com/umass-embodied-agi/budgetguidance)**|\n", "2506.13746": "|**2025-06-16**|**Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability**|Shova Kuikel et.al.|[2506.13746](http://arxiv.org/abs/2506.13746)|**[link](https://github.com/PsyberSecLab/Fine-Tuning-and-Explainability-for-Phishing-Detection)**|\n", "2506.13705": "|**2025-06-16**|**TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning**|Junru Zhang et.al.|[2506.13705](http://arxiv.org/abs/2506.13705)|**[link](https://github.com/langfengq/timemaster)**|\n", "2506.07564": "|**2025-06-11**|**SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems**|Peiran Li et.al.|[2506.07564](http://arxiv.org/abs/2506.07564)|null|\n", "2506.07334": "|**2025-06-09**|**Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models**|Haoyu Wang et.al.|[2506.07334](http://arxiv.org/abs/2506.07334)|null|\n", "2506.06444": "|**2025-07-09**|**Saffron-1: Safety Inference Scaling**|Ruizhong Qiu et.al.|[2506.06444_(SC)](http://arxiv.org/abs/2506.06444)|null|\n", "2505.15431": "|**2025-07-04**|**Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought**|Tencent Hunyuan Team et.al.|[2505.15431](http://arxiv.org/abs/2505.15431)|null|\n", "2505.13866": "|**2025-05-20**|**Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning**|Jiwon Song et.al.|[2505.13866](http://arxiv.org/abs/2505.13866)|null|\n", "2412.17747": "|**2024-12-23**|**Deliberation in Latent Space via Differentiable Cache Augmentation**|Luyang Liu et.al.|[2412.17747](http://arxiv.org/abs/2412.17747)|null|\n", "2505.21919": "|**2025-05-28**|**Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference**|Yue Zhu et.al.|[2505.21919](http://arxiv.org/abs/2505.21919)|null|\n", "2505.21889": "|**2025-05-29**|**EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse**|Tianyu Guo et.al.|[2505.21889_(DIS)](http://arxiv.org/abs/2505.21889)|null|\n", "2505.17694": "|**2025-05-23**|**FlashForge: Ultra-Efficient Prefix-Aware Attention for LLM Decoding**|Zhibin Wang et.al.|[2505.17694](http://arxiv.org/abs/2505.17694)|null|\n", "2506.03296": "|**2025-07-10**|**Parallel CPU-GPU Execution for LLM Inference on Constrained GPUs**|Jiakun Fan et.al.|[2506.03296](http://arxiv.org/abs/2506.03296)|null|\n", "2506.02006": "|**2025-05-24**|**Efficient and Workload-Aware LLM Serving via Runtime Layer Swapping and KV Cache Resizing**|Zhaoyuan Su et.al.|[2506.02006](http://arxiv.org/abs/2506.02006)|null|\n", "2505.23275": "|**2025-05-29**|**Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**|Guangyuan Liu et.al.|[2505.23275](http://arxiv.org/abs/2505.23275)|null|\n", "2506.10848": "|**2025-06-13**|**Accelerating Diffusion Large Language Models with SlowFast Sampling: The Three Golden Principles**|Qingyan Wei et.al.|[2506.10848](http://arxiv.org/abs/2506.10848)|null|\n", "2506.08373": "|**2025-07-19**|**Draft-based Approximate Inference for LLMs**|Kevin Galim et.al.|[2506.08373_(DIS)](http://arxiv.org/abs/2506.08373)|null|\n", "2506.07533": "|**2025-06-09**|**MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts**|Wei Tao et.al.|[2506.07533_(ACL)](http://arxiv.org/abs/2506.07533)|null|\n", "2506.07311": "|**2025-06-08**|**Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference**|Thomas Joshi et.al.|[2506.07311](http://arxiv.org/abs/2506.07311)|null|\n", "2506.11092": "|**2025-07-19**|**Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation**|Jubin Abhishek Soni et.al.|[2506.11092_(ISS)](http://arxiv.org/abs/2506.11092)|null|\n", "2506.05344": "|**2025-07-05**|**SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs**|Jiahui Wang et.al.|[2506.05344_(ICC)](http://arxiv.org/abs/2506.05344)|null|\n", "2506.05345": "|**2025-06-05**|**Inference-Time Hyper-Scaling with KV Cache Compression**|Adrian \u0141a\u0144cucki et.al.|[2506.05345](http://arxiv.org/abs/2506.05345)|null|\n", "2506.05332": "|**2025-06-05**|**Unleashing Hour-Scale Video Training for Long Video-Language Understanding**|Jingyang Lin et.al.|[2506.05332](http://arxiv.org/abs/2506.05332)|**[link](https://videomarathon.github.io/)**|\n", "2506.13772": "|**2025-06-05**|**MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs**|Zhenyan Lu et.al.|[2506.13772](http://arxiv.org/abs/2506.13772)|null|\n", "2506.05410": "|**2025-06-04**|**Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs**|Wanyun Cui et.al.|[2506.05410](http://arxiv.org/abs/2506.05410)|null|\n", "2506.03762": "|**2025-06-04**|**AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models**|Yifeng Gu et.al.|[2506.03762](http://arxiv.org/abs/2506.03762)|null|\n", "2506.03700": "|**2025-06-04**|**AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism**|Zhepei Wei et.al.|[2506.03700_(ICML)](http://arxiv.org/abs/2506.03700)|**[link](https://github.com/weizhepei/AdaDecode)**|\n", "2506.01827": "|**2025-06-02**|**Memory Access Characterization of Large Language Models in CPU Environment and its Potential Impacts**|Spencer Banasik et.al.|[2506.01827](http://arxiv.org/abs/2506.01827)|null|\n", "2506.01151": "|**2025-06-01**|**Earley-Driven Dynamic Pruning for Efficient Structured Decoding**|Xintong Sun et.al.|[2506.01151_(ICML)](http://arxiv.org/abs/2506.01151)|null|\n", "2506.00413": "|**2025-05-31**|**Accelerating Diffusion LLMs via Adaptive Parallel Decoding**|Daniel Israel et.al.|[2506.00413](http://arxiv.org/abs/2506.00413)|null|\n", "2505.24722": "|**2025-05-30**|**HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts**|Neil He et.al.|[2505.24722](http://arxiv.org/abs/2505.24722)|null|\n", "2505.24643": "|**2025-05-30**|**Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching**|Juan Wisznia et.al.|[2505.24643](http://arxiv.org/abs/2505.24643)|null|\n", "2505.24357": "|**2025-06-05**|**ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration**|Xianglong Yan et.al.|[2505.24357](http://arxiv.org/abs/2505.24357)|null|\n", "2505.24095": "|**2025-05-30**|**SkyLB: A Locality-Aware Cross-Region Load Balancer for LLM Inference**|Tian Xia et.al.|[2505.24095](http://arxiv.org/abs/2505.24095)|null|\n", "2505.23970": "|**2025-05-29**|**EmbAdvisor: Adaptive Cache Management for Sustainable LLM Serving**|Yuyang Tian et.al.|[2505.23970](http://arxiv.org/abs/2505.23970)|null|\n", "2505.23416": "|**2025-05-29**|**KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction**|Jang-Hyun Kim et.al.|[2505.23416](http://arxiv.org/abs/2505.23416)|null|\n", "2505.22913": "|**2025-05-28**|**Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference**|Donghyeon Joo et.al.|[2505.22913](http://arxiv.org/abs/2505.22913)|null|\n", "2505.22618": "|**2025-07-03**|**Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding**|Chengyue Wu et.al.|[2505.22618](http://arxiv.org/abs/2505.22618)|null|\n", "2505.22425": "|**2025-05-28**|**Scaling Reasoning without Attention**|Xueliang Zhao et.al.|[2505.22425](http://arxiv.org/abs/2505.22425)|null|\n", "2505.22156": "|**2025-05-28**|**InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing**|Shuaiyi Li et.al.|[2505.22156](http://arxiv.org/abs/2505.22156)|null|\n", "2505.21487": "|**2025-05-27**|**Hardware-Efficient Attention for Fast Decoding**|Ted Zadouri et.al.|[2505.21487](http://arxiv.org/abs/2505.21487)|null|\n", "2505.20776": "|**2025-05-27**|**SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences**|Jungyoub Cha et.al.|[2505.20776_(EMNLP)](http://arxiv.org/abs/2505.20776)|null|\n", "2505.20438": "|**2025-05-26**|**HAMburger: Accelerating LLM Inference via Token Smashing**|Jingyu Liu et.al.|[2505.20438](http://arxiv.org/abs/2505.20438)|null|\n", "2505.19586": "|**2025-05-27**|**TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization**|Dingyu Yao et.al.|[2505.19586](http://arxiv.org/abs/2505.19586)|null|\n", "2505.20334": "|**2025-05-24**|**Lookahead Q-Cache: Achieving More Consistent KV Cache Eviction via Pseudo Query**|Yixuan Wang et.al.|[2505.20334](http://arxiv.org/abs/2505.20334)|null|\n", "2505.18610": "|**2025-05-24**|**PM-KVQ: Progressive Mixed-precision KV Cache Quantization for Long-CoT LLMs**|Tengxuan Liu et.al.|[2505.18610](http://arxiv.org/abs/2505.18610)|null|\n", "2505.18458": "|**2025-06-01**|**A Survey of LLM $\\times$ DATA**|Xuanhe Zhou et.al.|[2505.18458](http://arxiv.org/abs/2505.18458)|**[link](https://github.com/weAIDB/awesome-data-llm)**|\n", "2505.20325": "|**2025-05-23**|**Guided by Gut: Efficient Test-Time Scaling with Reinforced Intrinsic Confidence**|Amirhosein Ghasemabadi et.al.|[2505.20325](http://arxiv.org/abs/2505.20325)|null|\n", "2505.18231": "|**2025-05-23**|**NSNQuant: A Double Normalization Approach for Calibration-Free Low-Bit Vector Quantization of KV Cache**|Donghyun Son et.al.|[2505.18231](http://arxiv.org/abs/2505.18231)|null|\n", "2505.17787": "|**2025-05-23**|**Titanus: Enabling KV Cache Pruning and Quantization On-the-Fly for LLM Acceleration**|Peilin Chen et.al.|[2505.17787](http://arxiv.org/abs/2505.17787)|null|\n", "2505.17272": "|**2025-05-22**|**Zebra-Llama: Towards Extremely Efficient Hybrid Models**|Mingyu Yang et.al.|[2505.17272](http://arxiv.org/abs/2505.17272)|null|\n", "2505.16986": "|**2025-05-22**|**T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning**|Amartya Chakraborty et.al.|[2505.16986](http://arxiv.org/abs/2505.16986)|null|\n", "2505.16582": "|**2025-05-26**|**O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering**|Jianbiao Mei et.al.|[2505.16582](http://arxiv.org/abs/2505.16582)|null|\n", "2505.17138": "|**2025-05-26**|**RAP: Runtime-Adaptive Pruning for LLM Inference**|Huanrong Liu et.al.|[2505.17138](http://arxiv.org/abs/2505.17138)|null|\n", "2505.16210": "|**2025-05-22**|**NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics**|Zhihang Cai et.al.|[2505.16210](http://arxiv.org/abs/2505.16210)|null|\n", "2505.16175": "|**2025-05-31**|**QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design**|Benjamin Schneider et.al.|[2505.16175](http://arxiv.org/abs/2505.16175)|null|\n", "2505.16056": "|**2025-05-21**|**Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models**|Jingcong Liang et.al.|[2505.16056](http://arxiv.org/abs/2505.16056)|null|\n", "2505.15793": "|**2025-05-22**|**HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving**|Zhiwen Chen et.al.|[2505.15793](http://arxiv.org/abs/2505.15793)|null|\n", "2505.15684": "|**2025-05-23**|**ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy**|Gengyang Li et.al.|[2505.15684](http://arxiv.org/abs/2505.15684)|null|\n", "2505.15683": "|**2025-05-21**|**A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability**|Zishuai Zhang et.al.|[2505.15683](http://arxiv.org/abs/2505.15683)|null|\n", "2505.15347": "|**2025-05-21**|**FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management**|Xiang Liu et.al.|[2505.15347](http://arxiv.org/abs/2505.15347)|null|\n", "2505.15269": "|**2025-05-21**|**LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval**|Zhenyu Ning et.al.|[2505.15269](http://arxiv.org/abs/2505.15269)|null|\n", "2505.15859": "|**2025-05-21**|**AutoData: A Multi-Agent System for Open Web Data Collection**|Tianyi Ma et.al.|[2505.15859](http://arxiv.org/abs/2505.15859)|null|\n", "2505.14992": "|**2025-05-21**|**Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models**|Zhihao Wen et.al.|[2505.14992](http://arxiv.org/abs/2505.14992)|null|\n", "2505.14427": "|**2025-05-20**|**SkyMemory: A LEO Edge Cache for Transformer Inference Optimization and Scale Out**|Thomas Sandholm et.al.|[2505.14427](http://arxiv.org/abs/2505.14427)|null|\n", "2505.14398": "|**2025-05-20**|**Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation**|Peter Baile Chen et.al.|[2505.14398](http://arxiv.org/abs/2505.14398)|**[link](https://peterbaile.github.io/lag/)**|\n", "2505.14085": "|**2025-05-20**|**CE-LSLM: Efficient Large-Small Language Model Inference and Communication via Cloud-Edge Collaboration**|Pengyan Zhu et.al.|[2505.14085](http://arxiv.org/abs/2505.14085)|null|\n", "2505.13109": "|**2025-05-19**|**FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference**|Guangda Liu et.al.|[2505.13109](http://arxiv.org/abs/2505.13109)|null|\n", "2505.12731": "|**2025-05-25**|**Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps**|Jie Ou et.al.|[2505.12731_(ACL)](http://arxiv.org/abs/2505.12731)|null|\n", "2505.12594": "|**2025-05-19**|**AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection**|Tiankai Yang et.al.|[2505.12594](http://arxiv.org/abs/2505.12594)|null|\n", "2505.12392": "|**2025-05-26**|**SLOT: Sample-specific Language Model Optimization at Test-time**|Yang Hu et.al.|[2505.12392](http://arxiv.org/abs/2505.12392)|null|\n", "2506.08018": "|**2025-05-18**|**KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache**|Fei Li et.al.|[2506.08018](http://arxiv.org/abs/2506.08018)|null|\n", "2505.11271": "|**2025-05-16**|**Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models**|Camille Couturier et.al.|[2505.11271_(CCC)](http://arxiv.org/abs/2505.11271)|null|\n", "2505.10951": "|**2025-05-19**|**SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache**|Qiuyu Zhu et.al.|[2505.10951](http://arxiv.org/abs/2505.10951)|null|\n", "2505.10938": "|**2025-05-16**|**Accurate KV Cache Quantization with Outlier Tokens Tracing**|Yi Su et.al.|[2505.10938_(ACL)](http://arxiv.org/abs/2505.10938)|null|\n", "2505.09081": "|**2025-05-14**|**SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation**|Gaurav Koley et.al.|[2505.09081](http://arxiv.org/abs/2505.09081)|null|\n", "2505.08261": "|**2025-05-13**|**Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration**|Rishabh Agrawal et.al.|[2505.08261](http://arxiv.org/abs/2505.08261)|null|\n", "2505.07680": "|**2025-05-12**|**SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models**|Hang Wu et.al.|[2505.07680](http://arxiv.org/abs/2505.07680)|null|\n", "2505.07274": "|**2025-05-12**|**Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains**|Ibne Farabi Shihab et.al.|[2505.07274](http://arxiv.org/abs/2505.07274)|null|\n", "2505.07239": "|**2025-05-12**|**Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity**|Guang Yan et.al.|[2505.07239](http://arxiv.org/abs/2505.07239)|null|\n", "2505.07203": "|**2025-05-12**|**PrefillOnly: An Inference Engine for Prefill-only Workloads in Large Language Model Applications**|Kuntai Du et.al.|[2505.07203](http://arxiv.org/abs/2505.07203)|null|\n", "2505.06901": "|**2025-05-11**|**Ecco: Improving Memory Bandwidth and Capacity for LLMs via Entropy-aware Cache Compression**|Feng Cheng et.al.|[2505.06901_(ISCA)](http://arxiv.org/abs/2505.06901)|null|\n", "2505.06738": "|**2025-06-15**|**I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference**|Zibo Gao et.al.|[2505.06738](http://arxiv.org/abs/2505.06738)|null|\n", "2505.05772": "|**2025-05-09**|**Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM**|Zehao Fan et.al.|[2505.05772](http://arxiv.org/abs/2505.05772)|null|\n", "2505.02922": "|**2025-06-30**|**RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference**|Yaoqi Chen et.al.|[2505.02922](http://arxiv.org/abs/2505.02922)|null|\n", "2505.02533": "|**2025-05-05**|**Large Language Model Partitioning for Low-Latency Inference at the Edge**|Dimitrios Kafetzis et.al.|[2505.02533](http://arxiv.org/abs/2505.02533)|null|\n", "2505.01658": "|**2025-05-08**|**A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency**|Sihyeong Park et.al.|[2505.01658](http://arxiv.org/abs/2505.01658)|null|\n", "2505.00817": "|**2025-05-01**|**Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models**|Andrew Adiletta et.al.|[2505.00817](http://arxiv.org/abs/2505.00817)|null|\n", "2505.00570": "|**2025-05-19**|**FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension**|Jushi Kai et.al.|[2505.00570](http://arxiv.org/abs/2505.00570)|null|\n", "2504.21228": "|**2025-04-29**|**CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks**|Rui Wang et.al.|[2504.21228](http://arxiv.org/abs/2504.21228)|null|\n", "2504.19867": "|**2025-04-28**|**semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage**|Ke Hong et.al.|[2504.19867](http://arxiv.org/abs/2504.19867)|null|\n", "2504.17584": "|**2025-04-24**|**L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference**|Qingyuan Liu et.al.|[2504.17584](http://arxiv.org/abs/2504.17584)|null|\n", "2504.15720": "|**2025-04-22**|**SeaLLM: Service-Aware and Latency-Optimized Resource Sharing for Large Language Model Inference**|Yihao Zhao et.al.|[2504.15720](http://arxiv.org/abs/2504.15720)|null|\n", "2504.15364": "|**2025-05-20**|**KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments**|Junyoung Park et.al.|[2504.15364](http://arxiv.org/abs/2504.15364)|null|\n", "2505.03763": "|**2025-04-21**|**Splitwiser: Efficient LM inference with constrained resources**|Asad Aali et.al.|[2505.03763](http://arxiv.org/abs/2505.03763)|null|\n", "2504.14775": "|**2025-05-28**|**gLLM: Global Balanced Pipeline Parallelism System for Distributed LLM Serving with Token Throttling**|Tianyu Guo et.al.|[2504.14775](http://arxiv.org/abs/2504.14775)|null|\n", "2504.14489": "|**2025-04-22**|**Optimizing SLO-oriented LLM Serving with PD-Multiplexing**|Weihao Cui et.al.|[2504.14489](http://arxiv.org/abs/2504.14489)|null|\n", "2505.03756": "|**2025-04-19**|**Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management**|Hang Zhang et.al.|[2505.03756](http://arxiv.org/abs/2505.03756)|null|\n", "2504.11816": "|**2025-04-16**|**Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache Offloading**|Kihyun Kim et.al.|[2504.11816](http://arxiv.org/abs/2504.11816)|null|\n", "2504.09775": "|**2025-04-20**|**Understanding and Optimizing Multi-Stage AI Inference Pipelines**|Abhimanyu Rajeshkumar Bambhaniya et.al.|[2504.09775](http://arxiv.org/abs/2504.09775)|null|\n", "2504.09590": "|**2025-04-13**|**Efficient LLM Serving on Hybrid Real-time and Best-effort Requests**|Wan Borui et.al.|[2504.09590](http://arxiv.org/abs/2504.09590)|null|\n", "2504.07494": "|**2025-04-10**|**Apt-Serve: Adaptive Request Scheduling on Hybrid Cache for Scalable LLM Inference Serving**|Shihong Gao et.al.|[2504.07494](http://arxiv.org/abs/2504.07494)|null|\n", "2503.24000": "|**2025-03-31**|**Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving**|Wei Gao et.al.|[2503.24000](http://arxiv.org/abs/2503.24000)|null|\n", "2503.18599": "|**2025-05-14**|**Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization**|Minsu Kim et.al.|[2503.18599](http://arxiv.org/abs/2503.18599)|null|\n", "2503.18292": "|**2025-03-24**|**Jenga: Effective Memory Management for Serving LLM with Heterogeneity**|Chen Zhang et.al.|[2503.18292](http://arxiv.org/abs/2503.18292)|null|\n", "2503.13773": "|**2025-03-24**|**Mitigating KV Cache Competition to Enhance User Experience in LLM Inference**|Haiying Shen et.al.|[2503.13773](http://arxiv.org/abs/2503.13773)|null|\n", "2503.13737": "|**2025-03-17**|**AccelGen: Heterogeneous SLO-Guaranteed High-Throughput LLM Inference Serving for Diverse Applications**|Haiying Shen et.al.|[2503.13737](http://arxiv.org/abs/2503.13737)|null|\n", "2503.16525": "|**2025-05-16**|**KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse**|Huan Yang et.al.|[2503.16525](http://arxiv.org/abs/2503.16525)|null|\n", "2503.08461": "|**2025-03-11**|**FastCache: Optimizing Multimodal LLM Serving through Lightweight KV-Cache Compression Framework**|Jianian Zhu et.al.|[2503.08461](http://arxiv.org/abs/2503.08461)|null|\n", "2503.01330": "|**2025-03-03**|**WeightedKV: Attention Scores Weighted Key-Value Cache Merging for Large Language Models**|Jian Yuan et.al.|[2503.01330_(ICASSP)](http://arxiv.org/abs/2503.01330)|null|\n", "2503.00392": "|**2025-03-01**|**Progressive Sparse Attention: Algorithm and System Co-design for Efficient Attention in LLM Serving**|Qihui Zhou et.al.|[2503.00392](http://arxiv.org/abs/2503.00392)|null|\n", "2502.20330": "|**2025-06-23**|**RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding**|Guanzheng Chen et.al.|[2502.20330_(ICML)](http://arxiv.org/abs/2502.20330)|null|\n", "2502.17606": "|**2025-02-24**|**ELMo-Tune-V2: LLM-Assisted Full-Cycle Auto-Tuning to Optimize LSM-Based Key-Value Stores**|Viraj Thakkar et.al.|[2502.17606](http://arxiv.org/abs/2502.17606)|null|\n", "2504.03648": "|**2025-02-22**|**AIBrix: Towards Scalable, Cost-Effective Large Language Model Inference Infrastructure**|The AIBrix Team et.al.|[2504.03648](http://arxiv.org/abs/2504.03648)|null|\n", "2502.15294": "|**2025-06-27**|**Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference**|Yaohua Tang et.al.|[2502.15294](http://arxiv.org/abs/2502.15294)|null|\n", "2502.14866": "|**2025-04-21**|**LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention**|Shang Yang et.al.|[2502.14866](http://arxiv.org/abs/2502.14866)|**[link](https://github.com/mit-han-lab/omniserve)**|\n", "2502.12665": "|**2025-06-03**|**A$^2$ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization**|Junhui He et.al.|[2502.12665](http://arxiv.org/abs/2502.12665)|null|\n", "2502.07903": "|**2025-02-11**|**HexGen-2: Disaggregated Generative Inference of LLMs in Heterogeneous Environment**|Youhe Jiang et.al.|[2502.07903_(ICLR)](http://arxiv.org/abs/2502.07903)|null|\n", "2502.05370": "|**2025-02-07**|**fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving**|Hanfei Yu et.al.|[2502.05370](http://arxiv.org/abs/2502.05370)|null|\n", "2502.02818": "|**2025-02-05**|**Accessible and Portable LLM Inference by Compiling Computational Graphs into SQL**|Wenbo Sun et.al.|[2502.02818](http://arxiv.org/abs/2502.02818)|null|\n", "2501.14312": "|**2025-01-24**|**Locality-aware Fair Scheduling in LLM Serving**|Shiyi Cao et.al.|[2501.14312](http://arxiv.org/abs/2501.14312)|null|\n", "2501.14205": "|**2025-01-24**|**Serving Long-Context LLMs at the Mobile Edge: Test-Time Reinforcement Learning-based Model Caching and Inference Offloading**|Minrui Xu et.al.|[2501.14205](http://arxiv.org/abs/2501.14205)|null|\n", "2501.12689": "|**2025-01-24**|**EchoLM: Accelerating LLM Serving with Real-time Knowledge Distillation**|Yifan Yu et.al.|[2501.12689](http://arxiv.org/abs/2501.12689)|null|\n", "2501.08192": "|**2025-05-26**|**PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving**|Ahmet Caner Y\u00fcz\u00fcg\u00fcler et.al.|[2501.08192](http://arxiv.org/abs/2501.08192)|null|\n", "2501.06709": "|**2025-01-12**|**Mell: Memory-Efficient Large Language Model Serving via Multi-GPU KV Cache Management**|Liu Qianli et.al.|[2501.06709](http://arxiv.org/abs/2501.06709)|null|\n", "2501.04052": "|**2025-01-06**|**The Power of Negative Zero: Datatype Customization for Quantized Large Language Models**|Yuzong Chen et.al.|[2501.04052_(ISS)](http://arxiv.org/abs/2501.04052)|null|\n", "2501.01005": "|**2025-04-21**|**FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving**|Zihao Ye et.al.|[2501.01005](http://arxiv.org/abs/2501.01005)|**[link](http://github.com/flashinfer-ai/flashinfer)**|\n", "2501.05460": "|**2025-06-28**|**Efficiently Serving Large Multimodal Models Using EPD Disaggregation**|Gursimran Singh et.al.|[2501.05460](http://arxiv.org/abs/2501.05460)|null|\n", "2412.16434": "|**2024-12-21**|**SYMPHONY: Improving Memory Management for LLM Inference Workloads**|Saurabh Agarwal et.al.|[2412.16434](http://arxiv.org/abs/2412.16434)|null|\n", "2412.12488": "|**2024-12-17**|**A System for Microserving of LLMs**|Hongyi Jin et.al.|[2412.12488](http://arxiv.org/abs/2412.12488)|null|\n", "2412.11741": "|**2024-12-16**|**CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation**|Hongxuan Zhang et.al.|[2412.11741](http://arxiv.org/abs/2412.11741)|null|\n", "2412.03131": "|**2025-04-08**|**Unifying KV Cache Compression for Large Language Models with LeanKV**|Yanqi Zhang et.al.|[2412.03131](http://arxiv.org/abs/2412.03131)|null|\n", "2412.01253": "|**2025-01-22**|**Yi-Lightning Technical Report**|Alan Wake et.al.|[2412.01253](http://arxiv.org/abs/2412.01253)|null|\n", "2411.19379": "|**2025-04-10**|**Marconi: Prefix Caching for the Era of Hybrid LLMs**|Rui Pan et.al.|[2411.19379](http://arxiv.org/abs/2411.19379)|null|\n", "2411.18424": "|**2024-11-27**|**FastSwitch: Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving**|Ao Shen et.al.|[2411.18424](http://arxiv.org/abs/2411.18424)|null|\n", "2411.18077": "|**2025-06-08**|**MiniKV: Pushing the Limits of LLM Inference via 2-Bit Layer-Discriminative KV Cache**|Akshat Sharma et.al.|[2411.18077](http://arxiv.org/abs/2411.18077)|null|\n", "2411.17741": "|**2024-11-24**|**Chameleon: Adaptive Caching and Scheduling for Many-Adapter LLM Inference Environments**|Nikoleta Iliakopoulou et.al.|[2411.17741](http://arxiv.org/abs/2411.17741)|null|\n", "2411.13820": "|**2025-07-14**|**InstCache: A Predictive Cache for LLM Serving**|Longwei Zou et.al.|[2411.13820](http://arxiv.org/abs/2411.13820)|null|\n", "2411.06364": "|**2025-03-24**|**EconoServe: Maximizing Multi-Resource Utilization with SLO Guarantees in LLM Serving**|Haiying Shen et.al.|[2411.06364](http://arxiv.org/abs/2411.06364)|null|\n", "2411.02820": "|**2025-07-14**|**DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving**|Yuhan Liu et.al.|[2411.02820](http://arxiv.org/abs/2411.02820)|null|\n", "2410.23537": "|**2024-10-31**|**ALISE: Accelerating Large Language Model Serving with Speculative Scheduling**|Youpeng Zhao et.al.|[2410.23537_(ICC)](http://arxiv.org/abs/2410.23537)|null|\n", "2410.22134": "|**2025-02-08**|**ProMoE: Fast MoE-based LLM Serving using Proactive Caching**|Xiaoniu Song et.al.|[2410.22134](http://arxiv.org/abs/2410.22134)|null|\n", "2410.21465": "|**2025-04-25**|**ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference**|Hanshi Sun et.al.|[2410.21465](http://arxiv.org/abs/2410.21465)|null|\n", "2410.16179": "|**2024-12-18**|**MagicPIG: LSH Sampling for Efficient LLM Generation**|Zhuoming Chen et.al.|[2410.16179](http://arxiv.org/abs/2410.16179)|null|\n", "2410.15332": "|**2025-05-27**|**EPIC: Efficient Position-Independent Caching for Serving Large Language Models**|Junhao Hu et.al.|[2410.15332](http://arxiv.org/abs/2410.15332)|null|\n", "2410.14740": "|**2024-10-23**|**Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching**|Jie Peng et.al.|[2410.14740](http://arxiv.org/abs/2410.14740)|null|\n", "2410.12168": "|**2024-10-16**|**COMET: Towards Partical W4A4KV4 LLMs Serving**|Lian Liu et.al.|[2410.12168](http://arxiv.org/abs/2410.12168)|null|\n", "2410.11305": "|**2025-02-01**|**QSpec: Speculative Decoding with Complementary Quantization Schemes**|Juntao Zhao et.al.|[2410.11305](http://arxiv.org/abs/2410.11305)|null|\n", "2410.05004": "|**2024-10-07**|**Fast State Restoration in LLM Serving with HCache**|Shiwei Gao et.al.|[2410.05004_(EuroSys)](http://arxiv.org/abs/2410.05004)|null|\n", "2410.03960": "|**2025-06-02**|**SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation**|Aurick Qiao et.al.|[2410.03960](http://arxiv.org/abs/2410.03960)|null|\n", "2410.03111": "|**2024-10-04**|**LoRC: Low-Rank Compression for LLMs KV Cache with a Progressive Compression Strategy**|Rongzhi Zhang et.al.|[2410.03111](http://arxiv.org/abs/2410.03111)|null|\n", "2410.01485": "|**2024-12-05**|**A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts**|Suyu Ge et.al.|[2410.01485](http://arxiv.org/abs/2410.01485)|null|\n", "2410.00428": "|**2024-10-09**|**LayerKV: Optimizing Large Language Model Serving with Layer-wise KV Cache Management**|Yi Xiong et.al.|[2410.00428](http://arxiv.org/abs/2410.00428)|null|\n", "2410.00161": "|**2024-10-07**|**KV-Compress: Paged KV-Cache Compression with Variable Compression Rates per Attention Head**|Isaac Rehg et.al.|[2410.00161](http://arxiv.org/abs/2410.00161)|null|\n", "2409.20002": "|**2025-02-12**|**The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems**|Linke Song et.al.|[2409.20002_(DATE)](http://arxiv.org/abs/2409.20002)|null|\n", "2409.17264": "|**2025-06-18**|**Medha: Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations**|Amey Agrawal et.al.|[2409.17264](http://arxiv.org/abs/2409.17264)|null|\n", "2409.15441": "|**2024-09-23**|**Steward: Natural Language Web Automation**|Brian Tang et.al.|[2409.15441](http://arxiv.org/abs/2409.15441)|null|\n", "2409.13761": "|**2024-10-21**|**Do Large Language Models Need a Content Delivery Network?**|Yihua Cheng et.al.|[2409.13761](http://arxiv.org/abs/2409.13761)|null|\n", "2409.10516": "|**2024-12-31**|**RetrievalAttention: Accelerating Long-Context LLM Inference via Vector Retrieval**|Di Liu et.al.|[2409.10516](http://arxiv.org/abs/2409.10516)|null|\n", "2408.11049": "|**2025-04-02**|**MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**|Ranajoy Sadhukhan et.al.|[2408.11049](http://arxiv.org/abs/2408.11049)|null|\n", "2408.05235": "|**2024-08-05**|**SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving**|Andreas Kosmas Kakolyris et.al.|[2408.05235](http://arxiv.org/abs/2408.05235)|null|\n", "2407.15309": "|**2024-07-22**|**vTensor: Flexible Virtual Tensor Management for Efficient LLM Serving**|Jiale Xu et.al.|[2407.15309](http://arxiv.org/abs/2407.15309)|null|\n", "2407.08454": "|**2024-07-21**|**Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks**|Zheng Wang et.al.|[2407.08454](http://arxiv.org/abs/2407.08454)|null|\n", "2407.12820": "|**2025-03-30**|**PQCache: Product Quantization-based KVCache for Long Context LLM Inference**|Hailin Zhang et.al.|[2407.12820](http://arxiv.org/abs/2407.12820)|null|\n", "2406.19707": "|**2024-06-28**|**InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management**|Wonbeom Lee et.al.|[2406.19707_(OSDI)](http://arxiv.org/abs/2406.19707)|null|\n", "2406.17565": "|**2024-12-21**|**MemServe: Context Caching for Disaggregated LLM Serving with Elastic Memory Pool**|Cunchen Hu et.al.|[2406.17565](http://arxiv.org/abs/2406.17565)|null|\n", "2407.00079": "|**2024-07-09**|**Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving**|Ruoyu Qin et.al.|[2407.00079](http://arxiv.org/abs/2407.00079)|null|\n", "2406.09827": "|**2025-01-23**|**A Training-free Sub-quadratic Cost Transformer Model Serving Framework With Hierarchically Pruned Attention**|Heejun Lee et.al.|[2406.09827](http://arxiv.org/abs/2406.09827)|null|\n", "2406.06282": "|**2024-12-12**|**PowerInfer-2: Fast Large Language Model Inference on a Smartphone**|Zhenliang Xue et.al.|[2406.06282](http://arxiv.org/abs/2406.06282)|null|\n", "2406.10247": "|**2024-06-08**|**QCQA: Quality and Capacity-aware grouped Query Attention**|Vinay Joshi et.al.|[2406.10247](http://arxiv.org/abs/2406.10247)|null|\n", "2406.03482": "|**2024-07-18**|**QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead**|Amir Zandieh et.al.|[2406.03482](http://arxiv.org/abs/2406.03482)|null|\n", "2405.16444": "|**2025-04-03**|**CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion**|Jiayi Yao et.al.|[2405.16444](http://arxiv.org/abs/2405.16444)|null|\n", "2407.00023": "|**2024-10-03**|**Preble: Efficient Distributed Prompt Scheduling for LLM Serving**|Vikranth Srivatsa et.al.|[2407.00023](http://arxiv.org/abs/2407.00023)|null|\n", "2405.04532": "|**2025-05-01**|**QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**|Yujun Lin et.al.|[2405.04532](http://arxiv.org/abs/2405.04532)|**[link](https://github.com/mit-han-lab/omniserve)**|\n", "2405.04437": "|**2025-01-29**|**vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention**|Ramya Prabhu et.al.|[2405.04437_(ASPLOS)](http://arxiv.org/abs/2405.04437)|null|\n", "2404.18322": "|**2024-09-23**|**BlockLLM: Multi-tenant Finer-grained Serving for Large Language Models**|Bodun Hu et.al.|[2404.18322](http://arxiv.org/abs/2404.18322)|null|\n", "2404.11912": "|**2024-08-04**|**TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding**|Hanshi Sun et.al.|[2404.11912](http://arxiv.org/abs/2404.11912)|null|\n", "2404.09529": "|**2024-04-15**|**Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models**|Siyan Zhao et.al.|[2404.09529](http://arxiv.org/abs/2404.09529)|**[link](https://github.com/siyan-zhao/prepacking)**|\n", "2404.09526": "|**2024-10-29**|**LoongServe: Efficiently Serving Long-Context Large Language Models with Elastic Sequence Parallelism**|Bingyang Wu et.al.|[2404.09526](http://arxiv.org/abs/2404.09526)|null|\n", "2403.19708": "|**2024-06-30**|**Cost-Efficient Large Language Model Serving for Multi-turn Conversations with CachedAttention**|Bin Gao et.al.|[2403.19708_(ATC)](http://arxiv.org/abs/2403.19708)|null|\n", "2504.14089": "|**2025-04-18**|**LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models**|Kang He et.al.|[2504.14089](http://arxiv.org/abs/2504.14089)|null|\n", "2504.13989": "|**2025-05-13**|**Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs**|Lucas Maisonnave et.al.|[2504.13989](http://arxiv.org/abs/2504.13989)|null|\n", "2504.16112": "|**2025-04-18**|**HPU: High-Bandwidth Processing Unit for Scalable, Cost-effective LLM Inference via GPU Co-processing**|Myunghyun Rhee et.al.|[2504.16112](http://arxiv.org/abs/2504.16112)|null|\n", "2504.12397": "|**2025-06-10**|**Activated LoRA: Fine-tuned LLMs for Intrinsics**|Kristjan Greenewald et.al.|[2504.12397](http://arxiv.org/abs/2504.12397)|null|\n", "2504.11765": "|**2025-04-16**|**Shared Disk KV Cache Management for Efficient Multi-Instance Inference in RAG-Powered LLMs**|Hyungwoo Lee et.al.|[2504.11765](http://arxiv.org/abs/2504.11765)|null|\n", "2504.11320": "|**2025-04-15**|**Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints**|Ruicheng Ao et.al.|[2504.11320](http://arxiv.org/abs/2504.11320)|null|\n", "2504.10326": "|**2025-04-14**|**AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference**|Yangshen Deng et.al.|[2504.10326](http://arxiv.org/abs/2504.10326)|null|\n", "2504.09936": "|**2025-04-14**|**KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference**|Yuxuan Tian et.al.|[2504.09936](http://arxiv.org/abs/2504.09936)|null|\n", "2504.08378": "|**2025-04-11**|**Scaling Up On-Device LLMs via Active-Weight Swapping Between DRAM and Flash**|Fucheng Jia et.al.|[2504.08378](http://arxiv.org/abs/2504.08378)|null|\n", "2504.07479": "|**2025-04-10**|**UniCAIM: A Unified CAM/CIM Architecture with Static-Dynamic KV Cache Pruning for Efficient Long-Context LLM Inference**|Weikai Xu et.al.|[2504.07479](http://arxiv.org/abs/2504.07479)|null|\n", "2504.06419": "|**2025-04-08**|**SPIRe: Boosting LLM Inference Throughput with Speculative Decoding**|Sanjit Neelam et.al.|[2504.06419](http://arxiv.org/abs/2504.06419)|null|\n", "2504.06261": "|**2025-05-23**|**Hogwild! Inference: Parallel LLM Generation via Concurrent Attention**|Gleb Rodionov et.al.|[2504.06261](http://arxiv.org/abs/2504.06261)|null|\n", "2504.05897": "|**2025-04-08**|**HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference**|Shuzhang Zhong et.al.|[2504.05897_(DAC)](http://arxiv.org/abs/2504.05897)|null|\n", "2504.06319": "|**2025-04-08**|**Accelerating LLM Inference Throughput via Asynchronous KV Cache Prefetching**|Yanhao Dong et.al.|[2504.06319](http://arxiv.org/abs/2504.06319)|null|\n", "2505.03745": "|**2025-04-07**|**AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design**|Yanbiao Liang et.al.|[2505.03745](http://arxiv.org/abs/2505.03745)|null|\n", "2504.04514": "|**2025-04-09**|**Saliency-driven Dynamic Token Pruning for Large Language Models**|Yao Tao et.al.|[2504.04514](http://arxiv.org/abs/2504.04514)|null|\n", "2504.02921": "|**2025-04-03**|**HyperRAG: Enhancing Quality-Efficiency Tradeoffs in Retrieval-Augmented Generation with Reranker KV-Cache Reuse**|Yuwei An et.al.|[2504.02921](http://arxiv.org/abs/2504.02921)|null|\n", "2504.01281": "|**2025-05-20**|**Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding**|Sakhinana Sagar Srinivas et.al.|[2504.01281](http://arxiv.org/abs/2504.01281)|null|\n", "2504.00970": "|**2025-04-01**|**SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching**|Yuxuan Zhu et.al.|[2504.00970](http://arxiv.org/abs/2504.00970)|null|\n", "2503.23294": "|**2025-03-30**|**Cocktail: Chunk-Adaptive Mixed-Precision Quantization for Long-Context LLM Inference**|Wei Tao et.al.|[2503.23294_(DATE)](http://arxiv.org/abs/2503.23294)|null|\n", "2504.03708": "|**2025-03-27**|**Solving AI Foundational Model Latency with Telco Infrastructure**|Sebastian Barros et.al.|[2504.03708](http://arxiv.org/abs/2504.03708)|null|\n", "2503.19950": "|**2025-03-25**|**LogQuant: Log-Distributed 2-Bit Quantization of KV Cache with Superior Accuracy Preservation**|Han Chen et.al.|[2503.19950_(ICLR)](http://arxiv.org/abs/2503.19950)|null|\n", "2503.18893": "|**2025-03-24**|**xKV: Cross-Layer SVD for KV-Cache Compression**|Chi-Chih Chang et.al.|[2503.18893](http://arxiv.org/abs/2503.18893)|null|\n", "2503.18869": "|**2025-04-21**|**Reimagining Memory Access for LLM Inference: Compression-Aware Memory Controller Design**|Rui Xie et.al.|[2503.18869](http://arxiv.org/abs/2503.18869)|null|\n", "2503.17922": "|**2025-03-27**|**WindowKV: Task-Adaptive Group-Wise KV Cache Window Selection for Efficient LLM Inference**|Youhui Zuo et.al.|[2503.17922](http://arxiv.org/abs/2503.17922)|null|\n", "2503.16257": "|**2025-03-20**|**Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models**|Keda Tao et.al.|[2503.16257](http://arxiv.org/abs/2503.16257)|null|\n", "2503.16163": "|**2025-03-20**|**SpeCache: Speculative Key-Value Caching for Efficient Generation of LLMs**|Shibo Jie et.al.|[2503.16163](http://arxiv.org/abs/2503.16163)|null|\n", "2503.12491": "|**2025-03-16**|**CAKE: Cascading and Adaptive KV Cache Eviction with Layer Preferences**|Ziran Qin et.al.|[2503.12491_(ICLR)](http://arxiv.org/abs/2503.12491)|null|\n", "2506.14731": "|**2025-06-18**|**Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs**|Ling Team et.al.|[2506.14731](http://arxiv.org/abs/2506.14731)|null|\n", "2506.14683": "|**2025-06-17**|**Unified Software Engineering agent as AI Software Engineer**|Leonhard Applis et.al.|[2506.14683](http://arxiv.org/abs/2506.14683)|null|\n", "2506.14681": "|**2025-06-17**|**Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality**|Yuto Harada et.al.|[2506.14681](http://arxiv.org/abs/2506.14681)|null|\n", "2506.14641": "|**2025-06-17**|**Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot**|Xiang Cheng et.al.|[2506.14641](http://arxiv.org/abs/2506.14641)|null|\n", "2506.14634": "|**2025-06-18**|**AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation**|Leah von der Heyde et.al.|[2506.14634](http://arxiv.org/abs/2506.14634)|null|\n", "2506.14625": "|**2025-06-18**|**Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models**|Chenchen Yuan et.al.|[2506.14625](http://arxiv.org/abs/2506.14625)|**[link](https://github.com/yuanchencn/collective-moral-reasoning)**|\n", "2506.14589": "|**2025-06-17**|**NetRoller: Interfacing General and Specialized Models for End-to-End Autonomous Driving**|Ren Xin et.al.|[2506.14589](http://arxiv.org/abs/2506.14589)|**[link](https://github.com/rex-sys-hk/netroller)**|\n", "2506.14535": "|**2025-06-17**|**Automatic Qiskit Code Refactoring Using Large Language Models**|Jos\u00e9 Manuel Su\u00e1rez et.al.|[2506.14535](http://arxiv.org/abs/2506.14535)|null|\n", "2506.14532": "|**2025-06-17**|**M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models**|Can Zheng et.al.|[2506.14532](http://arxiv.org/abs/2506.14532)|null|\n", "2506.14512": "|**2025-06-17**|**SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks**|Zijian Song et.al.|[2506.14512](http://arxiv.org/abs/2506.14512)|null|\n", "2506.14496": "|**2025-06-17**|**LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?**|Muhammad Atta Ur Rahman et.al.|[2506.14496](http://arxiv.org/abs/2506.14496)|null|\n", "2506.14448": "|**2025-06-17**|**How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison**|Jiayin Wang et.al.|[2506.14448](http://arxiv.org/abs/2506.14448)|**[link](https://github.com/alice1998/test-time-leaning)**|\n", "2506.14374": "|**2025-06-17**|**Excessive Reasoning Attack on Reasoning LLMs**|Wai Man Si et.al.|[2506.14374](http://arxiv.org/abs/2506.14374)|null|\n", "2506.14371": "|**2025-06-17**|**ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection**|Lucile Favero et.al.|[2506.14371](http://arxiv.org/abs/2506.14371)|null|\n", "2506.14345": "|**2025-06-17**|**A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis**|Bruno Martins et.al.|[2506.14345](http://arxiv.org/abs/2506.14345)|null|\n", "2506.14299": "|**2025-06-17**|**ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems**|Fanzhi Zeng et.al.|[2506.14299](http://arxiv.org/abs/2506.14299)|null|\n", "2506.14288": "|**2025-06-17**|**Large Language Model Empowered Design of Fluid Antenna Systems: Challenges, Frameworks, and Case Studies for 6G**|Chao Wang et.al.|[2506.14288](http://arxiv.org/abs/2506.14288)|null|\n", "2506.14280": "|**2025-06-17**|**Improving LoRA with Variational Learning**|Bai Cong et.al.|[2506.14280](http://arxiv.org/abs/2506.14280)|null|\n", "2506.14276": "|**2025-06-17**|**Don't throw the baby out with the bathwater: How and why deep learning for ARC**|Jack Cole et.al.|[2506.14276](http://arxiv.org/abs/2506.14276)|null|\n", "2506.14248": "|**2025-06-17**|**Re-Initialization Token Learning for Tool-Augmented Large Language Models**|Chenghao Li et.al.|[2506.14248](http://arxiv.org/abs/2506.14248)|**[link](https://github.com/lichenghaobuaa/tokenlearning)**|\n", "2506.14245": "|**2025-06-17**|**Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs**|Xumeng Wen et.al.|[2506.14245](http://arxiv.org/abs/2506.14245)|null|\n", "2506.14239": "|**2025-06-17**|**Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?**|Louis Vervoort et.al.|[2506.14239](http://arxiv.org/abs/2506.14239)|null|\n", "2506.14234": "|**2025-06-17**|**Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team**|Md Tanzib Hosain et.al.|[2506.14234](http://arxiv.org/abs/2506.14234)|null|\n", "2506.14161": "|**2025-06-17**|**MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind**|Yanlin Li et.al.|[2506.14161](http://arxiv.org/abs/2506.14161)|null|\n", "2506.14158": "|**2025-06-17**|**S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models**|Tao He et.al.|[2506.14158](http://arxiv.org/abs/2506.14158)|null|\n", "2506.14086": "|**2025-06-17**|**InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking**|Rahul Seetharaman et.al.|[2506.14086](http://arxiv.org/abs/2506.14086)|null|\n", "2506.14028": "|**2025-06-19**|**MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation**|Xueqing Peng et.al.|[2506.14028](http://arxiv.org/abs/2506.14028)|null|\n", "2506.14012": "|**2025-06-16**|**Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text**|Amr Mohamed et.al.|[2506.14012](http://arxiv.org/abs/2506.14012)|**[link](https://github.com/amr-mohamedd/lost-in-the-mix)**|\n", "2506.13996": "|**2025-06-16**|**Arctic Long Sequence Training: Scalable And Efficient Training For Multi-Million Token Sequences**|Stas Bekman et.al.|[2506.13996](http://arxiv.org/abs/2506.13996)|**[link](https://github.com/snowflakedb/ArcticTraining)**|\n", "2506.13932": "|**2025-06-16**|**How Does LLM Reasoning Work for Code? A Survey and a Call to Action**|Ira Ceka et.al.|[2506.13932](http://arxiv.org/abs/2506.13932)|null|\n", "2506.13905": "|**2025-06-16**|**Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems**|Zhongzhi Yu et.al.|[2506.13905](http://arxiv.org/abs/2506.13905)|null|\n", "2506.13886": "|**2025-06-16**|**Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles**|Antara Raaghavi Bhattacharya et.al.|[2506.13886](http://arxiv.org/abs/2506.13886)|null|\n", "2506.13692": "|**2025-06-16**|**Balancing Knowledge Delivery and Emotional Comfort in Healthcare Conversational Systems**|Shang-Chi Tsai et.al.|[2506.13692](http://arxiv.org/abs/2506.13692)|null|\n", "2506.13685": "|**2025-06-16**|**An LLM's Apology: Outsourcing Awkwardness in the Age of AI**|Twm Stone et.al.|[2506.13685](http://arxiv.org/abs/2506.13685)|**[link](https://github.com/cloakless/flake-bench)**|\n", "2506.13841": "|**2025-06-16**|**LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning**|Miho Koda et.al.|[2506.13841](http://arxiv.org/abs/2506.13841)|**[link](https://github.com/miho-koda/locationreasoner)**|\n", "2506.13641": "|**2025-06-16**|**EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs**|Bohao Yang et.al.|[2506.13641](http://arxiv.org/abs/2506.13641)|**[link](https://github.com/bernard-yang/evolvtrip)**|\n", "2506.13639": "|**2025-06-16**|**An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability**|Yusuke Yamauchi et.al.|[2506.13639](http://arxiv.org/abs/2506.13639)|null|\n", "2506.13629": "|**2025-06-16**|**FreeQ-Graph: Free-form Querying with Semantic Consistent Scene Graph for 3D Scene Understanding**|Chenlu Zhan et.al.|[2506.13629](http://arxiv.org/abs/2506.13629)|null|\n", "2506.13599": "|**2025-06-16**|**CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation**|Yuwei Du et.al.|[2506.13599](http://arxiv.org/abs/2506.13599)|null|\n", "2506.13559": "|**2025-06-16**|**Understand the Implication: Learning to Think for Pragmatic Understanding**|Settaluri Lakshmi Sravanthi et.al.|[2506.13559](http://arxiv.org/abs/2506.13559)|null|\n", "2506.13525": "|**2025-06-16**|**Implicit and Explicit Research Quality Score Probabilities from ChatGPT**|Mike Thelwall et.al.|[2506.13525](http://arxiv.org/abs/2506.13525)|null|\n", "2506.13502": "|**2025-06-16**|**BOW: Bottlenecked Next Word Exploration**|Ming Shen et.al.|[2506.13502](http://arxiv.org/abs/2506.13502)|null|\n", "2506.13464": "|**2025-06-16**|**Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study**|Zhengyu Hu et.al.|[2506.13464](http://arxiv.org/abs/2506.13464)|null|\n", "2506.13434": "|**2025-06-16**|**From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs**|Alsharif Abuadbba et.al.|[2506.13434](http://arxiv.org/abs/2506.13434)|null|\n", "2506.13405": "|**2025-06-16**|**RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis**|Pengzuo Wu et.al.|[2506.13405](http://arxiv.org/abs/2506.13405)|null|\n", "2506.13380": "|**2025-06-16**|**Decompositional Reasoning for Graph Retrieval with Large Language Models**|Valentin Six et.al.|[2506.13380](http://arxiv.org/abs/2506.13380)|null|\n", "2506.13358": "|**2025-06-16**|**Socratic RL: A Novel Framework for Efficient Knowledge Acquisition through Iterative Reflection and Viewpoint Distillation**|Xiangfan Wu et.al.|[2506.13358](http://arxiv.org/abs/2506.13358)|null|\n", "2506.13356": "|**2025-06-16**|**StoryBench: A Dynamic Benchmark for Evaluating Long-Term Memory with Multi Turns**|Luanbo Wan et.al.|[2506.13356](http://arxiv.org/abs/2506.13356)|null|\n", "2506.13351": "|**2025-06-16**|**Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks**|Yifei Xu et.al.|[2506.13351](http://arxiv.org/abs/2506.13351)|null|\n", "2506.13342": "|**2025-06-16**|**Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers**|Wooseok Seo et.al.|[2506.13342](http://arxiv.org/abs/2506.13342)|**[link](https://github.com/just1nseo/verifying-the-verifiers)**|\n", "2506.13324": "|**2025-06-16**|**Towards Pervasive Distributed Agentic Generative AI -- A State of The Art**|Gianni Molinari et.al.|[2506.13324](http://arxiv.org/abs/2506.13324)|null|\n", "2506.13206": "|**2025-06-16**|**Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models**|James Chua et.al.|[2506.13206](http://arxiv.org/abs/2506.13206)|null|\n", "2506.13192": "|**2025-06-16**|**Breaking Thought Patterns: A Multi-Dimensional Reasoning Framework for LLMs**|Xintong Tang et.al.|[2506.13192](http://arxiv.org/abs/2506.13192)|null|\n", "2506.13178": "|**2025-06-16**|**Enhancing Large Language Models with Reliable Knowledge Graphs**|Qinggang Zhang et.al.|[2506.13178](http://arxiv.org/abs/2506.13178)|null|\n", "2506.13172": "|**2025-06-17**|**AI-Facilitated Analysis of Abstracts and Conclusions: Flagging Unsubstantiated Claims and Ambiguous Pronouns**|Evgeny Markhasin et.al.|[2506.13172](http://arxiv.org/abs/2506.13172)|null|\n", "2506.13102": "|**2025-06-16**|**Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs**|Gyutaek Oh et.al.|[2506.13102](http://arxiv.org/abs/2506.13102)|null|\n", "2506.13082": "|**2025-06-16**|**Discerning What Matters: A Multi-Dimensional Assessment of Moral Competence in LLMs**|Daniel Kilov et.al.|[2506.13082](http://arxiv.org/abs/2506.13082)|null|\n", "2506.13065": "|**2025-06-16**|**MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?**|Xixian Yong et.al.|[2506.13065](http://arxiv.org/abs/2506.13065)|null|\n", "2506.13056": "|**2025-06-16**|**Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning**|Haibo Qiu et.al.|[2506.13056](http://arxiv.org/abs/2506.13056)|null|\n", "2506.13044": "|**2025-06-16**|**Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models**|Muhammad Reza Qorib et.al.|[2506.13044](http://arxiv.org/abs/2506.13044)|null|\n", "2506.13026": "|**2025-06-16**|**Knowledge Graph Fusion with Large Language Models for Accurate, Explainable Manufacturing Process Planning**|Danny Hoang et.al.|[2506.13026](http://arxiv.org/abs/2506.13026)|null|\n", "2506.12992": "|**2025-06-15**|**SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models**|Xinyi Zhao et.al.|[2506.12992](http://arxiv.org/abs/2506.12992)|**[link](https://github.com/xinyi-0724/smarthome-bench-llm)**|\n", "2506.12978": "|**2025-06-15**|**Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation**|Yuanyuan Lei et.al.|[2506.12978](http://arxiv.org/abs/2506.12978)|null|\n", "2506.12958": "|**2025-06-20**|**Domain Specific Benchmarks for Evaluating Multimodal Large Language Models**|Khizar Anjum et.al.|[2506.12958](http://arxiv.org/abs/2506.12958)|null|\n", "2506.12928": "|**2025-06-15**|**Scaling Test-time Compute for LLM Agents**|King Zhu et.al.|[2506.12928](http://arxiv.org/abs/2506.12928)|null|\n", "2506.12915": "|**2025-06-15**|**PersonaFeedback: A Large-scale Human-annotated Benchmark For Personalization**|Meiling Tao et.al.|[2506.12915](http://arxiv.org/abs/2506.12915)|null|\n", "2506.12909": "|**2025-06-15**|**SciDA: Scientific Dynamic Assessor of LLMs**|Junting Zhou et.al.|[2506.12909](http://arxiv.org/abs/2506.12909)|null|\n", "2506.12841": "|**2025-06-15**|**WereWolf-Plus: An Update of Werewolf Game setting Based on DSGBench**|Xinyuan Xia et.al.|[2506.12841](http://arxiv.org/abs/2506.12841)|null|\n", "2506.12801": "|**2025-06-15**|**Mastering Da Vinci Code: A Comparative Study of Transformer, LLM, and PPO-based Agents**|LeCheng Zhang et.al.|[2506.12801](http://arxiv.org/abs/2506.12801)|null|\n", "2506.12728": "|**2025-06-15**|**MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution**|Yibo Wang et.al.|[2506.12728](http://arxiv.org/abs/2506.12728)|null|\n", "2506.12713": "|**2025-06-15**|**Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?**|Xiangyang Li et.al.|[2506.12713](http://arxiv.org/abs/2506.12713)|**[link](https://github.com/humanity-s-last-code-exam/hlce)**|\n", "2506.12667": "|**2025-06-15**|**Building Trustworthy AI by Addressing its 16+2 Desiderata with Goal-Directed Commonsense Reasoning**|Alexis R. Tudor et.al.|[2506.12667](http://arxiv.org/abs/2506.12667)|null|\n", "2506.12657": "|**2025-06-14**|**Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics**|Jiarui Liu et.al.|[2506.12657](http://arxiv.org/abs/2506.12657)|null|\n", "2506.12607": "|**2025-06-14**|**Towards Building General Purpose Embedding Models for Industry 4.0 Agents**|Christodoulos Constantinides et.al.|[2506.12607](http://arxiv.org/abs/2506.12607)|null|\n", "2506.12577": "|**2025-06-14**|**OneEval: Benchmarking LLM Knowledge-intensive Reasoning over Diverse Knowledge Bases**|Yongrui Chen et.al.|[2506.12577](http://arxiv.org/abs/2506.12577)|null|\n", "2506.12538": "|**2025-06-14**|**RealFactBench: A Benchmark for Evaluating Large Language Models in Real-World Fact-Checking**|Shuo Yang et.al.|[2506.12538](http://arxiv.org/abs/2506.12538)|null|\n", "2506.12527": "|**2025-06-14**|**Detection, Classification, and Mitigation of Gender Bias in Large Language Models**|Xiaoqing Cheng et.al.|[2506.12527](http://arxiv.org/abs/2506.12527)|null|\n", "2506.12509": "|**2025-06-14**|**Graph of Verification: Structured Verification of LLM Reasoning with Directed Acyclic Graphs**|Jiwei Fang et.al.|[2506.12509](http://arxiv.org/abs/2506.12509)|null|\n", "2506.12508": "|**2025-06-17**|**AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving**|Wentao Zhang et.al.|[2506.12508](http://arxiv.org/abs/2506.12508)|**[link](https://github.com/SkyworkAI/DeepResearchAgent)**|\n", "2506.12446": "|**2025-06-14**|**From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment**|Bin Xie et.al.|[2506.12446](http://arxiv.org/abs/2506.12446)|null|\n", "2506.12365": "|**2025-06-14**|**Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics**|Asifullah khan et.al.|[2506.12365](http://arxiv.org/abs/2506.12365)|null|\n", "2506.12355": "|**2025-06-14**|**QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm**|Qirui Zhou et.al.|[2506.12355](http://arxiv.org/abs/2506.12355)|null|\n", "2506.12349": "|**2025-06-14**|**Information Suppression in Large Language Models: Auditing, Quantifying, and Characterizing Censorship in DeepSeek**|Peiran Qiu et.al.|[2506.12349](http://arxiv.org/abs/2506.12349)|null|\n", "2506.12307": "|**2025-06-14**|**Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning**|Xiaotian Zhang et.al.|[2506.12307](http://arxiv.org/abs/2506.12307)|null|\n", "2506.12301": "|**2025-06-14**|**Unveiling Confirmation Bias in Chain-of-Thought Reasoning**|Yue Wan et.al.|[2506.12301](http://arxiv.org/abs/2506.12301)|null|\n", "2506.12286": "|**2025-06-14**|**The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason**|Shanchao Liang et.al.|[2506.12286](http://arxiv.org/abs/2506.12286)|null|\n", "2506.13811": "|**2025-06-13**|**Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study**|Sompote Youwai et.al.|[2506.13811](http://arxiv.org/abs/2506.13811)|null|\n", "2506.12217": "|**2025-06-13**|**From Emergence to Control: Probing and Modulating Self-Reflection in Language Models**|Xudong Zhu et.al.|[2506.12217](http://arxiv.org/abs/2506.12217)|**[link](https://github.com/xzascc/probingreflection)**|\n", "2506.12189": "|**2025-06-13**|**Supernova Event Dataset: Interpreting Large Language Model's Personality through Critical Event Analysis**|Pranav Agarwal et.al.|[2506.12189](http://arxiv.org/abs/2506.12189)|null|\n", "2506.12182": "|**2025-06-13**|**Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs**|Chenqian Le et.al.|[2506.12182](http://arxiv.org/abs/2506.12182)|null|\n", "2506.12014": "|**2025-06-13**|**code_transformed: The Influence of Large Language Models on Code**|Yuliang Xu et.al.|[2506.12014](http://arxiv.org/abs/2506.12014)|null|\n", "2506.12012": "|**2025-06-13**|**Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making**|Xiaopeng Yuan et.al.|[2506.12012](http://arxiv.org/abs/2506.12012)|null|\n", "2506.11976": "|**2025-06-13**|**How Visual Representations Map to Language Feature Space in Multimodal LLMs**|Constantin Venhoff et.al.|[2506.11976](http://arxiv.org/abs/2506.11976)|null|\n", "2506.11930": "|**2025-06-13**|**Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback**|Dongwei Jiang et.al.|[2506.11930](http://arxiv.org/abs/2506.11930)|null|\n", "2506.11928": "|**2025-06-13**|**LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?**|Zihan Zheng et.al.|[2506.11928](http://arxiv.org/abs/2506.11928)|null|\n", "2506.11902": "|**2025-06-13**|**TreeRL: LLM Reinforcement Learning with On-Policy Tree Search**|Zhenyu Hou et.al.|[2506.11902](http://arxiv.org/abs/2506.11902)|**[link](https://github.com/thudm/treerl)**|\n", "2506.11887": "|**2025-06-16**|**Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making**|Claudio Fanconi et.al.|[2506.11887](http://arxiv.org/abs/2506.11887)|null|\n", "2504.07596": "|**2025-04-11**|**Boosting Universal LLM Reward Design through Heuristic Reward Observation Space Evolution**|Zen Kit Heng et.al.|[2504.07596](http://arxiv.org/abs/2504.07596)|null|\n", "2504.03048": "|**2025-04-03**|**LLM Library Learning Fails: A LEGO-Prover Case Study**|Ian Berlot-Attwell et.al.|[2504.03048](http://arxiv.org/abs/2504.03048)|null|\n", "2504.01157": "|**2025-04-01**|**Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB**|Anas Dorbani et.al.|[2504.01157](http://arxiv.org/abs/2504.01157)|null|\n", "2503.16131": "|**2025-03-21**|**MKG-Rank: Enhancing Large Language Models with Knowledge Graph for Multilingual Medical Question Answering**|Feiyang Li et.al.|[2503.16131](http://arxiv.org/abs/2503.16131)|null|\n", "2503.13275": "|**2025-04-01**|**Knowledge-Aware Iterative Retrieval for Multi-Agent Systems**|Seyoung Song et.al.|[2503.13275](http://arxiv.org/abs/2503.13275)|null|\n", "2503.04982": "|**2025-03-06**|**LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression**|Souvik Kundu et.al.|[2503.04982_(ACL)](http://arxiv.org/abs/2503.04982)|null|\n", "2503.04973": "|**2025-03-06**|**Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning**|Giulio Corallo et.al.|[2503.04973](http://arxiv.org/abs/2503.04973)|null|\n", "2502.17421": "|**2025-06-17**|**LongSpec: Long-Context Lossless Speculative Decoding with Efficient Drafting and Verification**|Penghui Yang et.al.|[2502.17421](http://arxiv.org/abs/2502.17421)|null|\n", "2502.17535": "|**2025-02-24**|**The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?**|Zhenheng Tang et.al.|[2502.17535](http://arxiv.org/abs/2502.17535)|null|\n", "2502.16235": "|**2025-02-27**|**Dynamic Parallel Tree Search for Efficient LLM Reasoning**|Yifu Ding et.al.|[2502.16235](http://arxiv.org/abs/2502.16235)|null|\n", "2502.11444": "|**2025-02-17**|**Does RAG Really Perform Bad For Long-Context Processing?**|Kun Luo et.al.|[2502.11444](http://arxiv.org/abs/2502.11444)|null|\n", "2502.11147": "|**2025-05-30**|**RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning**|Junhao Hu et.al.|[2502.11147](http://arxiv.org/abs/2502.11147)|null|\n", "2502.04420": "|**2025-05-31**|**KVTuner: Sensitivity-Aware Layer-Wise Mixed-Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference**|Xing Li et.al.|[2502.04420_(ICML)](http://arxiv.org/abs/2502.04420)|**[link](https://github.com/cmd2001/KVTuner)**|\n", "2502.01941": "|**2025-05-21**|**Can LLMs Maintain Fundamental Abilities under KV Cache Compression?**|Xiang Liu et.al.|[2502.01941](http://arxiv.org/abs/2502.01941)|null|\n", "2501.18356": "|**2025-01-30**|**State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence**|Thea Aviss et.al.|[2501.18356](http://arxiv.org/abs/2501.18356)|null|\n", "2501.15113": "|**2025-01-25**|**Task-KV: Task-aware KV Cache Optimization via Semantic Differentiation of Attention Heads**|Xingyang He et.al.|[2501.15113](http://arxiv.org/abs/2501.15113)|null|\n", "2501.16383": "|**2025-02-02**|**RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations**|Zunhai Su et.al.|[2501.16383](http://arxiv.org/abs/2501.16383)|null|\n", "2501.13331": "|**2025-02-05**|**Qrazor: Reliable and Effortless 4-bit LLM Quantization by Significant Data Razoring**|Dongyoung Lee et.al.|[2501.13331](http://arxiv.org/abs/2501.13331)|null|\n", "2501.01039": "|**2025-01-02**|**MSWA: Refining Local Attention with Multi-ScaleWindow Attention**|Yixing Xu et.al.|[2501.01039](http://arxiv.org/abs/2501.01039)|null|\n", "2412.21015": "|**2025-06-13**|**MapQaTor: An Extensible Framework for Efficient Annotation of Map-Based QA Datasets**|Mahir Labib Dihan et.al.|[2412.21015_(ACL)](http://arxiv.org/abs/2412.21015)|null|\n", "2412.19442": "|**2025-07-30**|**A Survey on Large Language Model Acceleration based on KV Cache Management**|Haoyang Li et.al.|[2412.19442](http://arxiv.org/abs/2412.19442)|null|\n", "2412.18914": "|**2025-03-12**|**PRISM: Efficient Long-Range Reasoning With Short-Context LLMs**|Dulhan Jayalath et.al.|[2412.18914](http://arxiv.org/abs/2412.18914)|null|\n", "2412.13771": "|**2024-12-18**|**Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization**|Guanghan Li et.al.|[2412.13771_(AAAI)](http://arxiv.org/abs/2412.13771)|null|\n", "2412.13649": "|**2025-06-03**|**SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation**|Jialong Wu et.al.|[2412.13649_(ACL)](http://arxiv.org/abs/2412.13649)|null|\n", "2412.16187": "|**2025-06-04**|**HashEvict: A Pre-Attention KV Cache Eviction Strategy using Locality-Sensitive Hashing**|Minghui Liu et.al.|[2412.16187](http://arxiv.org/abs/2412.16187)|null|\n", "2412.03213": "|**2025-06-14**|**ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression**|Guangda Liu et.al.|[2412.03213](http://arxiv.org/abs/2412.03213)|null|\n", "2411.09425": "|**2025-02-10**|**MARM: Unlocking the Future of Recommendation Systems through Memory Augmentation and Scalable Complexity**|Xiao Lv et.al.|[2411.09425](http://arxiv.org/abs/2411.09425)|null|\n", "2410.19258": "|**2024-11-14**|**Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning**|Yu Fu et.al.|[2410.19258](http://arxiv.org/abs/2410.19258)|null|\n", "2410.17635": "|**2025-03-06**|**Markov Chain of Thought for Efficient Mathematical Reasoning**|Wen Yang et.al.|[2410.17635_(ACL)](http://arxiv.org/abs/2410.17635)|null|\n", "2410.13846": "|**2025-02-04**|**LightTransfer: Your Long-Context LLM is Secretly a Hybrid Model with Effortless Adaptation**|Xuan Zhang et.al.|[2410.13846](http://arxiv.org/abs/2410.13846)|null|\n", "2410.05265": "|**2025-01-27**|**PrefixQuant: Eliminating Outliers by Prefixed Tokens for Large Language Models Quantization**|Mengzhao Chen et.al.|[2410.05265](http://arxiv.org/abs/2410.05265)|null|\n", "2410.00359": "|**2024-10-01**|**Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness**|Xiao Peng et.al.|[2410.00359](http://arxiv.org/abs/2410.00359)|null|\n", "2409.15523": "|**2024-09-23**|**SEAL: Suite for Evaluating API-use of LLMs**|Woojeong Kim et.al.|[2409.15523](http://arxiv.org/abs/2409.15523)|null|\n", "2409.09086": "|**2024-09-11**|**Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU**|Zhenyu Ning et.al.|[2409.09086](http://arxiv.org/abs/2409.09086)|null|\n", "2408.05646": "|**2024-11-08**|**Eigen Attention: Attention in Low-Rank Space for KV Cache Compression**|Utkarsh Saxena et.al.|[2408.05646](http://arxiv.org/abs/2408.05646)|null|\n", "2407.15360": "|**2024-07-22**|**Dissecting Multiplication in Transformers: Insights into LLMs**|Luyu Qiu et.al.|[2407.15360](http://arxiv.org/abs/2407.15360)|null|\n", "2407.01527": "|**2024-10-08**|**KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches**|Jiayi Yuan et.al.|[2407.01527](http://arxiv.org/abs/2407.01527)|null|\n", "2405.17062": "|**2025-05-26**|**UniICL: An Efficient Unified Framework Unifying Compression, Selection, and Generation**|Jun Gao et.al.|[2405.17062_(ACL)](http://arxiv.org/abs/2405.17062)|null|\n", "2405.16406": "|**2025-02-20**|**SpinQuant: LLM quantization with learned rotations**|Zechun Liu et.al.|[2405.16406_(ICLR)](http://arxiv.org/abs/2405.16406)|null|\n", "2404.00242": "|**2025-03-07**|**DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference**|Jinwei Yao et.al.|[2404.00242_(DATE)](http://arxiv.org/abs/2404.00242)|**[link](https://github.com/LINs-lab/DeFT)**|\n", "2401.08156": "|**2024-01-16**|**GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching**|Cong Guo et.al.|[2401.08156_(ASPLOS)](http://arxiv.org/abs/2401.08156)|null|\n", "2401.08138": "|**2024-01-16**|**LLMs for Test Input Generation for Semantic Caches**|Zafaryab Rasool et.al.|[2401.08138](http://arxiv.org/abs/2401.08138)|null|\n", "2312.07104": "|**2024-06-06**|**SGLang: Efficient Execution of Structured Language Model Programs**|Lianmin Zheng et.al.|[2312.07104](http://arxiv.org/abs/2312.07104)|null|\n", "2312.04985": "|**2024-09-04**|**SparQ Attention: Bandwidth-Efficient LLM Inference**|Luka Ribar et.al.|[2312.04985](http://arxiv.org/abs/2312.04985)|null|\n", "2305.17126": "|**2024-03-11**|**Large Language Models as Tool Makers**|Tianle Cai et.al.|[2305.17126](http://arxiv.org/abs/2305.17126)|**[link](https://github.com/ctlllll/LLM-ToolMaker)**|\n", "2407.21018": "|**2025-02-27**|**ThinK: Thinner Key Cache by Query-Driven Pruning**|Yuhui Xu et.al.|[2407.21018_(ICLR)](http://arxiv.org/abs/2407.21018)|null|\n", "2502.15734": "|**2025-02-05**|**Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation**|Shubham Agarwal et.al.|[2502.15734_(SIGMOD)](http://arxiv.org/abs/2502.15734)|null|\n", "2412.03594": "|**2025-01-17**|**BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching**|Zhen Zheng et.al.|[2412.03594](http://arxiv.org/abs/2412.03594)|null|\n", "2410.03065": "|**2025-02-20**|**Compute Or Load KV Cache? Why Not Both?**|Shuowei Jin et.al.|[2410.03065](http://arxiv.org/abs/2410.03065)|null|\n", "2408.00539": "|**2024-08-01**|**Intermittent Semi-working Mask: A New Masking Paradigm for LLMs**|Mingcong Lu et.al.|[2408.00539](http://arxiv.org/abs/2408.00539)|null|\n", "2406.12016": "|**2024-10-04**|**Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization**|Seungwoo Son et.al.|[2406.12016_(EMNLP)](http://arxiv.org/abs/2406.12016)|null|\n", "2403.08845": "|**2024-07-11**|**Bifurcated Attention: Accelerating Massively Parallel Decoding with Shared Prefixes in LLMs**|Ben Athiwaratkun et.al.|[2403.08845](http://arxiv.org/abs/2403.08845)|null|\n", "2402.15220": "|**2024-08-01**|**ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**|Lu Ye et.al.|[2402.15220_(ACL)](http://arxiv.org/abs/2402.15220)|null|\n", "2402.05099": "|**2024-05-13**|**Hydragen: High-Throughput LLM Inference with Shared Prefixes**|Jordan Juravsky et.al.|[2402.05099](http://arxiv.org/abs/2402.05099)|null|\n", "2503.06433": "|**2025-03-09**|**Seesaw: High-throughput LLM Inference via Model Re-sharding**|Qidong Su et.al.|[2503.06433](http://arxiv.org/abs/2503.06433)|null|\n", "2503.03182": "|**2025-03-05**|**Enhancing Memory Efficiency in Large Language Model Training Through Chronos-aware Pipeline Parallelism**|Xinyuan Lin et.al.|[2503.03182](http://arxiv.org/abs/2503.03182)|null|\n", "2502.07115": "|**2025-05-20**|**Online Scheduling for LLM Inference with KV Cache Constraints**|Patrick Jaillet et.al.|[2502.07115](http://arxiv.org/abs/2502.07115)|null|\n", "2501.14743": "|**2024-12-13**|**KVDirect: Distributed Disaggregated LLM Inference**|Shiyang Chen et.al.|[2501.14743](http://arxiv.org/abs/2501.14743)|null|\n", "2411.17089": "|**2025-06-04**|**KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation**|Chaoyi Jiang et.al.|[2411.17089_(ACL)](http://arxiv.org/abs/2411.17089)|null|\n", "2411.01142": "|**2024-11-02**|**NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference**|Xuanlin Jiang et.al.|[2411.01142](http://arxiv.org/abs/2411.01142)|null|\n", "2410.19123": "|**2024-10-24**|**Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design**|Ruisi Cai et.al.|[2410.19123_(NeurIPS)](http://arxiv.org/abs/2410.19123)|null|\n", "2410.18248": "|**2024-10-25**|**Fast Inference for Augmented Large Language Models**|Rana Shahout et.al.|[2410.18248](http://arxiv.org/abs/2410.18248)|null|\n", "2410.17954": "|**2024-10-23**|**ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference**|Xin He et.al.|[2410.17954](http://arxiv.org/abs/2410.17954)|null|\n", "2403.17312": "|**2024-03-26**|**ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching**|Youpeng Zhao et.al.|[2403.17312_(ISCA)](http://arxiv.org/abs/2403.17312)|null|\n", "2403.11421": "|**2024-03-18**|**FastDecode: High-Throughput GPU-Efficient LLM Serving using Heterogeneous Pipelines**|Jiaao He et.al.|[2403.11421](http://arxiv.org/abs/2403.11421)|null|\n", "2401.17644": "|**2025-05-26**|**BurstGPT: A Real-world Workload Dataset to Optimize LLM Serving Systems**|Yuxin Wang et.al.|[2401.17644](http://arxiv.org/abs/2401.17644)|null|\n", "2312.04916": "|**2024-06-16**|**EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism**|Yanxi Chen et.al.|[2312.04916_(ICML)](http://arxiv.org/abs/2312.04916)|null|\n", "2306.06000": "|**2023-06-09**|**S$^{3}$: Increasing GPU Utilization during Generative Inference for Higher Throughput**|Yunho Jin et.al.|[2306.06000](http://arxiv.org/abs/2306.06000)|null|\n", "2503.02398": "|**2025-05-24**|**PersonaX: A Recommendation Agent Oriented User Modeling Framework for Long Behavior Sequence**|Yunxiao Shi et.al.|[2503.02398_(ACL)](http://arxiv.org/abs/2503.02398)|null|\n", "2411.04975": "|**2025-06-02**|**SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications**|Gabriele Oliaro et.al.|[2411.04975](http://arxiv.org/abs/2411.04975)|null|\n", "2406.13399": "|**2024-06-19**|**VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework**|Zhi Yao et.al.|[2406.13399](http://arxiv.org/abs/2406.13399)|null|\n", "2406.06799": "|**2024-09-21**|**LLM-dCache: Improving Tool-Augmented LLMs with GPT-Driven Localized Data Caching**|Simranjit Singh et.al.|[2406.06799](http://arxiv.org/abs/2406.06799)|null|\n", "2403.05826": "|**2024-05-31**|**Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks**|Minrui Xu et.al.|[2403.05826](http://arxiv.org/abs/2403.05826)|null|\n", "2402.02643": "|**2024-02-04**|**LLM-Enhanced Data Management**|Xuanhe Zhou et.al.|[2402.02643](http://arxiv.org/abs/2402.02643)|null|\n", "2401.07764": "|**2024-02-16**|**When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment**|Minrui Xu et.al.|[2401.07764](http://arxiv.org/abs/2401.07764)|null|\n", "2401.01614": "|**2024-03-12**|**GPT-4V(ision) is a Generalist Web Agent, if Grounded**|Boyuan Zheng et.al.|[2401.01614](http://arxiv.org/abs/2401.01614)|null|\n", "2506.15155": "|**2025-06-18**|**eLLM: Elastic Memory Management Framework for Efficient LLM Serving**|Jiale Xu et.al.|[2506.15155](http://arxiv.org/abs/2506.15155)|null|\n", "2506.14852": "|**2025-06-17**|**Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching**|Qizheng Zhang et.al.|[2506.14852](http://arxiv.org/abs/2506.14852)|null|\n", "2506.15662": "|**2025-06-18**|**CC-LEARN: Cohort-based Consistency Learning**|Xiao Ye et.al.|[2506.15662](http://arxiv.org/abs/2506.15662)|null|\n", "2506.15629": "|**2025-06-18**|**Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability**|Yusuke Sakai et.al.|[2506.15629](http://arxiv.org/abs/2506.15629)|null|\n", "2506.15567": "|**2025-06-18**|**Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents**|Aline Dobrovsky et.al.|[2506.15567](http://arxiv.org/abs/2506.15567)|null|\n", "2506.15522": "|**2025-06-18**|**Lessons from Training Grounded LLMs with Verifiable Rewards**|Shang Hong Sim et.al.|[2506.15522](http://arxiv.org/abs/2506.15522)|null|\n", "2506.15512": "|**2025-06-18**|**Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach**|Wenqi Guan et.al.|[2506.15512](http://arxiv.org/abs/2506.15512)|null|\n", "2506.15498": "|**2025-06-18**|**SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling**|Md Imbesat Hassan Rizvi et.al.|[2506.15498](http://arxiv.org/abs/2506.15498)|**[link](https://github.com/ukplab/arxiv2025-spare-prm)**|\n", "2506.15455": "|**2025-06-18**|**RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation**|Xinnuo Xu et.al.|[2506.15455](http://arxiv.org/abs/2506.15455)|null|\n", "2506.15451": "|**2025-06-18**|**AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need**|Zhouhong Gu et.al.|[2506.15451](http://arxiv.org/abs/2506.15451)|**[link](https://github.com/mikegu721/agentgroupchat-v2)**|\n", "2506.15339": "|**2025-06-18**|**DeVisE: Behavioral Testing of Medical Large Language Models**|Camila Zurdo Tagliabue et.al.|[2506.15339](http://arxiv.org/abs/2506.15339)|null|\n", "2506.15301": "|**2025-06-18**|**Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment**|Shrestha Ghosh et.al.|[2506.15301](http://arxiv.org/abs/2506.15301)|null|\n", "2506.15215": "|**2025-06-18**|**MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs**|Yongqi Fan et.al.|[2506.15215](http://arxiv.org/abs/2506.15215)|**[link](https://github.com/johnny-fans/minoseval)**|\n", "2506.15211": "|**2025-06-18**|**ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs**|Feng He et.al.|[2506.15211](http://arxiv.org/abs/2506.15211)|null|\n", "2506.15076": "|**2025-06-18**|**Learning-Time Encoding Shapes Unlearning in LLMs**|Ruihan Wu et.al.|[2506.15076](http://arxiv.org/abs/2506.15076)|**[link](https://github.com/wrh14/learning_time_shapes_unlearning)**|\n", "2506.15065": "|**2025-06-18**|**HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models**|Trishna Chakraborty et.al.|[2506.15065](http://arxiv.org/abs/2506.15065)|null|\n", "2506.15050": "|**2025-06-18**|**Truncated Proximal Policy Optimization**|Tiantian Fan et.al.|[2506.15050](http://arxiv.org/abs/2506.15050)|null|\n", "2506.14965": "|**2025-06-17**|**Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective**|Zhoujun Cheng et.al.|[2506.14965](http://arxiv.org/abs/2506.14965)|**[link](https://github.com/llm360/reasoning360)**|\n", "2506.14948": "|**2025-06-17**|**Structured Moral Reasoning in Language Models: A Value-Grounded Evaluation Framework**|Mohna Chakraborty et.al.|[2506.14948](http://arxiv.org/abs/2506.14948)|null|\n", "2506.14936": "|**2025-06-17**|**CALM: Contextual Analog Logic with Multimodality**|Maxwell J. Jacobson et.al.|[2506.14936](http://arxiv.org/abs/2506.14936)|null|\n", "2506.14927": "|**2025-06-17**|**MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance**|Joseph J. Peper et.al.|[2506.14927](http://arxiv.org/abs/2506.14927)|null|\n", "2506.15969": "|**2025-06-19**|**LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning**|Haoyue Zhang et.al.|[2506.15969](http://arxiv.org/abs/2506.15969)|null|\n", "2506.15704": "|**2025-05-30**|**Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding**|Feiyu Yao et.al.|[2506.15704](http://arxiv.org/abs/2506.15704)|null|\n", "2506.17219": "|**2025-06-25**|**No Free Lunch: Rethinking Internal Feedback for LLM Reasoning**|Yanzhi Zhang et.al.|[2506.17219](http://arxiv.org/abs/2506.17219)|null|\n", "2506.17188": "|**2025-06-20**|**Towards AI Search Paradigm**|Yuchen Li et.al.|[2506.17188](http://arxiv.org/abs/2506.17188)|null|\n", "2506.17124": "|**2025-06-20**|**When Can Model-Free Reinforcement Learning be Enough for Thinking?**|Josiah P. Hanna et.al.|[2506.17124](http://arxiv.org/abs/2506.17124)|null|\n", "2506.17104": "|**2025-06-20**|**Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving**|Chuxue Cao et.al.|[2506.17104](http://arxiv.org/abs/2506.17104)|null|\n", "2506.17088": "|**2025-06-20**|**Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation**|Jiahao Cheng et.al.|[2506.17088](http://arxiv.org/abs/2506.17088)|null|\n", "2506.17080": "|**2025-06-20**|**Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs**|Ricardo Rei et.al.|[2506.17080](http://arxiv.org/abs/2506.17080)|null|\n", "2506.17052": "|**2025-06-20**|**From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers**|Jingtong Su et.al.|[2506.17052](http://arxiv.org/abs/2506.17052)|null|\n", "2506.16975": "|**2025-06-20**|**Latent Concept Disentanglement in Transformer-based Language Models**|Guan Zhe Hong et.al.|[2506.16975](http://arxiv.org/abs/2506.16975)|null|\n", "2506.16796": "|**2025-06-23**|**RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought**|Junbo Qiao et.al.|[2506.16796](http://arxiv.org/abs/2506.16796)|**[link](https://github.com/junboooo/realsr-r1)**|\n", "2506.16691": "|**2025-06-20**|**LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation**|Tongtian Yue et.al.|[2506.16691](http://arxiv.org/abs/2506.16691)|null|\n", "2506.16650": "|**2025-06-19**|**SemAgent: A Semantics Aware Program Repair Agent**|Anvith Pabba et.al.|[2506.16650](http://arxiv.org/abs/2506.16650)|null|\n", "2506.16639": "|**2025-06-19**|**LLM-based Satisfiability Checking of String Requirements by Consistent Data and Checker Generation**|Boqi Chen et.al.|[2506.16639](http://arxiv.org/abs/2506.16639)|null|\n", "2506.16507": "|**2025-06-19**|**Robust Reward Modeling via Causal Rubrics**|Pragya Srivastava et.al.|[2506.16507](http://arxiv.org/abs/2506.16507)|null|\n", "2506.16500": "|**2025-06-19**|**SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity**|Samir Khaki et.al.|[2506.16500](http://arxiv.org/abs/2506.16500)|null|\n", "2506.16499": "|**2025-06-19**|**ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning**|Zexi Liu et.al.|[2506.16499](http://arxiv.org/abs/2506.16499)|null|\n", "2506.16493": "|**2025-06-19**|**Grounding Language Models with Semantic Digital Twins for Robotic Planning**|Mehreen Naeem et.al.|[2506.16493](http://arxiv.org/abs/2506.16493)|null|\n", "2506.16450": "|**2025-06-19**|**How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?**|Giuseppe Lando et.al.|[2506.16450](http://arxiv.org/abs/2506.16450)|null|\n", "2506.16406": "|**2025-06-19**|**Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights**|Zhiyuan Liang et.al.|[2506.16406](http://arxiv.org/abs/2506.16406)|null|\n", "2506.16401": "|**2025-06-19**|**TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis**|Chunhou Ji et.al.|[2506.16401](http://arxiv.org/abs/2506.16401)|**[link](https://github.com/februarysea/trajscenellm)**|\n", "2506.16395": "|**2025-06-19**|**OJBench: A Competition Level Code Benchmark For Large Language Models**|Zhexu Wang et.al.|[2506.16395](http://arxiv.org/abs/2506.16395)|null|\n", "2506.16393": "|**2025-06-19**|**From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling**|Yao Lu et.al.|[2506.16393](http://arxiv.org/abs/2506.16393)|null|\n", "2506.16389": "|**2025-06-19**|**RiOT: Efficient Prompt Refinement with Residual Optimization Tree**|Chenyi Zhou et.al.|[2506.16389](http://arxiv.org/abs/2506.16389)|**[link](https://github.com/qing1zhong/riot)**|\n", "2506.16383": "|**2025-06-19**|**Large Language Models in Argument Mining: A Survey**|Hao Li et.al.|[2506.16383](http://arxiv.org/abs/2506.16383)|null|\n", "2506.16359": "|**2025-06-19**|**SHREC and PHEONA: Using Large Language Models to Advance Next-Generation Computational Phenotyping**|Sarah Pungitore et.al.|[2506.16359](http://arxiv.org/abs/2506.16359)|null|\n", "2506.16335": "|**2025-06-19**|**Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach**|Albert Sadowski et.al.|[2506.16335](http://arxiv.org/abs/2506.16335)|**[link](https://github.com/albsadowski/structured-decomposition)**|\n", "2506.16172": "|**2025-06-19**|**SGIC: A Self-Guided Iterative Calibration Framework for RAG**|Guanhua Chen et.al.|[2506.16172](http://arxiv.org/abs/2506.16172)|null|\n", "2506.16151": "|**2025-06-19**|**Under the Shadow of Babel: How Language Shapes Reasoning in LLMs**|Chenxi Wang et.al.|[2506.16151](http://arxiv.org/abs/2506.16151)|null|\n", "2506.16141": "|**2025-06-19**|**GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning**|Yi Chen et.al.|[2506.16141](http://arxiv.org/abs/2506.16141)|**[link](https://github.com/tencentarc/grpo-care)**|\n", "2506.16136": "|**2025-06-19**|**Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing**|Kai Huang et.al.|[2506.16136](http://arxiv.org/abs/2506.16136)|null|\n", "2506.16112": "|**2025-06-19**|**AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models**|Yuan Zhang et.al.|[2506.16112](http://arxiv.org/abs/2506.16112)|null|\n", "2506.16044": "|**2025-06-19**|**Human-Centered Shared Autonomy for Motor Planning, Learning, and Control Applications**|MH Farhadi et.al.|[2506.16044](http://arxiv.org/abs/2506.16044)|null|\n", "2506.16043": "|**2025-06-19**|**DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling**|Fei Wang et.al.|[2506.16043](http://arxiv.org/abs/2506.16043)|null|\n", "2506.16010": "|**2025-06-19**|**SimuPanel: A Novel Immersive Multi-Agent System to Simulate Interactive Expert Panel Discussion**|Xiangyang He et.al.|[2506.16010](http://arxiv.org/abs/2506.16010)|null|\n", "2506.15894": "|**2025-06-18**|**Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning**|Sam Silver et.al.|[2506.15894](http://arxiv.org/abs/2506.15894)|null|\n", "2506.15882": "|**2025-06-18**|**Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute**|Sheng Liu et.al.|[2506.15882](http://arxiv.org/abs/2506.15882)|null|\n", "2506.15841": "|**2025-06-18**|**MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents**|Zijian Zhou et.al.|[2506.15841](http://arxiv.org/abs/2506.15841)|null|\n", "2506.15828": "|**2025-06-18**|**Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning**|Emanuele Musumeci et.al.|[2506.15828](http://arxiv.org/abs/2506.15828)|null|\n", "2506.15794": "|**2025-06-18**|**Veracity: An Open-Source AI Fact-Checking System**|Taylor Lynn Curtis et.al.|[2506.15794](http://arxiv.org/abs/2506.15794)|null|\n", "2506.15790": "|**2025-06-18**|**ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis**|Chenyang Peng et.al.|[2506.15790](http://arxiv.org/abs/2506.15790)|null|\n", "2506.15787": "|**2025-06-23**|**SLR: An Automated Synthesis Framework for Scalable Logical Reasoning**|Lukas Helff et.al.|[2506.15787](http://arxiv.org/abs/2506.15787)|null|\n", "2506.18879": "|**2025-06-23**|**CommVQ: Commutative Vector Quantization for KV Cache Compression**|Junyan Li et.al.|[2506.18879_(ICML)](http://arxiv.org/abs/2506.18879)|null|\n", "2506.17286": "|**2025-07-23**|**GTA: Grouped-head latenT Attention**|Luoyang Sun et.al.|[2506.17286](http://arxiv.org/abs/2506.17286)|null|\n", "2506.18896": "|**2025-06-23**|**ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs**|Jiaru Zou et.al.|[2506.18896](http://arxiv.org/abs/2506.18896)|null|\n", "2506.18880": "|**2025-06-23**|**OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization**|Yiyou Sun et.al.|[2506.18880](http://arxiv.org/abs/2506.18880)|null|\n", "2506.18841": "|**2025-06-23**|**LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning**|Yuhao Wu et.al.|[2506.18841](http://arxiv.org/abs/2506.18841)|null|\n", "2506.18824": "|**2025-06-23**|**Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories**|Islem Bouzenia et.al.|[2506.18824](http://arxiv.org/abs/2506.18824)|null|\n", "2506.18781": "|**2025-06-23**|**Existing LLMs Are Not Self-Consistent For Simple Tasks**|Zhenru Lin et.al.|[2506.18781](http://arxiv.org/abs/2506.18781)|null|\n", "2506.18777": "|**2025-06-23**|**Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training**|Jonathan Cook et.al.|[2506.18777](http://arxiv.org/abs/2506.18777)|null|\n", "2506.18631": "|**2025-06-24**|**ReDit: Reward Dithering for Improved LLM Policy Optimization**|Chenxing Wei et.al.|[2506.18631](http://arxiv.org/abs/2506.18631)|null|\n", "2506.18512": "|**2025-06-23**|**MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis**|Yuting Zhang et.al.|[2506.18512](http://arxiv.org/abs/2506.18512)|null|\n", "2506.18501": "|**2025-06-29**|**Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance**|Wael Etaiwi et.al.|[2506.18501](http://arxiv.org/abs/2506.18501)|null|\n", "2506.18485": "|**2025-06-23**|**MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models**|Junjie Zhang et.al.|[2506.18485](http://arxiv.org/abs/2506.18485)|null|\n", "2506.18421": "|**2025-06-23**|**TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models**|Ce Li et.al.|[2506.18421](http://arxiv.org/abs/2506.18421)|null|\n", "2506.18387": "|**2025-06-23**|**Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics**|Yousang Cho et.al.|[2506.18387](http://arxiv.org/abs/2506.18387)|null|\n", "2506.18383": "|**2025-06-23**|**LOGICPO: Efficient Translation of NL-based Logical Problems to FOL using LLMs and Preference Optimization**|Koushik Viswanadha et.al.|[2506.18383](http://arxiv.org/abs/2506.18383)|null|\n", "2506.18348": "|**2025-06-27**|**Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team**|Weilun Yu et.al.|[2506.18348](http://arxiv.org/abs/2506.18348)|null|\n", "2506.18341": "|**2025-06-23**|**Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs**|Kang Chen et.al.|[2506.18341](http://arxiv.org/abs/2506.18341)|null|\n", "2506.18337": "|**2025-06-23**|**TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance**|Syed Mekael Wasti et.al.|[2506.18337](http://arxiv.org/abs/2506.18337)|null|\n", "2506.18330": "|**2025-06-25**|**Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning**|Lixin Wu et.al.|[2506.18330](http://arxiv.org/abs/2506.18330)|null|\n", "2506.18293": "|**2025-06-23**|**LLM-Integrated Digital Twins for Hierarchical Resource Allocation in 6G Networks**|Majumder Haider et.al.|[2506.18293](http://arxiv.org/abs/2506.18293)|null|\n", "2506.18254": "|**2025-06-23**|**RLPR: Extrapolating RLVR to General Domains without Verifiers**|Tianyu Yu et.al.|[2506.18254](http://arxiv.org/abs/2506.18254)|null|\n", "2506.18178": "|**2025-06-22**|**Integrating LLMs and Digital Twins for Adaptive Multi-Robot Task Allocation in Construction**|Min Deng et.al.|[2506.18178](http://arxiv.org/abs/2506.18178)|null|\n", "2506.18167": "|**2025-06-24**|**Understanding Reasoning in Thinking Language Models via Steering Vectors**|Constantin Venhoff et.al.|[2506.18167](http://arxiv.org/abs/2506.18167)|null|\n", "2506.18125": "|**2025-06-22**|**Programming Quantum Computers with Large Language Models**|Elena R. Henderson et.al.|[2506.18125](http://arxiv.org/abs/2506.18125)|null|\n", "2506.18116": "|**2025-06-22**|**Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives**|Batool Haider et.al.|[2506.18116](http://arxiv.org/abs/2506.18116)|null|\n", "2506.18102": "|**2025-06-22**|**InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating**|Fuyu Wang et.al.|[2506.18102](http://arxiv.org/abs/2506.18102)|null|\n", "2506.18096": "|**2025-06-22**|**Deep Research Agents: A Systematic Examination And Roadmap**|Yuxuan Huang et.al.|[2506.18096](http://arxiv.org/abs/2506.18096)|null|\n", "2506.17944": "|**2025-06-27**|**SegChange-R1: LLM-Augmented Remote Sensing Change Detection**|Fei Zhou et.al.|[2506.17944](http://arxiv.org/abs/2506.17944)|null|\n", "2506.17930": "|**2025-06-22**|**Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective**|Jianyu Wang et.al.|[2506.17930](http://arxiv.org/abs/2506.17930)|null|\n", "2506.17900": "|**2025-06-22**|**Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms**|Cheng Ji et.al.|[2506.17900](http://arxiv.org/abs/2506.17900)|null|\n", "2506.17871": "|**2025-06-22**|**How Alignment Shrinks the Generative Horizon**|Chenghao Yang et.al.|[2506.17871](http://arxiv.org/abs/2506.17871)|null|\n", "2506.17788": "|**2025-06-21**|**Bayesian Social Deduction with Graph-Informed Language Models**|Shahab Rahimirad et.al.|[2506.17788](http://arxiv.org/abs/2506.17788)|null|\n", "2506.17772": "|**2025-06-21**|**PAGENT: Learning to Patch Software Engineering Agents**|Haoran Xue et.al.|[2506.17772](http://arxiv.org/abs/2506.17772)|null|\n", "2506.17761": "|**2025-06-21**|**Towards a Unified Textual Graph Framework for Spectral Reasoning via Physical and Chemical Information Fusion**|Jiheng Liang et.al.|[2506.17761](http://arxiv.org/abs/2506.17761)|null|\n", "2506.17728": "|**2025-06-24**|**KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation**|Dalong Zhang et.al.|[2506.17728](http://arxiv.org/abs/2506.17728)|null|\n", "2506.17692": "|**2025-06-21**|**Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering**|Binquan Ji et.al.|[2506.17692](http://arxiv.org/abs/2506.17692)|null|\n", "2506.17644": "|**2025-06-21**|**Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges**|Zimo Ji et.al.|[2506.17644](http://arxiv.org/abs/2506.17644)|null|\n", "2506.17630": "|**2025-06-21**|**Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs**|Yang Wu et.al.|[2506.17630](http://arxiv.org/abs/2506.17630)|null|\n", "2506.17629": "|**2025-06-21**|**CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning**|Kailing Li et.al.|[2506.17629](http://arxiv.org/abs/2506.17629)|null|\n", "2506.17545": "|**2025-06-21**|**Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations**|Zhihao Yuan et.al.|[2506.17545](http://arxiv.org/abs/2506.17545)|null|\n", "2506.17533": "|**2025-06-21**|**DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning**|Yuanhao Wu et.al.|[2506.17533](http://arxiv.org/abs/2506.17533)|null|\n", "2506.17486": "|**2025-06-20**|**Distilling On-device Language Models for Robot Planning with Minimal Human Intervention**|Zachary Ravichandran et.al.|[2506.17486](http://arxiv.org/abs/2506.17486)|null|\n", "2506.17417": "|**2025-06-20**|**Aha Moment Revisited: Are VLMs Truly Capable of Self Verification in Inference-time Scaling?**|Mingyuan Wu et.al.|[2506.17417](http://arxiv.org/abs/2506.17417)|null|\n", "2506.17336": "|**2025-06-19**|**Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases**|Yubeen Bae et.al.|[2506.17336](http://arxiv.org/abs/2506.17336)|**[link](https://github.com/Yubeen-Bae/PPMI)**|\n", "2506.17335": "|**2025-06-19**|**LMR-BENCH: Evaluating LLM Agent's Ability on Reproducing Language Modeling Research**|Shuo Yan et.al.|[2506.17335](http://arxiv.org/abs/2506.17335)|null|\n", "2506.17330": "|**2025-06-19**|**Large Language Models for Spreadsheets: Benchmarking Progress and Evaluating Performance with FLARE**|Simon Thorne et.al.|[2506.17330](http://arxiv.org/abs/2506.17330)|null|\n", "2506.19505": "|**2025-06-24**|**AnTKV: Anchor Token-Aware Sub-Bit Vector Quantization for KV Cache in Large Language Models**|Zeyu Li et.al.|[2506.19505](http://arxiv.org/abs/2506.19505)|null|\n", "2506.19433": "|**2025-06-24**|**Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System**|Lixuan He et.al.|[2506.19433](http://arxiv.org/abs/2506.19433)|null|\n", "2506.19846": "|**2025-06-24**|**JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning**|Ai Han et.al.|[2506.19846](http://arxiv.org/abs/2506.19846)|null|\n", "2506.19835": "|**2025-06-24**|**MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration**|Yucheng Zhou et.al.|[2506.19835](http://arxiv.org/abs/2506.19835)|null|\n", "2506.19807": "|**2025-06-24**|**KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality**|Baochang Ren et.al.|[2506.19807](http://arxiv.org/abs/2506.19807)|null|\n", "2506.19802": "|**2025-06-24**|**KnowML: Improving Generalization of ML-NIDS with Attack Knowledge Graphs**|Xin Fan Guo et.al.|[2506.19802](http://arxiv.org/abs/2506.19802)|null|\n", "2506.19794": "|**2025-06-24**|**Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study**|Yuqi Zhu et.al.|[2506.19794](http://arxiv.org/abs/2506.19794)|null|\n", "2506.19773": "|**2025-06-24**|**Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study**|Nandana Mihindukulasooriya et.al.|[2506.19773](http://arxiv.org/abs/2506.19773)|null|\n", "2506.19767": "|**2025-06-24**|**SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning**|Yuqian Fu et.al.|[2506.19767](http://arxiv.org/abs/2506.19767)|null|\n", "2506.19733": "|**2025-06-24**|**Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?**|Chuxuan Hu et.al.|[2506.19733](http://arxiv.org/abs/2506.19733)|null|\n", "2506.19599": "|**2025-06-24**|**ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model**|Zhenke Duan et.al.|[2506.19599](http://arxiv.org/abs/2506.19599)|null|\n", "2506.19527": "|**2025-06-24**|**KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs**|Kelin Fu et.al.|[2506.19527](http://arxiv.org/abs/2506.19527)|null|\n", "2506.19483": "|**2025-06-24**|**Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models**|Marcos Estecha-Garitagoitia et.al.|[2506.19483](http://arxiv.org/abs/2506.19483)|null|\n", "2506.19467": "|**2025-06-24**|**Can Large Language Models Capture Human Annotator Disagreements?**|Jingwei Ni et.al.|[2506.19467](http://arxiv.org/abs/2506.19467)|null|\n", "2506.19466": "|**2025-06-27**|**KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models**|Cheng Li et.al.|[2506.19466](http://arxiv.org/abs/2506.19466)|null|\n", "2506.19235": "|**2025-06-24**|**RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1**|Yu Xie et.al.|[2506.19235](http://arxiv.org/abs/2506.19235)|null|\n", "2506.19209": "|**2025-06-24**|**Augmenting Multi-Agent Communication with State Delta Trajectory**|Yichen Tang et.al.|[2506.19209](http://arxiv.org/abs/2506.19209)|null|\n", "2506.19171": "|**2025-06-23**|**Distilling Tool Knowledge into Language Models via Back-Translated Traces**|Xingyue Huang et.al.|[2506.19171](http://arxiv.org/abs/2506.19171)|null|\n", "2506.19143": "|**2025-06-25**|**Thought Anchors: Which LLM Reasoning Steps Matter?**|Paul C. Bogdan et.al.|[2506.19143](http://arxiv.org/abs/2506.19143)|null|\n", "2506.19140": "|**2025-06-23**|**Command-V: Pasting LLM Behaviors via Activation Profiles**|Barry Wang et.al.|[2506.19140](http://arxiv.org/abs/2506.19140)|null|\n", "2506.19113": "|**2025-06-23**|**Human-Aligned Faithfulness in Toxicity Explanations of LLMs**|Ramaravind K. Mothilal et.al.|[2506.19113](http://arxiv.org/abs/2506.19113)|null|\n", "2506.19095": "|**2025-06-23**|**Baba is LLM: Reasoning in a Game with Dynamic Rules**|Fien van Wetten et.al.|[2506.19095](http://arxiv.org/abs/2506.19095)|null|\n", "2506.19089": "|**2025-06-23**|**Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting**|Nathaniel Getachew et.al.|[2506.19089](http://arxiv.org/abs/2506.19089)|null|\n", "2506.19073": "|**2025-06-23**|**MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanation**|Jackson Trager et.al.|[2506.19073](http://arxiv.org/abs/2506.19073)|null|\n", "2506.18998": "|**2025-06-23**|**Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge**|Sahil Kale et.al.|[2506.18998](http://arxiv.org/abs/2506.18998)|null|\n", "2506.18959": "|**2025-06-26**|**From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents**|Weizhi Zhang et.al.|[2506.18959](http://arxiv.org/abs/2506.18959)|null|\n", "2506.18951": "|**2025-06-23**|**SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications**|Jinyang Li et.al.|[2506.18951](http://arxiv.org/abs/2506.18951)|null|\n", "2506.18928": "|**2025-06-21**|**Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience**|Lingyu Yang et.al.|[2506.18928](http://arxiv.org/abs/2506.18928)|null|\n", "2506.20420": "|**2025-06-25**|**Semantic Caching for Improving Web Affordability**|Hafsa Akbar et.al.|[2506.20420](http://arxiv.org/abs/2506.20420)|null|\n", "2506.20187": "|**2025-07-02**|**Breaking the Boundaries of Long-Context LLM Inference: Adaptive KV Management on a Single Commodity GPU**|He Sun et.al.|[2506.20187](http://arxiv.org/abs/2506.20187)|null|\n", "2506.20666": "|**2025-06-25**|**Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs**|Sonia K. Murthy et.al.|[2506.20666](http://arxiv.org/abs/2506.20666)|null|\n", "2506.20664": "|**2025-06-25**|**The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind**|Andrei Lupu et.al.|[2506.20664](http://arxiv.org/abs/2506.20664)|null|\n", "2506.20642": "|**2025-06-25**|**Memento: Note-Taking for Your Future Self**|Chao Wan et.al.|[2506.20642](http://arxiv.org/abs/2506.20642)|null|\n", "2506.20601": "|**2025-06-25**|**Video Perception Models for 3D Scene Synthesis**|Rui Huang et.al.|[2506.20601](http://arxiv.org/abs/2506.20601)|null|\n", "2506.20531": "|**2025-06-25**|**Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios**|Wenbin Gan et.al.|[2506.20531](http://arxiv.org/abs/2506.20531)|null|\n", "2506.20520": "|**2025-06-25**|**Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards**|Charles Arnal et.al.|[2506.20520](http://arxiv.org/abs/2506.20520)|null|\n", "2506.20495": "|**2025-06-25**|**ReCode: Updating Code API Knowledge with Reinforcement Learning**|Haoze Wu et.al.|[2506.20495](http://arxiv.org/abs/2506.20495)|null|\n", "2506.20488": "|**2025-06-25**|**Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions**|Shuo Yang et.al.|[2506.20488](http://arxiv.org/abs/2506.20488)|null|\n", "2506.20451": "|**2025-06-25**|**Automatic Demonstration Selection for LLM-based Tabular Data Classification**|Shuchu Han et.al.|[2506.20451](http://arxiv.org/abs/2506.20451)|null|\n", "2506.20430": "|**2025-06-25**|**An Agentic System for Rare Disease Diagnosis with Traceable Reasoning**|Weike Zhao et.al.|[2506.20430](http://arxiv.org/abs/2506.20430)|null|\n", "2506.20415": "|**2025-06-25**|**SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models**|Dipayan Saha et.al.|[2506.20415](http://arxiv.org/abs/2506.20415)|null|\n", "2506.20357": "|**2025-06-25**|**Tabular Feature Discovery With Reasoning Type Exploration**|Sungwon Han et.al.|[2506.20357](http://arxiv.org/abs/2506.20357)|null|\n", "2506.20274": "|**2025-06-25**|**Enterprise Large Language Model Evaluation Benchmark**|Liya Wang et.al.|[2506.20274](http://arxiv.org/abs/2506.20274)|null|\n", "2506.20241": "|**2025-06-25**|**Enhancing Large Language Models through Structured Reasoning**|Yubo Dong et.al.|[2506.20241](http://arxiv.org/abs/2506.20241)|null|\n", "2506.20167": "|**2025-06-25**|**SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs**|Fengze Li et.al.|[2506.20167](http://arxiv.org/abs/2506.20167)|null|\n", "2506.20073": "|**2025-06-25**|**A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs**|Kethmi Hirushini Hettige et.al.|[2506.20073](http://arxiv.org/abs/2506.20073)|null|\n", "2506.20020": "|**2025-06-24**|**Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning**|Saloni Dash et.al.|[2506.20020](http://arxiv.org/abs/2506.20020)|null|\n", "2506.19967": "|**2025-06-24**|**Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs**|Travis Thompson et.al.|[2506.19967](http://arxiv.org/abs/2506.19967)|null|\n", "2506.19923": "|**2025-06-24**|**Prover Agent: An Agent-based Framework for Formal Mathematical Proofs**|Kaito Baba et.al.|[2506.19923](http://arxiv.org/abs/2506.19923)|null|\n", "2506.20886": "|**2025-06-25**|**Omniwise: Predicting GPU Kernels Performance with LLMs**|Zixian Wang et.al.|[2506.20886](http://arxiv.org/abs/2506.20886)|null|\n", "2506.21551": "|**2025-07-03**|**Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test**|Ziyue Li et.al.|[2506.21551](http://arxiv.org/abs/2506.21551)|null|\n", "2506.21497": "|**2025-06-26**|**Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments**|Jiashuo Wang et.al.|[2506.21497](http://arxiv.org/abs/2506.21497)|null|\n", "2506.21285": "|**2025-06-26**|**Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning**|Xin Xu et.al.|[2506.21285](http://arxiv.org/abs/2506.21285)|null|\n", "2506.21277": "|**2025-06-26**|**HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context**|Qize Yang et.al.|[2506.21277](http://arxiv.org/abs/2506.21277)|null|\n", "2506.21220": "|**2025-06-26**|**Complexity-aware fine-tuning**|Andrey Goncharov et.al.|[2506.21220](http://arxiv.org/abs/2506.21220)|null|\n", "2506.21215": "|**2025-06-26**|**Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?**|Haoang Chi et.al.|[2506.21215](http://arxiv.org/abs/2506.21215)|null|\n", "2506.21211": "|**2025-06-26**|**$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models**|Quanming Liu et.al.|[2506.21211](http://arxiv.org/abs/2506.21211)|null|\n", "2506.21053": "|**2025-06-26**|**MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection**|Fuqiang Niu et.al.|[2506.21053](http://arxiv.org/abs/2506.21053)|null|\n", "2506.21031": "|**2025-06-26**|**Large Language Models Acing Chartered Accountancy**|Jatin Gupta et.al.|[2506.21031](http://arxiv.org/abs/2506.21031)|null|\n", "2506.21030": "|**2025-06-26**|**STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner**|Zhou Tianxing et.al.|[2506.21030](http://arxiv.org/abs/2506.21030)|null|\n", "2506.20921": "|**2025-06-26**|**LLM-guided Chemical Process Optimization with a Multi-Agent Approach**|Tong Zeng et.al.|[2506.20921](http://arxiv.org/abs/2506.20921)|null|\n", "2506.20911": "|**2025-06-26**|**FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing**|Advait Gupta et.al.|[2506.20911](http://arxiv.org/abs/2506.20911)|null|\n", "2506.20822": "|**2025-06-25**|**Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes**|Quintin Myers et.al.|[2506.20822](http://arxiv.org/abs/2506.20822)|null|\n", "2506.20821": "|**2025-06-25**|**MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering**|Chinmay Gondhalekar et.al.|[2506.20821](http://arxiv.org/abs/2506.20821)|null|\n", "2506.20815": "|**2025-06-25**|**Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications**|Xinye Tang et.al.|[2506.20815](http://arxiv.org/abs/2506.20815)|null|\n", "2506.20747": "|**2025-06-25**|**Towards Probabilistic Question Answering Over Tabular Data**|Chen Shen et.al.|[2506.20747](http://arxiv.org/abs/2506.20747)|null|\n", "2506.20729": "|**2025-06-25**|**Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset**|Zhiqi Gao et.al.|[2506.20729](http://arxiv.org/abs/2506.20729)|null|\n", "2506.22396": "|**2025-06-27**|**QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization**|Danush Khanna et.al.|[2506.22396_(ISS)](http://arxiv.org/abs/2506.22396)|null|\n", "2506.22033": "|**2025-06-27**|**SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference**|Yongchao He et.al.|[2506.22033](http://arxiv.org/abs/2506.22033)|null|\n", "2506.21901": "|**2025-06-27**|**A Survey of LLM Inference Systems**|James Pan et.al.|[2506.21901](http://arxiv.org/abs/2506.21901)|null|\n", "2506.21593": "|**2025-06-18**|**PentaRAG: Large-Scale Intelligent Knowledge Retrieval for Enterprise LLM Applications**|Abu Hanif Muhammad Syarubany et.al.|[2506.21593_(ICS)](http://arxiv.org/abs/2506.21593)|null|\n", "2506.21590": "|**2025-06-18**|**Representation Consistency for Accurate and Coherent LLM Answer Aggregation**|Junqi Jiang et.al.|[2506.21590](http://arxiv.org/abs/2506.21590)|null|\n", "2506.22419": "|**2025-06-30**|**The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements**|Bingchen Zhao et.al.|[2506.22419](http://arxiv.org/abs/2506.22419)|null|\n", "2506.22385": "|**2025-06-27**|**Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment**|Yue Zhang et.al.|[2506.22385](http://arxiv.org/abs/2506.22385)|null|\n", "2506.22376": "|**2025-06-27**|**Probabilistic Optimality for Inference-time Scaling**|Youkang Wang et.al.|[2506.22376](http://arxiv.org/abs/2506.22376)|null|\n", "2506.22359": "|**2025-06-27**|**Concept-Level AI for Telecom: Moving Beyond Large Language Models**|Viswanath Kumarskandpriya et.al.|[2506.22359](http://arxiv.org/abs/2506.22359)|null|\n", "2506.22200": "|**2025-06-30**|**EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework**|Chen Wang et.al.|[2506.22200](http://arxiv.org/abs/2506.22200)|null|\n", "2506.22157": "|**2025-06-27**|**Training Language Model to Critique for Better Refinement**|Tianshu Yu et.al.|[2506.22157](http://arxiv.org/abs/2506.22157)|null|\n", "2506.22058": "|**2025-06-27**|**Lost at the Beginning of Reasoning**|Baohao Liao et.al.|[2506.22058](http://arxiv.org/abs/2506.22058)|null|\n", "2506.22028": "|**2025-06-27**|**LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies**|Ossi Parikka et.al.|[2506.22028](http://arxiv.org/abs/2506.22028)|null|\n", "2506.22026": "|**2025-06-27**|**Literature-Grounded Novelty Assessment of Scientific Ideas**|Simra Shahid et.al.|[2506.22026](http://arxiv.org/abs/2506.22026)|null|\n", "2506.21967": "|**2025-06-27**|**More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents**|Weimin Xiong et.al.|[2506.21967](http://arxiv.org/abs/2506.21967)|null|\n", "2506.21934": "|**2025-06-27**|**CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design**|Najmeh Forouzandehmehr et.al.|[2506.21934](http://arxiv.org/abs/2506.21934)|null|\n", "2506.21931": "|**2025-06-27**|**ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation**|Reza Yousefi Maragheh et.al.|[2506.21931](http://arxiv.org/abs/2506.21931)|null|\n", "2506.21924": "|**2025-06-27**|**SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding**|Zhao Jin et.al.|[2506.21924](http://arxiv.org/abs/2506.21924)|null|\n", "2506.21783": "|**2025-06-26**|**Evaluating List Construction and Temporal Understanding capabilities of Large Language Models**|Alexandru Dumitru et.al.|[2506.21783](http://arxiv.org/abs/2506.21783)|null|\n", "2506.21763": "|**2025-06-26**|**THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?**|Xin Wang et.al.|[2506.21763](http://arxiv.org/abs/2506.21763)|null|\n", "2506.21734": "|**2025-06-26**|**Hierarchical Reasoning Model**|Guan Wang et.al.|[2506.21734](http://arxiv.org/abs/2506.21734)|null|\n", "2506.21669": "|**2025-06-26**|**SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents**|Wanxin Tian et.al.|[2506.21669](http://arxiv.org/abs/2506.21669)|null|\n", "2506.21655": "|**2025-06-26**|**APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization**|Minjie Hong et.al.|[2506.21655](http://arxiv.org/abs/2506.21655)|null|\n", "2506.22791": "|**2025-07-15**|**ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models**|Jianxin Yan et.al.|[2506.22791](http://arxiv.org/abs/2506.22791)|null|\n", "2506.24119": "|**2025-07-01**|**SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning**|Bo Liu et.al.|[2506.24119](http://arxiv.org/abs/2506.24119)|null|\n", "2506.24006": "|**2025-06-30**|**Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective**|Anselm R. Strohmaier et.al.|[2506.24006](http://arxiv.org/abs/2506.24006)|null|\n", "2506.23888": "|**2025-06-30**|**Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting**|Andr\u00e9 de Souza Loureiro et.al.|[2506.23888](http://arxiv.org/abs/2506.23888)|null|\n", "2506.23864": "|**2025-06-30**|**Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It**|Seyed Mahed Mousavi et.al.|[2506.23864](http://arxiv.org/abs/2506.23864)|null|\n", "2506.23844": "|**2025-06-30**|**A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents**|Hang Su et.al.|[2506.23844](http://arxiv.org/abs/2506.23844)|null|\n", "2506.23719": "|**2025-06-30**|**DABstep: Data Agent Benchmark for Multi-step Reasoning**|Alex Egg et.al.|[2506.23719](http://arxiv.org/abs/2506.23719)|null|\n", "2506.23694": "|**2025-06-30**|**If You Had to Pitch Your Ideal Software -- Evaluating Large Language Models to Support User Scenario Writing for User Experience Experts and Laypersons**|Patrick Stadler et.al.|[2506.23694](http://arxiv.org/abs/2506.23694)|null|\n", "2506.23689": "|**2025-06-30**|**Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red**|Zihao Liu et.al.|[2506.23689](http://arxiv.org/abs/2506.23689)|null|\n", "2506.23678": "|**2025-06-30**|**Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models**|Rock Yuren Pang et.al.|[2506.23678](http://arxiv.org/abs/2506.23678)|null|\n", "2506.23643": "|**2025-06-30**|**Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation**|Yifan Wang et.al.|[2506.23643](http://arxiv.org/abs/2506.23643)|null|\n", "2506.23463": "|**2025-06-30**|**What to Keep and What to Drop: Adaptive Table Filtering Framework**|Jang Won June et.al.|[2506.23463](http://arxiv.org/abs/2506.23463)|null|\n", "2506.23408": "|**2025-06-29**|**Do LLMs Dream of Discrete Algorithms?**|Claudionor Coelho Jr et.al.|[2506.23408](http://arxiv.org/abs/2506.23408)|null|\n", "2506.23352": "|**2025-06-29**|**GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields**|Shunsuke Yasuki et.al.|[2506.23352](http://arxiv.org/abs/2506.23352)|null|\n", "2506.23276": "|**2025-06-29**|**Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games**|David Guzman Piedrahita et.al.|[2506.23276](http://arxiv.org/abs/2506.23276)|null|\n", "2506.23274": "|**2025-06-29**|**Predicting thinking time in Reasoning models**|Hans Peter Lynsg\u00f8e Raaschou-jensen et.al.|[2506.23274](http://arxiv.org/abs/2506.23274)|null|\n", "2506.23270": "|**2025-06-29**|**Token Activation Map to Visually Explain Multimodal LLMs**|Yi Li et.al.|[2506.23270](http://arxiv.org/abs/2506.23270)|null|\n", "2506.23139": "|**2025-06-29**|**Benchmarking Deep Search over Heterogeneous Enterprise Data**|Prafulla Kumar Choubey et.al.|[2506.23139](http://arxiv.org/abs/2506.23139)|null|\n", "2506.23133": "|**2025-06-29**|**Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format**|Dingzirui Wang et.al.|[2506.23133](http://arxiv.org/abs/2506.23133)|null|\n", "2506.23128": "|**2025-06-29**|**Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons**|Chi Chiu So et.al.|[2506.23128](http://arxiv.org/abs/2506.23128)|null|\n", "2506.23122": "|**2025-06-29**|**Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models**|Shivam Sharma et.al.|[2506.23122](http://arxiv.org/abs/2506.23122)|null|\n", "2506.23120": "|**2025-06-29**|**Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation**|Zhenhua Ning et.al.|[2506.23120](http://arxiv.org/abs/2506.23120)|null|\n", "2506.23100": "|**2025-06-29**|**Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search**|Jiayi Zhang et.al.|[2506.23100](http://arxiv.org/abs/2506.23100)|null|\n", "2506.23056": "|**2025-06-29**|**Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning**|Xiang Zhuang et.al.|[2506.23056](http://arxiv.org/abs/2506.23056)|null|\n", "2506.23049": "|**2025-06-29**|**AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks**|Leander Melroy Maben et.al.|[2506.23049](http://arxiv.org/abs/2506.23049)|null|\n", "2506.22957": "|**2025-06-28**|**Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models**|Younwoo Choi et.al.|[2506.22957](http://arxiv.org/abs/2506.22957)|null|\n", "2506.22954": "|**2025-06-28**|**Evaluating and Improving Large Language Models for Competitive Program Generation**|Minnan Wei et.al.|[2506.22954](http://arxiv.org/abs/2506.22954)|null|\n", "2506.22920": "|**2025-06-28**|**Improving Rationality in the Reasoning Process of Language Models through Self-playing Game**|Pinzheng Wang et.al.|[2506.22920](http://arxiv.org/abs/2506.22920)|null|\n", "2506.22865": "|**2025-06-28**|**ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models**|Ziqi Zhong et.al.|[2506.22865](http://arxiv.org/abs/2506.22865)|null|\n", "2506.22819": "|**2025-06-28**|**Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration**|Ramya Hebbalaguppe et.al.|[2506.22819](http://arxiv.org/abs/2506.22819)|null|\n", "2506.22653": "|**2025-06-27**|**URSA: The Universal Research and Scientific Agent**|Michael Grosskopf et.al.|[2506.22653](http://arxiv.org/abs/2506.22653)|null|\n", "2506.22636": "|**2025-06-27**|**ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models**|Sotirios Panagiotis Chytas et.al.|[2506.22636](http://arxiv.org/abs/2506.22636)|null|\n", "2506.22578": "|**2025-06-27**|**The Hidden Link Between RLHF and Contrastive Learning**|Xufei Lv et.al.|[2506.22578](http://arxiv.org/abs/2506.22578)|null|\n", "2506.22557": "|**2025-06-27**|**MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs**|Boyuan Chen et.al.|[2506.22557](http://arxiv.org/abs/2506.22557)|null|\n", "2506.22518": "|**2025-06-26**|**Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation**|Deyu Zou et.al.|[2506.22518](http://arxiv.org/abs/2506.22518)|null|\n", "2507.01438": "|**2025-07-02**|**EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices**|Zheyu Shen et.al.|[2507.01438](http://arxiv.org/abs/2507.01438)|null|\n", "2507.01216": "|**2025-08-09**|**PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning**|Xingke Yang et.al.|[2507.01216](http://arxiv.org/abs/2507.01216)|null|\n", "2507.01154": "|**2025-07-01**|**FlashDP: Private Training Large Language Models with Efficient DP-SGD**|Liangyu Wang et.al.|[2507.01154](http://arxiv.org/abs/2507.01154)|null|\n", "2507.00797": "|**2025-07-01**|**VEDA: Efficient LLM Generation Through Voting-based KV Cache Eviction and Dataflow-flexible Accelerator**|Zhican Wang et.al.|[2507.00797_(DAC)](http://arxiv.org/abs/2507.00797)|null|\n", "2507.00715": "|**2025-07-01**|**EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens**|Chaoqun Yang et.al.|[2507.00715_(KDD)](http://arxiv.org/abs/2507.00715)|null|\n", "2507.01936": "|**2025-07-02**|**The Thin Line Between Comprehension and Persuasion in LLMs**|Adrian de Wynter et.al.|[2507.01936](http://arxiv.org/abs/2507.01936)|null|\n", "2507.01930": "|**2025-07-03**|**Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations**|Wenhao Wang et.al.|[2507.01930](http://arxiv.org/abs/2507.01930)|null|\n", "2507.01903": "|**2025-07-02**|**AI4Research: A Survey of Artificial Intelligence for Scientific Research**|Qiguang Chen et.al.|[2507.01903](http://arxiv.org/abs/2507.01903)|null|\n", "2507.01887": "|**2025-07-02**|**MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants**|Dongyi Ding et.al.|[2507.01887](http://arxiv.org/abs/2507.01887)|null|\n", "2507.01862": "|**2025-07-02**|**Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents**|Sanjay Krishna Anbalagan et.al.|[2507.01862](http://arxiv.org/abs/2507.01862)|null|\n", "2507.01853": "|**2025-07-07**|**Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages**|Samridhi Raj Sinha et.al.|[2507.01853](http://arxiv.org/abs/2507.01853)|null|\n", "2507.01752": "|**2025-07-02**|**Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training**|Ismail Labiad et.al.|[2507.01752](http://arxiv.org/abs/2507.01752)|null|\n", "2507.01701": "|**2025-07-02**|**Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture**|Bochen Han et.al.|[2507.01701](http://arxiv.org/abs/2507.01701)|null|\n", "2507.01679": "|**2025-07-02**|**Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling**|Zeyu Huang et.al.|[2507.01679](http://arxiv.org/abs/2507.01679)|null|\n", "2507.01599": "|**2025-07-02**|**Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems**|Zhaoyan Sun et.al.|[2507.01599](http://arxiv.org/abs/2507.01599)|null|\n", "2507.01551": "|**2025-07-03**|**Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning**|Wu Fei et.al.|[2507.01551](http://arxiv.org/abs/2507.01551)|null|\n", "2507.01543": "|**2025-07-02**|**Is External Information Useful for Stance Detection with LLMs?**|Quang Minh Nguyen et.al.|[2507.01543](http://arxiv.org/abs/2507.01543)|null|\n", "2507.01513": "|**2025-07-02**|**SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism**|Beitao Chen et.al.|[2507.01513](http://arxiv.org/abs/2507.01513)|null|\n", "2507.01489": "|**2025-07-02**|**Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning**|Yanfei Zhang et.al.|[2507.01489](http://arxiv.org/abs/2507.01489)|null|\n", "2507.01485": "|**2025-07-02**|**BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments**|Yibo Qiu et.al.|[2507.01485](http://arxiv.org/abs/2507.01485)|null|\n", "2507.01444": "|**2025-07-02**|**A Large Language Model for Chemistry and Retrosynthesis Predictions**|Yueqing Zhang et.al.|[2507.01444](http://arxiv.org/abs/2507.01444)|null|\n", "2507.01378": "|**2025-07-02**|**RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms**|Ziyao Wang et.al.|[2507.01378](http://arxiv.org/abs/2507.01378)|null|\n", "2507.01376": "|**2025-07-02**|**AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing**|Yinwang Ren et.al.|[2507.01376](http://arxiv.org/abs/2507.01376)|null|\n", "2507.01334": "|**2025-07-03**|**Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs**|Nifu Dan et.al.|[2507.01334](http://arxiv.org/abs/2507.01334)|null|\n", "2507.01282": "|**2025-07-02**|**Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care**|Matthew JY Kang et.al.|[2507.01282](http://arxiv.org/abs/2507.01282)|null|\n", "2507.01278": "|**2025-07-02**|**Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening**|Cindy Lie Tabuse et.al.|[2507.01278](http://arxiv.org/abs/2507.01278)|null|\n", "2507.00971": "|**2025-07-01**|**Reasoning as an Adaptive Defense for Safety**|Taeyoun Kim et.al.|[2507.00971](http://arxiv.org/abs/2507.00971)|null|\n", "2507.00914": "|**2025-07-01**|**Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications**|Jindong Han et.al.|[2507.00914](http://arxiv.org/abs/2507.00914)|null|\n", "2507.00883": "|**2025-07-01**|**Mathematics Isn't Culture-Free: Probing Cultural Gaps via Entity and Scenario Perturbations**|Aditya Tomar et.al.|[2507.00883](http://arxiv.org/abs/2507.00883)|null|\n", "2507.00833": "|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Zhi Jing et.al.|[2507.00833](http://arxiv.org/abs/2507.00833)|null|\n", "2507.00828": "|**2025-07-01**|**ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering**|Alexander Hoyle et.al.|[2507.00828](http://arxiv.org/abs/2507.00828)|null|\n", "2507.00814": "|**2025-07-01**|**Many LLMs Are More Utilitarian Than One**|Anita Keshmirian et.al.|[2507.00814](http://arxiv.org/abs/2507.00814)|null|\n", "2507.00754": "|**2025-07-01**|**Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs**|Selim Kuzucu et.al.|[2507.00754](http://arxiv.org/abs/2507.00754)|null|\n", "2507.00726": "|**2025-07-02**|**Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess**|Dongyoon Hwang et.al.|[2507.00726](http://arxiv.org/abs/2507.00726)|null|\n", "2507.00718": "|**2025-07-01**|**AI Analyst: Framework and Comprehensive Evaluation of Large Language Models for Financial Time Series Report Generation**|Elizabeth Fons et.al.|[2507.00718](http://arxiv.org/abs/2507.00718)|null|\n", "2507.00711": "|**2025-07-01**|**Large Reasoning Models are not thinking straight: on the unreliability of thinking trajectories**|Jhouben Cuesta-Ramirez et.al.|[2507.00711](http://arxiv.org/abs/2507.00711)|null|\n", "2507.00672": "|**2025-07-01**|**Toward Edge General Intelligence with Multiple-Large Language Model (Multi-LLM): Architecture, Trust, and Orchestration**|Haoxiang Luo et.al.|[2507.00672](http://arxiv.org/abs/2507.00672)|null|\n", "2507.00653": "|**2025-07-01**|**Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models**|Yilun Zhang et.al.|[2507.00653](http://arxiv.org/abs/2507.00653)|null|\n", "2507.00642": "|**2025-07-01**|**ChatHLS: Towards Systematic Design Automation and Optimization for High-Level Synthesis**|Runkai Li et.al.|[2507.00642](http://arxiv.org/abs/2507.00642)|null|\n", "2507.00606": "|**2025-07-03**|**Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies**|Tao Xiong et.al.|[2507.00606](http://arxiv.org/abs/2507.00606)|null|\n", "2507.00432": "|**2025-07-01**|**Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning**|Maggie Huan et.al.|[2507.00432](http://arxiv.org/abs/2507.00432)|null|\n", "2507.00417": "|**2025-07-01**|**ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context**|Joongwon Kim et.al.|[2507.00417](http://arxiv.org/abs/2507.00417)|null|\n", "2507.00389": "|**2025-07-01**|**Causal Prompting for Implicit Sentiment Analysis with Large Language Models**|Jing Ren et.al.|[2507.00389](http://arxiv.org/abs/2507.00389)|null|\n", "2507.00316": "|**2025-07-02**|**$\u03bc^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation**|Siyou Li et.al.|[2507.00316](http://arxiv.org/abs/2507.00316)|null|\n", "2507.00214": "|**2025-06-30**|**Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning**|Mads Henrichsen et.al.|[2507.00214](http://arxiv.org/abs/2507.00214)|null|\n", "2507.00092": "|**2025-06-30**|**Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models**|Basab Jha et.al.|[2507.00092](http://arxiv.org/abs/2507.00092)|null|\n", "2507.00081": "|**2025-06-30**|**State and Memory is All You Need for Robust and Reliable AI Agents**|Matthew Muhoberac et.al.|[2507.00081](http://arxiv.org/abs/2507.00081)|null|\n", "2507.02659": "|**2025-07-31**|**OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding**|Ramchalam Kinattinkara Ramakrishnan et.al.|[2507.02659](http://arxiv.org/abs/2507.02659)|null|\n", "2507.02859": "|**2025-07-03**|**Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation**|Jiaer Xia et.al.|[2507.02859](http://arxiv.org/abs/2507.02859)|null|\n", "2507.02851": "|**2025-07-03**|**MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs**|Purbesh Mitra et.al.|[2507.02851](http://arxiv.org/abs/2507.02851)|null|\n", "2507.02841": "|**2025-07-03**|**StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason**|Kaiyi Zhang et.al.|[2507.02841](http://arxiv.org/abs/2507.02841)|null|\n", "2507.02822": "|**2025-07-03**|**SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model**|Wencheng Zhang et.al.|[2507.02822](http://arxiv.org/abs/2507.02822)|null|\n", "2507.02804": "|**2025-07-03**|**Multimodal Mathematical Reasoning with Diverse Solving Perspective**|Wenhao Shi et.al.|[2507.02804](http://arxiv.org/abs/2507.02804)|null|\n", "2507.02799": "|**2025-07-03**|**Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models**|Riccardo Cantini et.al.|[2507.02799](http://arxiv.org/abs/2507.02799)|null|\n", "2507.02788": "|**2025-07-03**|**Moral Responsibility or Obedience: What Do We Want from AI?**|Joseph Boland et.al.|[2507.02788](http://arxiv.org/abs/2507.02788)|null|\n", "2507.02778": "|**2025-07-03**|**Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs**|Ken Tsui et.al.|[2507.02778](http://arxiv.org/abs/2507.02778)|null|\n", "2507.02773": "|**2025-07-06**|**KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs**|Yuzhang Xie et.al.|[2507.02773](http://arxiv.org/abs/2507.02773)|null|\n", "2507.02760": "|**2025-07-03**|**Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work**|Guangwei Zhang et.al.|[2507.02760](http://arxiv.org/abs/2507.02760)|null|\n", "2507.02737": "|**2025-07-03**|**Early Signs of Steganographic Capabilities in Frontier LLMs**|Artur Zolkowski et.al.|[2507.02737](http://arxiv.org/abs/2507.02737)|null|\n", "2507.02726": "|**2025-07-03**|**Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving**|Matthieu Zimmer et.al.|[2507.02726](http://arxiv.org/abs/2507.02726)|null|\n", "2507.02699": "|**2025-07-03**|**Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents**|Jiangrong Wu et.al.|[2507.02699](http://arxiv.org/abs/2507.02699)|null|\n", "2507.02626": "|**2025-07-03**|**VRAgent-R1: Boosting Video Recommendation with MLLM-based Agents via Reinforcement Learning**|Siran Chen et.al.|[2507.02626](http://arxiv.org/abs/2507.02626)|null|\n", "2507.02618": "|**2025-07-03**|**Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory**|Kenneth Payne et.al.|[2507.02618](http://arxiv.org/abs/2507.02618)|null|\n", "2507.02616": "|**2025-07-03**|**DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making**|Tianqi Shang et.al.|[2507.02616](http://arxiv.org/abs/2507.02616)|null|\n", "2507.02592": "|**2025-07-03**|**WebSailor: Navigating Super-human Reasoning for Web Agent**|Kuan Li et.al.|[2507.02592](http://arxiv.org/abs/2507.02592)|null|\n", "2507.02541": "|**2025-07-03**|**Clarifying Before Reasoning: A Coq Prover with Structural Context**|Yanzhen Lu et.al.|[2507.02541](http://arxiv.org/abs/2507.02541)|null|\n", "2507.02424": "|**2025-07-03**|**CyberRAG: An agentic RAG cyber attack classification and reporting tool**|Francesco Blefari et.al.|[2507.02424](http://arxiv.org/abs/2507.02424)|null|\n", "2507.02353": "|**2025-07-03**|**OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent**|Bowen Chen et.al.|[2507.02353](http://arxiv.org/abs/2507.02353)|null|\n", "2507.02283": "|**2025-07-03**|**Misaligned from Within: Large Language Models Reproduce Our Double-Loop Learning Blindness**|Tim Rogers et.al.|[2507.02283](http://arxiv.org/abs/2507.02283)|null|\n", "2507.02256": "|**2025-07-03**|**Uncertainty-aware Reward Design Process**|Yang Yang et.al.|[2507.02256](http://arxiv.org/abs/2507.02256)|null|\n", "2507.02253": "|**2025-07-03**|**Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation**|Jungkoo Kang et.al.|[2507.02253](http://arxiv.org/abs/2507.02253)|null|\n", "2507.02173": "|**2025-07-02**|**Data Diversification Methods In Alignment Enhance Math Performance In LLMs**|Berkan Dokmeci et.al.|[2507.02173](http://arxiv.org/abs/2507.02173)|null|\n", "2507.02170": "|**2025-07-02**|**Synergizing Logical Reasoning, Knowledge Management and Collaboration in Multi-Agent LLM System**|Adam Kostka et.al.|[2507.02170](http://arxiv.org/abs/2507.02170)|null|\n", "2507.02145": "|**2025-07-02**|**Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization**|Keyan Jin et.al.|[2507.02145](http://arxiv.org/abs/2507.02145)|null|\n", "2507.02107": "|**2025-07-02**|**Structural Code Search using Natural Language Queries**|Ben Limpanukorn et.al.|[2507.02107](http://arxiv.org/abs/2507.02107)|null|\n", "2507.02076": "|**2025-07-02**|**Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs**|Mohammad Ali Alomrani et.al.|[2507.02076](http://arxiv.org/abs/2507.02076)|null|\n", "2507.02074": "|**2025-07-02**|**Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges**|Sanjeda Akter et.al.|[2507.02074](http://arxiv.org/abs/2507.02074)|null|\n", "2507.02004": "|**2025-07-01**|**STELLA: Self-Evolving LLM Agent for Biomedical Research**|Ruofan Jin et.al.|[2507.02004](http://arxiv.org/abs/2507.02004)|null|\n", "2507.02002": "|**2025-07-01**|**Dynamic Strategy Adaptation in Multi-Agent Environments with Large Language Models**|Shaurya Mallampati et.al.|[2507.02002](http://arxiv.org/abs/2507.02002)|null|\n", "2507.05240": "|**2025-07-07**|**StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling**|Meng Wei et.al.|[2507.05240](http://arxiv.org/abs/2507.05240)|null|\n", "2507.04967": "|**2025-07-07**|**The Case for Instance-Optimized LLMs in OLAP Databases**|Bardia Mohammadi et.al.|[2507.04967](http://arxiv.org/abs/2507.04967)|null|\n", "2507.04697": "|**2025-07-07**|**Performance Evaluation of General Purpose Large Language Models for Basic Linear Algebra Subprograms Code Generation**|Daichi Mukunoki et.al.|[2507.04697](http://arxiv.org/abs/2507.04697)|null|\n", "2507.03153": "|**2025-07-03**|**HGCA: Hybrid GPU-CPU Attention for Long Context LLM Inference**|Weishu Deng et.al.|[2507.03153](http://arxiv.org/abs/2507.03153)|null|\n", "2507.05258": "|**2025-07-07**|**Spatio-Temporal LLM: Reasoning about Environments and Actions**|Haozhen Zheng et.al.|[2507.05258](http://arxiv.org/abs/2507.05258)|null|\n", "2507.05257": "|**2025-07-07**|**Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions**|Yuanzhe Hu et.al.|[2507.05257](http://arxiv.org/abs/2507.05257)|null|\n", "2507.05255": "|**2025-07-07**|**Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning**|Yana Wei et.al.|[2507.05255](http://arxiv.org/abs/2507.05255)|null|\n", "2507.05179": "|**2025-07-07**|**From Fragments to Facts: A Curriculum-Driven DPO Approach for Generating Hindi News Veracity Explanations**|Pulkit Bansal et.al.|[2507.05179](http://arxiv.org/abs/2507.05179)|null|\n", "2507.05178": "|**2025-07-07**|**CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale**|Jonathan Hyun et.al.|[2507.05178](http://arxiv.org/abs/2507.05178)|null|\n", "2507.05118": "|**2025-07-07**|**VerifyLLM: LLM-Based Pre-Execution Task Plan Verification for Robots**|Danil S. Grigorev et.al.|[2507.05118](http://arxiv.org/abs/2507.05118)|null|\n", "2507.04996": "|**2025-07-07**|**From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems**|Jiangbo Yu et.al.|[2507.04996](http://arxiv.org/abs/2507.04996)|null|\n", "2507.04893": "|**2025-07-07**|**MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction**|Kaleem Ullah Qasim et.al.|[2507.04893](http://arxiv.org/abs/2507.04893)|null|\n", "2507.04886": "|**2025-07-07**|**Emergent Semantics Beyond Token Embeddings: Transformer LMs with Frozen Visual Unicode Representations**|A. Bochkov et.al.|[2507.04886](http://arxiv.org/abs/2507.04886)|null|\n", "2507.04770": "|**2025-07-07**|**FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System**|Toan Nguyen et.al.|[2507.04770](http://arxiv.org/abs/2507.04770)|null|\n", "2507.04766": "|**2025-07-07**|**ABench-Physics: Benchmarking Physical Reasoning in LLMs via High-Difficulty and Dynamic Physics Problems**|Yiming Zhang et.al.|[2507.04766](http://arxiv.org/abs/2507.04766)|null|\n", "2507.04752": "|**2025-07-07**|**Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions**|Shuo Yang et.al.|[2507.04752](http://arxiv.org/abs/2507.04752)|null|\n", "2507.04748": "|**2025-07-07**|**LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction**|Sungmin Lee et.al.|[2507.04748](http://arxiv.org/abs/2507.04748)|null|\n", "2507.04742": "|**2025-07-08**|**Activation Steering for Chain-of-Thought Compression**|Seyedarmin Azizi et.al.|[2507.04742](http://arxiv.org/abs/2507.04742)|null|\n", "2507.04708": "|**2025-07-07**|**Why We Feel What We Feel: Joint Detection of Emotions and Their Opinion Triggers in E-commerce**|Arnav Attri et.al.|[2507.04708](http://arxiv.org/abs/2507.04708)|null|\n", "2507.04706": "|**2025-07-07**|**UrbanMind: Towards Urban General Intelligence via Tool-Enhanced Retrieval-Augmented Generation and Multilevel Optimization**|Kai Yang et.al.|[2507.04706](http://arxiv.org/abs/2507.04706)|null|\n", "2507.04673": "|**2025-07-07**|**Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message**|Wei Duan et.al.|[2507.04673](http://arxiv.org/abs/2507.04673)|null|\n", "2507.04664": "|**2025-07-07**|**VectorLLM: Human-like Extraction of Structured Building Contours vis Multimodal LLMs**|Tao Zhang et.al.|[2507.04664](http://arxiv.org/abs/2507.04664)|null|\n", "2507.04632": "|**2025-07-07**|**Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?**|Yun Qu et.al.|[2507.04632](http://arxiv.org/abs/2507.04632)|null|\n", "2507.04621": "|**2025-07-07**|**Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences**|Yusong Zhang et.al.|[2507.04621](http://arxiv.org/abs/2507.04621)|null|\n", "2507.04453": "|**2025-07-06**|**ESSA: Evolutionary Strategies for Scalable Alignment**|Daria Korotyshova et.al.|[2507.04453](http://arxiv.org/abs/2507.04453)|null|\n", "2507.04412": "|**2025-07-06**|**SFOOD: A Multimodal Benchmark for Comprehensive Food Attribute Analysis Beyond RGB with Spectral Insights**|Zhenbo Xu et.al.|[2507.04412](http://arxiv.org/abs/2507.04412)|null|\n", "2507.04404": "|**2025-07-06**|**LayerCake: Token-Aware Contrastive Decoding within Large Language Model Layers**|Jingze Zhu et.al.|[2507.04404](http://arxiv.org/abs/2507.04404)|null|\n", "2507.04333": "|**2025-07-06**|**Computed Tomography Visual Question Answering with Cross-modal Feature Graphing**|Yuanhe Tian et.al.|[2507.04333](http://arxiv.org/abs/2507.04333)|null|\n", "2507.04295": "|**2025-07-06**|**LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop**|Runcong Zhao et.al.|[2507.04295](http://arxiv.org/abs/2507.04295)|null|\n", "2507.04293": "|**2025-07-06**|**AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning**|Weixing Chen et.al.|[2507.04293](http://arxiv.org/abs/2507.04293)|null|\n", "2507.04289": "|**2025-07-06**|**M$^3$-Med: A Benchmark for Multi-lingual, Multi-modal, and Multi-hop Reasoning in Medical Instructional Video Understanding**|Shenxi Liu et.al.|[2507.04289](http://arxiv.org/abs/2507.04289)|null|\n", "2507.04189": "|**2025-07-05**|**SymbolicThought: Integrating Language Models and Symbolic Reasoning for Consistent and Interpretable Human Relationship Understanding**|Runcong Zhao et.al.|[2507.04189](http://arxiv.org/abs/2507.04189)|null|\n", "2507.04185": "|**2025-07-05**|**From Legal Text to Tech Specs: Generative AI's Interpretation of Consent in Privacy Law**|Aniket Kesari et.al.|[2507.04185](http://arxiv.org/abs/2507.04185)|null|\n", "2507.04142": "|**2025-07-05**|**Dissecting Clinical Reasoning in Language Models: A Comparative Study of Prompts and Model Adaptation Strategies**|Mael Jullien et.al.|[2507.04142](http://arxiv.org/abs/2507.04142)|null|\n", "2507.04136": "|**2025-07-05**|**A Technical Survey of Reinforcement Learning Techniques for Large Language Models**|Saksham Sahai Srivastava et.al.|[2507.04136](http://arxiv.org/abs/2507.04136)|null|\n", "2507.04127": "|**2025-07-05**|**BYOKG-RAG: Multi-Strategy Graph Retrieval for Knowledge Graph Question Answering**|Costas Mavromatis et.al.|[2507.04127](http://arxiv.org/abs/2507.04127)|null|\n", "2507.04069": "|**2025-07-05**|**Beyond Independent Passages: Adaptive Passage Combination Retrieval for Retrieval Augmented Open-Domain Question Answering**|Ting-Wen Ko et.al.|[2507.04069](http://arxiv.org/abs/2507.04069)|null|\n", "2507.04023": "|**2025-07-05**|**LLMThinkBench: Towards Basic Math Reasoning and Overthinking in Large Language Models**|Gaurav Srivastava et.al.|[2507.04023](http://arxiv.org/abs/2507.04023)|null|\n", "2507.04014": "|**2025-07-05**|**Nunchi-Bench: Benchmarking Language Models on Cultural Reasoning with a Focus on Korean Superstition**|Kyuhee Kim et.al.|[2507.04014](http://arxiv.org/abs/2507.04014)|null|\n", "2507.03998": "|**2025-07-05**|**Toward Better Generalisation in Uncertainty Estimators: Leveraging Data-Agnostic Features**|Thuy An Ha et.al.|[2507.03998](http://arxiv.org/abs/2507.03998)|null|\n", "2507.03984": "|**2025-07-05**|**CoT-Segmenter: Enhancing OOD Detection in Dense Road Scenes via Chain-of-Thought Reasoning**|Jeonghyo Song et.al.|[2507.03984](http://arxiv.org/abs/2507.03984)|null|\n", "2507.03958": "|**2025-07-05**|**A Comparative Study of Specialized LLMs as Dense Retrievers**|Hengran Zhang et.al.|[2507.03958](http://arxiv.org/abs/2507.03958)|null|\n", "2507.03928": "|**2025-07-05**|**CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate**|Yiliu Sun et.al.|[2507.03928](http://arxiv.org/abs/2507.03928)|null|\n", "2507.03834": "|**2025-07-04**|**Economic Evaluation of LLMs**|Michael J. Zellinger et.al.|[2507.03834](http://arxiv.org/abs/2507.03834)|null|\n", "2507.03726": "|**2025-07-04**|**Agent-Based Detection and Resolution of Incompleteness and Ambiguity in Interactions with Large Language Models**|Riya Naik et.al.|[2507.03726](http://arxiv.org/abs/2507.03726)|null|\n", "2507.03724": "|**2025-07-08**|**MemOS: A Memory OS for AI System**|Zhiyu Li et.al.|[2507.03724](http://arxiv.org/abs/2507.03724)|null|\n", "2507.03711": "|**2025-07-09**|**Can LLMs Play \u00d4 \u0102n Quan Game? A Study of Multi-Step Planning and Decision Making**|Sang Quang Nguyen et.al.|[2507.03711](http://arxiv.org/abs/2507.03711)|null|\n", "2507.03682": "|**2025-07-04**|**Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning**|Rebekah A. Gelp\u00ed et.al.|[2507.03682](http://arxiv.org/abs/2507.03682)|null|\n", "2507.03659": "|**2025-07-04**|**Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs**|Valentina Wu et.al.|[2507.03659](http://arxiv.org/abs/2507.03659)|null|\n", "2507.03616": "|**2025-07-04**|**EvoAgentX: An Automated Framework for Evolving Agentic Workflows**|Yingxu Wang et.al.|[2507.03616](http://arxiv.org/abs/2507.03616)|null|\n", "2507.03608": "|**2025-07-04**|**Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)**|Sarat Ahmad et.al.|[2507.03608](http://arxiv.org/abs/2507.03608)|null|\n", "2507.03585": "|**2025-07-04**|**Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation**|Tao Tang et.al.|[2507.03585](http://arxiv.org/abs/2507.03585)|null|\n", "2507.03493": "|**2025-07-04**|**AI-VaxGuide: An Agentic RAG-Based LLM for Vaccination Decisions**|Abdellah Zeggai et.al.|[2507.03493](http://arxiv.org/abs/2507.03493)|null|\n", "2507.03477": "|**2025-07-04**|**REAL: Benchmarking Abilities of Large Language Models for Housing Transactions and Services**|Kexin Zhu et.al.|[2507.03477](http://arxiv.org/abs/2507.03477)|null|\n", "2507.03435": "|**2025-07-04**|**ElliottAgents: A Natural Language-Driven Multi-Agent System for Stock Market Analysis and Prediction**|Jaros\u0142aw A. Chudziak et.al.|[2507.03435](http://arxiv.org/abs/2507.03435)|null|\n", "2507.03410": "|**2025-07-04**|**Graph Repairs with Large Language Models: An Empirical Study**|Hrishikesh Terdalkar et.al.|[2507.03410](http://arxiv.org/abs/2507.03410)|null|\n", "2507.03347": "|**2025-07-04**|**Effects of structure on reasoning in instance-level Self-Discover**|Sachith Gunasekara et.al.|[2507.03347](http://arxiv.org/abs/2507.03347)|null|\n", "2507.03336": "|**2025-07-04**|**Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky**|Ashutosh Hathidara et.al.|[2507.03336](http://arxiv.org/abs/2507.03336)|null|\n", "2507.03327": "|**2025-07-04**|**Read Quietly, Think Aloud: Decoupling Comprehension and Reasoning in LLMs**|Yuanxin Wang et.al.|[2507.03327](http://arxiv.org/abs/2507.03327)|null|\n", "2507.03293": "|**2025-07-04**|**LTLCrit: A Temporal Logic-based LLM Critic for Safe and Efficient Embodied Agents**|Anand Gokhale et.al.|[2507.03293](http://arxiv.org/abs/2507.03293)|null|\n", "2507.03254": "|**2025-07-04**|**CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs**|Bruce Yang et.al.|[2507.03254](http://arxiv.org/abs/2507.03254)|null|\n", "2507.03226": "|**2025-07-04**|**Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems**|Congmin Min et.al.|[2507.03226](http://arxiv.org/abs/2507.03226)|null|\n", "2507.03224": "|**2025-07-03**|**RCA Copilot: Transforming Network Data into Actionable Insights via Large Language Models**|Alexander Shan et.al.|[2507.03224](http://arxiv.org/abs/2507.03224)|null|\n", "2507.03162": "|**2025-07-03**|**MateInfoUB: A Real-World Benchmark for Testing LLMs in Competitive, Multilingual, and Multimodal Educational Tasks**|Dumitran Adrian Marius et.al.|[2507.03162](http://arxiv.org/abs/2507.03162)|null|\n", "2507.03133": "|**2025-07-03**|**ReliableMath: Benchmark of Reliable Mathematical Reasoning on Large Language Models**|Boyang Xue et.al.|[2507.03133](http://arxiv.org/abs/2507.03133)|null|\n", "2507.03112": "|**2025-07-03**|**RLVER: Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents**|Peisong Wang et.al.|[2507.03112](http://arxiv.org/abs/2507.03112)|null|\n", "2507.03051": "|**2025-07-03**|**Improving LLM Reasoning for Vulnerability Detection via Group Relative Policy Optimization**|Marco Simoni et.al.|[2507.03051](http://arxiv.org/abs/2507.03051)|null|\n", "2507.03047": "|**2025-07-03**|**Counterfactual Tuning for Temporal Sensitivity Enhancement in Large Language Model-based Recommendation**|Yutian Liu et.al.|[2507.03047](http://arxiv.org/abs/2507.03047)|null|\n", "2507.06203": "|**2025-07-10**|**A Survey on Latent Reasoning**|Rui-Jie Zhu et.al.|[2507.06203](http://arxiv.org/abs/2507.06203)|null|\n", "2507.06167": "|**2025-07-10**|**Skywork-R1V3 Technical Report**|Wei Shen et.al.|[2507.06167](http://arxiv.org/abs/2507.06167)|null|\n", "2507.06138": "|**2025-07-08**|**Coding Triangle: How Does Large Language Model Understand Code?**|Taolin Zhang et.al.|[2507.06138](http://arxiv.org/abs/2507.06138)|null|\n", "2507.06127": "|**2025-07-08**|**PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization**|Dongsheng Zuo et.al.|[2507.06127](http://arxiv.org/abs/2507.06127)|null|\n", "2507.06057": "|**2025-07-09**|**FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models**|Bo Pang et.al.|[2507.06057](http://arxiv.org/abs/2507.06057)|null|\n", "2507.06044": "|**2025-07-08**|**Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations**|Yibin Liu et.al.|[2507.06044](http://arxiv.org/abs/2507.06044)|null|\n", "2507.06016": "|**2025-07-08**|**Conditional Multi-Stage Failure Recovery for Embodied Agents**|Youmna Farag et.al.|[2507.06016](http://arxiv.org/abs/2507.06016)|null|\n", "2507.06013": "|**2025-07-08**|**CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation**|Kushal Gajjar et.al.|[2507.06013](http://arxiv.org/abs/2507.06013)|null|\n", "2507.05997": "|**2025-07-08**|**DocIE@XLLM25: In-Context Learning for Information Extraction using Fully Synthetic Demonstrations**|Nicholas Popovi\u010d et.al.|[2507.05997](http://arxiv.org/abs/2507.05997)|null|\n", "2507.05970": "|**2025-07-08**|**Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval**|Haiwen Li et.al.|[2507.05970](http://arxiv.org/abs/2507.05970)|null|\n", "2507.05886": "|**2025-07-08**|**Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better**|Aaron Bembenek et.al.|[2507.05886](http://arxiv.org/abs/2507.05886)|null|\n", "2507.05863": "|**2025-07-08**|**KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation**|Zeyuan Meng et.al.|[2507.05863](http://arxiv.org/abs/2507.05863)|null|\n", "2507.05822": "|**2025-07-08**|**Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models**|L'ea Dubois et.al.|[2507.05822](http://arxiv.org/abs/2507.05822)|null|\n", "2507.05795": "|**2025-07-08**|**Creating a customisable freely-accessible Socratic AI physics tutor**|Eugenio Tufino et.al.|[2507.05795](http://arxiv.org/abs/2507.05795)|null|\n", "2507.05754": "|**2025-07-08**|**LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving**|Yuhang Zhang et.al.|[2507.05754](http://arxiv.org/abs/2507.05754)|null|\n", "2507.05727": "|**2025-07-08**|**ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark**|He Wang et.al.|[2507.05727](http://arxiv.org/abs/2507.05727)|null|\n", "2507.05723": "|**2025-07-08**|**Large Language Models for Agent-Based Modelling: Current and possible uses across the modelling cycle**|Lo\u00efs Vanh\u00e9e et.al.|[2507.05723](http://arxiv.org/abs/2507.05723)|null|\n", "2507.05638": "|**2025-07-08**|**LLMs are Introvert**|Litian Zhang et.al.|[2507.05638](http://arxiv.org/abs/2507.05638)|null|\n", "2507.05617": "|**2025-07-08**|**Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching**|Mingzhe Li et.al.|[2507.05617](http://arxiv.org/abs/2507.05617)|null|\n", "2507.05607": "|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Chongshan Fan et.al.|[2507.05607](http://arxiv.org/abs/2507.05607)|null|\n", "2507.05591": "|**2025-07-08**|**MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models**|Wei Zhang et.al.|[2507.05591](http://arxiv.org/abs/2507.05591)|null|\n", "2507.05568": "|**2025-07-08**|**ReLayout: Integrating Relation Reasoning for Content-aware Layout Generation with Multi-modal Large Language Models**|Jiaxu Tian et.al.|[2507.05568](http://arxiv.org/abs/2507.05568)|null|\n", "2507.05557": "|**2025-07-08**|**Enhancing Test-Time Scaling of Large Language Models with Hierarchical Retrieval-Augmented MCTS**|Alex ZH Dou et.al.|[2507.05557](http://arxiv.org/abs/2507.05557)|null|\n", "2507.05424": "|**2025-07-07**|**\"Lost-in-the-Later\": Framework for Quantifying Contextual Grounding in Large Language Models**|Yufei Tao et.al.|[2507.05424](http://arxiv.org/abs/2507.05424)|null|\n", "2507.05418": "|**2025-07-07**|**Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning**|Jaedong Hwang et.al.|[2507.05418](http://arxiv.org/abs/2507.05418)|null|\n", "2507.05362": "|**2025-07-07**|**On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study**|Riccardo Alberghi et.al.|[2507.05362](http://arxiv.org/abs/2507.05362)|null|\n", "2507.05330": "|**2025-07-07**|**MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents**|Ming Gong et.al.|[2507.05330](http://arxiv.org/abs/2507.05330)|null|\n", "2507.05289": "|**2025-07-09**|**Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models**|Igor Regis da Silva Simoes et.al.|[2507.05289](http://arxiv.org/abs/2507.05289)|null|\n", "2507.05288": "|**2025-07-05**|**A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models**|Shuliang Liu et.al.|[2507.05288](http://arxiv.org/abs/2507.05288)|null|\n", "2507.06567": "|**2025-07-09**|**SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference**|Qian Chen et.al.|[2507.06567](http://arxiv.org/abs/2507.06567)|null|\n", "2507.06517": "|**2025-07-09**|**SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers**|Zicong Tang et.al.|[2507.06517_(ACL)](http://arxiv.org/abs/2507.06517)|null|\n", "2507.07061": "|**2025-07-08**|**An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems**|Shervin Ghaffari et.al.|[2507.07061_(SC)](http://arxiv.org/abs/2507.07061)|null|\n", "2507.07106": "|**2025-07-09**|**Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor**|Vatsal Agarwal et.al.|[2507.07106](http://arxiv.org/abs/2507.07106)|null|\n", "2507.07048": "|**2025-07-09**|**Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata**|Bruce Coburn et.al.|[2507.07048](http://arxiv.org/abs/2507.07048)|null|\n", "2507.07017": "|**2025-07-09**|**First Return, Entropy-Eliciting Explore**|Tianyu Zheng et.al.|[2507.07017](http://arxiv.org/abs/2507.07017)|null|\n", "2507.06999": "|**2025-07-09**|**Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs**|Yahan Yu et.al.|[2507.06999](http://arxiv.org/abs/2507.06999)|null|\n", "2507.06980": "|**2025-07-09**|**Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation**|Binquan Zhang et.al.|[2507.06980](http://arxiv.org/abs/2507.06980)|null|\n", "2507.06920": "|**2025-07-10**|**Rethinking Verification for LLM Code Generation: From Generation to Testing**|Zihan Ma et.al.|[2507.06920](http://arxiv.org/abs/2507.06920)|null|\n", "2507.06892": "|**2025-07-11**|**Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model**|Jing Liang et.al.|[2507.06892](http://arxiv.org/abs/2507.06892)|null|\n", "2507.06838": "|**2025-07-10**|**Shifting from Ranking to Set Selection for Retrieval Augmented Generation**|Dahyun Lee et.al.|[2507.06838](http://arxiv.org/abs/2507.06838)|null|\n", "2507.06829": "|**2025-07-09**|**Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework**|Zenan Xu et.al.|[2507.06829](http://arxiv.org/abs/2507.06829)|null|\n", "2507.06742": "|**2025-07-09**|**PenTest2.0: Towards Autonomous Privilege Escalation Using GenAI**|Haitham S. Al-Sinani et.al.|[2507.06742](http://arxiv.org/abs/2507.06742)|null|\n", "2507.06719": "|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Zhenyang Liu et.al.|[2507.06719](http://arxiv.org/abs/2507.06719)|null|\n", "2507.06573": "|**2025-07-09**|**From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization**|Xinjie Chen et.al.|[2507.06573](http://arxiv.org/abs/2507.06573)|null|\n", "2507.06520": "|**2025-07-09**|**Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration**|Xinyuan Song et.al.|[2507.06520](http://arxiv.org/abs/2507.06520)|null|\n", "2507.06512": "|**2025-07-09**|**Towards LLM-based Root Cause Analysis of Hardware Design Failures**|Siyu Qiu et.al.|[2507.06512](http://arxiv.org/abs/2507.06512)|null|\n", "2507.06507": "|**2025-07-14**|**GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models**|Zhen Yang et.al.|[2507.06507](http://arxiv.org/abs/2507.06507)|null|\n", "2507.06485": "|**2025-07-09**|**Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning**|Ziyang Wang et.al.|[2507.06485](http://arxiv.org/abs/2507.06485)|null|\n", "2507.06448": "|**2025-07-13**|**Perception-Aware Policy Optimization for Multimodal Reasoning**|Zhenhailong Wang et.al.|[2507.06448](http://arxiv.org/abs/2507.06448)|null|\n", "2507.06427": "|**2025-07-08**|**Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders**|Shun Wang et.al.|[2507.06427](http://arxiv.org/abs/2507.06427)|null|\n", "2507.06323": "|**2025-07-08**|**Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms**|Tarek Gasmi et.al.|[2507.06323](http://arxiv.org/abs/2507.06323)|null|\n", "2507.06804": "|**2025-07-07**|**Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving**|Zhenwen Liang et.al.|[2507.06804](http://arxiv.org/abs/2507.06804)|null|\n", "2507.07060": "|**2025-07-07**|**DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning**|Shreyas Vinaya Sathyanarayana et.al.|[2507.07060](http://arxiv.org/abs/2507.07060)|null|\n", "2507.07990": "|**2025-07-10**|**Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs**|Jeongseok Hyun et.al.|[2507.07990_(ICC)](http://arxiv.org/abs/2507.07990)|**[link](https://www.jshyun.me/projects/sttm)**|\n", "2507.07400": "|**2025-07-10**|**KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows**|Zaifeng Pan et.al.|[2507.07400](http://arxiv.org/abs/2507.07400)|null|\n", "2507.07120": "|**2025-07-07**|**Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding**|Nidhi Bhatia et.al.|[2507.07120](http://arxiv.org/abs/2507.07120)|null|\n", "2507.07998": "|**2025-07-14**|**PyVision: Agentic Vision with Dynamic Tooling**|Shitian Zhao et.al.|[2507.07998](http://arxiv.org/abs/2507.07998)|null|\n", "2507.07996": "|**2025-07-10**|**Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs**|Ziyue Li et.al.|[2507.07996](http://arxiv.org/abs/2507.07996)|null|\n", "2507.07988": "|**2025-07-10**|**Automating Expert-Level Medical Reasoning Evaluation of Large Language Models**|Shuang Zhou et.al.|[2507.07988](http://arxiv.org/abs/2507.07988)|null|\n", "2507.07957": "|**2025-07-10**|**MIRIX: Multi-Agent Memory System for LLM-Based Agents**|Yu Wang et.al.|[2507.07957](http://arxiv.org/abs/2507.07957)|null|\n", "2507.07870": "|**2025-07-10**|**DocCHA: Towards LLM-Augmented Interactive Online diagnosis System**|Xinyi Liu et.al.|[2507.07870](http://arxiv.org/abs/2507.07870)|null|\n", "2507.07818": "|**2025-07-10**|**MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving**|Lu Xu et.al.|[2507.07818](http://arxiv.org/abs/2507.07818)|null|\n", "2507.07781": "|**2025-07-10**|**SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes**|Jiaxin Huang et.al.|[2507.07781](http://arxiv.org/abs/2507.07781)|null|\n", "2507.07748": "|**2025-07-10**|**When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance**|Peizhang Shao et.al.|[2507.07748](http://arxiv.org/abs/2507.07748)|null|\n", "2507.07723": "|**2025-07-10**|**Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization**|Chengtao Jian et.al.|[2507.07723](http://arxiv.org/abs/2507.07723)|null|\n", "2507.07685": "|**2025-07-10**|**Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought**|Shin'ya Yamaguchi et.al.|[2507.07685](http://arxiv.org/abs/2507.07685)|null|\n", "2507.07644": "|**2025-07-10**|**PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations**|Fedor Rodionov et.al.|[2507.07644](http://arxiv.org/abs/2507.07644)|null|\n", "2507.07544": "|**2025-07-10**|**Position: We Need An Algorithmic Understanding of Generative AI**|Oliver Eberle et.al.|[2507.07544](http://arxiv.org/abs/2507.07544)|null|\n", "2507.07498": "|**2025-07-14**|**Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code**|Keqin Bao et.al.|[2507.07498](http://arxiv.org/abs/2507.07498)|null|\n", "2507.07495": "|**2025-07-10**|**PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving**|Mihir Parmar et.al.|[2507.07495](http://arxiv.org/abs/2507.07495)|null|\n", "2507.07451": "|**2025-07-10**|**RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning**|Hongzhi Zhang et.al.|[2507.07451](http://arxiv.org/abs/2507.07451)|null|\n", "2507.07445": "|**2025-07-11**|**StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley**|Weihao Tan et.al.|[2507.07445](http://arxiv.org/abs/2507.07445)|null|\n", "2507.07441": "|**2025-07-10**|**SAND: Boosting LLM Agents with Self-Taught Action Deliberation**|Yu Xia et.al.|[2507.07441](http://arxiv.org/abs/2507.07441)|null|\n", "2507.07426": "|**2025-07-12**|**DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search**|Zerui Yang et.al.|[2507.07426](http://arxiv.org/abs/2507.07426)|null|\n", "2507.07328": "|**2025-07-09**|**Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery**|Malikussaid et.al.|[2507.07328](http://arxiv.org/abs/2507.07328)|null|\n", "2507.07313": "|**2025-07-09**|**Frontier LLMs Still Struggle with Simple Reasoning Tasks**|Alan Malek et.al.|[2507.07313](http://arxiv.org/abs/2507.07313)|null|\n", "2507.07306": "|**2025-07-09**|**ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning**|Yichen Lu et.al.|[2507.07306](http://arxiv.org/abs/2507.07306)|null|\n", "2507.07129": "|**2025-07-08**|**Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate**|A. Bochkov et.al.|[2507.07129](http://arxiv.org/abs/2507.07129)|null|\n", "2507.08523": "|**2025-07-11**|**InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching**|Yilun Wang et.al.|[2507.08523](http://arxiv.org/abs/2507.08523)|null|\n", "2507.08432": "|**2025-07-11**|**xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models**|Gustavo Correa Publio et.al.|[2507.08432_(VLDB)](http://arxiv.org/abs/2507.08432)|null|\n", "2507.08143": "|**2025-07-10**|**Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores**|Vivek Chari et.al.|[2507.08143](http://arxiv.org/abs/2507.08143)|null|\n", "2507.08045": "|**2025-07-10**|**Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing**|Junyi Wen et.al.|[2507.08045](http://arxiv.org/abs/2507.08045)|null|\n", "2507.08794": "|**2025-07-11**|**One Token to Fool LLM-as-a-Judge**|Yulai Zhao et.al.|[2507.08794](http://arxiv.org/abs/2507.08794)|null|\n", "2507.08679": "|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Rajarshi Roy et.al.|[2507.08679](http://arxiv.org/abs/2507.08679)|null|\n", "2507.08664": "|**2025-07-11**|**Introspection of Thought Helps AI Agents**|Haoran Sun et.al.|[2507.08664](http://arxiv.org/abs/2507.08664)|null|\n", "2507.08649": "|**2025-07-11**|**Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning**|Xingguang Ji et.al.|[2507.08649](http://arxiv.org/abs/2507.08649)|null|\n", "2507.08621": "|**2025-07-11**|**A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1**|Marcin Pietro\u0144 et.al.|[2507.08621](http://arxiv.org/abs/2507.08621)|null|\n", "2507.08619": "|**2025-07-11**|**Agentic Large Language Models for Conceptual Systems Engineering and Design**|Soheyl Massoudi et.al.|[2507.08619](http://arxiv.org/abs/2507.08619)|null|\n", "2507.08616": "|**2025-07-11**|**AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs**|Florian Gr\u00f6tschla et.al.|[2507.08616](http://arxiv.org/abs/2507.08616)|null|\n", "2507.08567": "|**2025-07-11**|**AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling**|Preslav Aleksandrov et.al.|[2507.08567](http://arxiv.org/abs/2507.08567)|null|\n", "2507.08538": "|**2025-07-11**|**The AI Language Proficiency Monitor -- Tracking the Progress of LLMs on Multilingual Benchmarks**|David Pomerenke et.al.|[2507.08538](http://arxiv.org/abs/2507.08538)|null|\n", "2507.08501": "|**2025-07-11**|**From Language to Logic: A Bi-Level Framework for Structured Reasoning**|Keying Yang et.al.|[2507.08501](http://arxiv.org/abs/2507.08501)|null|\n", "2507.08496": "|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Shibo Sun et.al.|[2507.08496](http://arxiv.org/abs/2507.08496)|null|\n", "2507.08468": "|**2025-07-11**|**Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study**|Marina Luketina et.al.|[2507.08468](http://arxiv.org/abs/2507.08468)|null|\n", "2507.08427": "|**2025-07-11**|**ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains**|Zilu Dong et.al.|[2507.08427](http://arxiv.org/abs/2507.08427)|null|\n", "2507.08367": "|**2025-07-11**|**Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment**|Yuki Yoshihara et.al.|[2507.08367](http://arxiv.org/abs/2507.08367)|null|\n", "2507.08339": "|**2025-07-11**|**What Factors Affect LLMs and RLLMs in Financial Question Answering?**|Peng Wang et.al.|[2507.08339](http://arxiv.org/abs/2507.08339)|null|\n", "2507.08270": "|**2025-07-11**|**Agent Safety Alignment via Reinforcement Learning**|Zeyang Sha et.al.|[2507.08270](http://arxiv.org/abs/2507.08270)|null|\n", "2507.08267": "|**2025-07-11**|**A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning**|Hiroshi Yoshihara et.al.|[2507.08267](http://arxiv.org/abs/2507.08267)|null|\n", "2507.08235": "|**2025-07-11**|**InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems**|Pinaki Prasad Guha Neogi et.al.|[2507.08235](http://arxiv.org/abs/2507.08235)|null|\n", "2507.08224": "|**2025-07-11**|**Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning**|Chan Young Park et.al.|[2507.08224](http://arxiv.org/abs/2507.08224)|null|\n", "2507.08218": "|**2025-07-16**|**Simple Mechanistic Explanations for Out-Of-Context Reasoning**|Atticus Wang et.al.|[2507.08218](http://arxiv.org/abs/2507.08218)|null|\n", "2507.08208": "|**2025-07-10**|**Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions**|Quanyan Zhu et.al.|[2507.08208](http://arxiv.org/abs/2507.08208)|null|\n", "2507.08182": "|**2025-07-10**|**CTRLS: Chain-of-Thought Reasoning via Latent State-Transition**|Junda Wu et.al.|[2507.08182](http://arxiv.org/abs/2507.08182)|null|\n", "2507.08046": "|**2025-07-10**|**TableReasoner: Advancing Table Reasoning Framework with Large Language Models**|Sishi Xiong et.al.|[2507.08046](http://arxiv.org/abs/2507.08046)|null|\n", "2507.08037": "|**2025-07-09**|**CRISP: Complex Reasoning with Interpretable Step-based Plans**|Matan Vetzler et.al.|[2507.08037](http://arxiv.org/abs/2507.08037)|null|\n", "2507.08034": "|**2025-07-09**|**Integrating External Tools with Large Language Models to Improve Accuracy**|Nripesh Niketan et.al.|[2507.08034](http://arxiv.org/abs/2507.08034)|null|\n", "2507.08027": "|**2025-07-08**|**\"Amazing, They All Lean Left\" -- Analyzing the Political Temperaments of Current LLMs**|W. Russell Neuman et.al.|[2507.08027](http://arxiv.org/abs/2507.08027)|null|\n", "2507.10069": "|**2025-07-14**|**ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism**|Zedong Liu et.al.|[2507.10069](http://arxiv.org/abs/2507.10069)|null|\n", "2507.09025": "|**2025-07-20**|**Lizard: An Efficient Linearization Framework for Large Language Models**|Chien Van Nguyen et.al.|[2507.09025](http://arxiv.org/abs/2507.09025)|null|\n", "2507.10540": "|**2025-07-14**|**Fusing LLM Capabilities with Routing Data**|Tao Feng et.al.|[2507.10540](http://arxiv.org/abs/2507.10540)|null|\n", "2507.10535": "|**2025-07-14**|**CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks**|Hongchao Jiang et.al.|[2507.10535](http://arxiv.org/abs/2507.10535)|null|\n", "2507.10532": "|**2025-07-14**|**Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination**|Mingqi Wu et.al.|[2507.10532](http://arxiv.org/abs/2507.10532)|null|\n", "2507.10522": "|**2025-07-14**|**DeepResearch$^{\\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology**|Jennifer D'Souza et.al.|[2507.10522](http://arxiv.org/abs/2507.10522)|null|\n", "2507.10445": "|**2025-07-14**|**Referential ambiguity and clarification requests: comparing human and LLM behaviour**|Chris Madge et.al.|[2507.10445](http://arxiv.org/abs/2507.10445)|null|\n", "2507.10284": "|**2025-07-14**|**Prompt Informed Reinforcement Learning for Visual Coverage Path Planning**|Venkat Margapuri et.al.|[2507.10284](http://arxiv.org/abs/2507.10284)|null|\n", "2507.10281": "|**2025-07-14**|**Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence**|Jiaming Tian et.al.|[2507.10281](http://arxiv.org/abs/2507.10281)|null|\n", "2507.10182": "|**2025-07-14**|**Breaking the Myth: Can Small Models Infer Postconditions Too?**|Gehao Zhang et.al.|[2507.10182](http://arxiv.org/abs/2507.10182)|null|\n", "2507.10098": "|**2025-07-14**|**Fusing Large Language Models with Temporal Transformers for Time Series Forecasting**|Chen Su et.al.|[2507.10098](http://arxiv.org/abs/2507.10098)|null|\n", "2507.10087": "|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Muhammad Tayyab Khan et.al.|[2507.10087](http://arxiv.org/abs/2507.10087)|null|\n", "2507.10062": "|**2025-07-14**|**LLMShot: Reducing snapshot testing maintenance via LLMs**|Erg\u00fcn Batuhan Kaynak et.al.|[2507.10062](http://arxiv.org/abs/2507.10062)|null|\n", "2507.10039": "|**2025-07-14**|**Towards Applying Large Language Models to Complement Single-Cell Foundation Models**|Steven Palayew et.al.|[2507.10039](http://arxiv.org/abs/2507.10039)|null|\n", "2507.10007": "|**2025-07-14**|**Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning**|Zijun Chen et.al.|[2507.10007](http://arxiv.org/abs/2507.10007)|null|\n", "2507.09955": "|**2025-07-14**|**DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models**|Luolin Xiong et.al.|[2507.09955](http://arxiv.org/abs/2507.09955)|null|\n", "2507.09931": "|**2025-07-14**|**Mechanistic Interpretability of LoRA-Adapted Language Models for Nuclear Reactor Safety Applications**|Yoon Pyo Lee et.al.|[2507.09931](http://arxiv.org/abs/2507.09931)|null|\n", "2507.09884": "|**2025-07-15**|**VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains**|Xuzhao Li et.al.|[2507.09884](http://arxiv.org/abs/2507.09884)|null|\n", "2507.09876": "|**2025-07-14**|**ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models**|Yongheng Zhang et.al.|[2507.09876](http://arxiv.org/abs/2507.09876)|null|\n", "2507.09850": "|**2025-07-16**|**The Challenge of Teaching Reasoning to LLMs Without RL or Distillation**|Wei Du et.al.|[2507.09850](http://arxiv.org/abs/2507.09850)|null|\n", "2507.09790": "|**2025-07-13**|**Prompting for Performance: Exploring LLMs for Configuring Software**|Helge Spieker et.al.|[2507.09790](http://arxiv.org/abs/2507.09790)|null|\n", "2507.09751": "|**2025-07-13**|**Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations**|Bradley P. Allen et.al.|[2507.09751](http://arxiv.org/abs/2507.09751)|null|\n", "2507.09709": "|**2025-07-13**|**Large Language Models Encode Semantics in Low-Dimensional Linear Subspaces**|Baturay Saglam et.al.|[2507.09709](http://arxiv.org/abs/2507.09709)|null|\n", "2507.09676": "|**2025-07-13**|**Can AI Rely on the Systematicity of Truth? The Challenge of Modelling Normative Domains**|Matthieu Queloz et.al.|[2507.09676](http://arxiv.org/abs/2507.09676)|null|\n", "2507.09638": "|**2025-07-13**|**Can Group Relative Policy Optimization Improve Thai Legal Reasoning and Question Answering?**|Pawitsapak Akarajaradwong et.al.|[2507.09638](http://arxiv.org/abs/2507.09638)|null|\n", "2507.09580": "|**2025-07-13**|**AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models**|Yu Wang et.al.|[2507.09580](http://arxiv.org/abs/2507.09580)|null|\n", "2507.09535": "|**2025-07-13**|**Reframing SAR Target Recognition as Visual Reasoning: A Chain-of-Thought Dataset with Multimodal LLMs**|Chaoran Li et.al.|[2507.09535](http://arxiv.org/abs/2507.09535)|null|\n", "2507.09477": "|**2025-07-16**|**Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs**|Yangning Li et.al.|[2507.09477](http://arxiv.org/abs/2507.09477)|null|\n", "2507.09407": "|**2025-07-12**|**LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing**|Quanyan Zhu et.al.|[2507.09407](http://arxiv.org/abs/2507.09407)|null|\n", "2507.09255": "|**2025-07-12**|**StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets**|Charidimos Papadakis et.al.|[2507.09255](http://arxiv.org/abs/2507.09255)|null|\n", "2507.09195": "|**2025-07-12**|**Towards Spatial Audio Understanding via Question Answering**|Parthasaarathy Sudarsanam et.al.|[2507.09195](http://arxiv.org/abs/2507.09195)|null|\n", "2507.09185": "|**2025-07-12**|**Detecting and Pruning Prominent but Detrimental Neurons in Large Language Models**|Ameen Ali et.al.|[2507.09185](http://arxiv.org/abs/2507.09185)|null|\n", "2507.09155": "|**2025-07-12**|**OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering**|Ali Vosoughi et.al.|[2507.09155](http://arxiv.org/abs/2507.09155)|null|\n", "2507.09116": "|**2025-07-15**|**Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition**|Bingshen Mu et.al.|[2507.09116](http://arxiv.org/abs/2507.09116)|null|\n", "2507.09104": "|**2025-07-12**|**CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards**|Taolin Zhang et.al.|[2507.09104](http://arxiv.org/abs/2507.09104)|null|\n", "2507.09083": "|**2025-07-12**|**Learning from Synthetic Labs: Language Models as Auction Participants**|Anand Shah et.al.|[2507.09083](http://arxiv.org/abs/2507.09083)|null|\n", "2507.09075": "|**2025-07-11**|**OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique**|Wasi Uddin Ahmad et.al.|[2507.09075](http://arxiv.org/abs/2507.09075)|null|\n", "2507.09068": "|**2025-07-11**|**Infinite Video Understanding**|Dell Zhang et.al.|[2507.09068](http://arxiv.org/abs/2507.09068)|null|\n", "2507.09037": "|**2025-07-11**|**ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making**|Bharadwaj Ravichandran et.al.|[2507.09037](http://arxiv.org/abs/2507.09037)|null|\n", "2507.08960": "|**2025-07-11**|**How to Train a Leader: Hierarchical Reasoning in Multi-Agent LLMs**|Andrew Estornell et.al.|[2507.08960](http://arxiv.org/abs/2507.08960)|null|\n", "2507.08958": "|**2025-07-15**|**Bridging Literature and the Universe Via A Multi-Agent Large Language Model System**|Xiaowen Zhang et.al.|[2507.08958](http://arxiv.org/abs/2507.08958)|null|\n", "2507.08945": "|**2025-07-11**|**GraphRunner: A Multi-Stage Framework for Efficient and Accurate Graph-Based Retrieval**|Savini Kashmira et.al.|[2507.08945](http://arxiv.org/abs/2507.08945)|null|\n", "2507.08944": "|**2025-07-11**|**Optimizing Sequential Multi-Step Tasks with Parallel LLM Agents**|Enhao Zhang et.al.|[2507.08944](http://arxiv.org/abs/2507.08944)|null|\n", "2507.10435": "|**2025-07-11**|**From Sequence to Structure: Uncovering Substructure Reasoning in Transformers**|Xinnan Dai et.al.|[2507.10435](http://arxiv.org/abs/2507.10435)|null|\n", "2507.08862": "|**2025-07-09**|**RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation**|Tianzhe Zhao et.al.|[2507.08862](http://arxiv.org/abs/2507.08862)|null|\n", "2507.11507": "|**2025-07-15**|**MIRAGE: KV Cache Optimization through Parameter Remapping for Multi-tenant LLM Serving**|Ruihao Li et.al.|[2507.11507](http://arxiv.org/abs/2507.11507)|null|\n", "2507.11273": "|**2025-07-15**|**KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding**|Luohe Shi et.al.|[2507.11273_(ACL)](http://arxiv.org/abs/2507.11273)|null|\n", "2507.11538": "|**2025-07-15**|**How Many Instructions Can LLMs Follow at Once?**|Daniel Jaroslawicz et.al.|[2507.11538](http://arxiv.org/abs/2507.11538)|null|\n", "2507.11527": "|**2025-07-15**|**DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering**|Yinsheng Li et.al.|[2507.11527](http://arxiv.org/abs/2507.11527)|null|\n", "2507.11467": "|**2025-07-15**|**Modeling Code: Is Text All You Need?**|Daniel Nichols et.al.|[2507.11467](http://arxiv.org/abs/2507.11467)|null|\n", "2507.11457": "|**2025-07-15**|**LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer**|Yaoxian Dong et.al.|[2507.11457](http://arxiv.org/abs/2507.11457)|null|\n", "2507.11423": "|**2025-07-16**|**Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?**|Yanjian Zhang et.al.|[2507.11423](http://arxiv.org/abs/2507.11423)|null|\n", "2507.11408": "|**2025-07-15**|**KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?**|Soumadeep Saha et.al.|[2507.11408](http://arxiv.org/abs/2507.11408)|null|\n", "2507.11405": "|**2025-07-15**|**DCR: Quantifying Data Contamination in LLMs Evaluation**|Cheng Xu et.al.|[2507.11405](http://arxiv.org/abs/2507.11405)|null|\n", "2507.11371": "|**2025-07-15**|**Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs**|Gabriel Bo et.al.|[2507.11371](http://arxiv.org/abs/2507.11371)|null|\n", "2507.11344": "|**2025-07-15**|**Guiding LLM Decision-Making with Fairness Reward Models**|Zara Hall et.al.|[2507.11344](http://arxiv.org/abs/2507.11344)|null|\n", "2507.11310": "|**2025-07-15**|**LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification**|Fengxiao Tang et.al.|[2507.11310](http://arxiv.org/abs/2507.11310)|null|\n", "2507.11277": "|**2025-07-15**|**Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems**|Dany Moshkovich et.al.|[2507.11277](http://arxiv.org/abs/2507.11277)|null|\n", "2507.11275": "|**2025-07-15**|**FMC: Formalization of Natural Language Mathematical Competition Problems**|Jiaxuan Xie et.al.|[2507.11275](http://arxiv.org/abs/2507.11275)|null|\n", "2507.11222": "|**2025-07-15**|**An Agentic Flow for Finite State Machine Extraction using Prompt Chaining**|Fares Wael et.al.|[2507.11222](http://arxiv.org/abs/2507.11222)|null|\n", "2507.11052": "|**2025-07-15**|**LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP**|Haowei Yang et.al.|[2507.11052](http://arxiv.org/abs/2507.11052)|null|\n", "2507.10972": "|**2025-07-15**|**Teach Me Sign: Stepwise Prompting LLM for Sign Language Production**|Zhaoyi An et.al.|[2507.10972](http://arxiv.org/abs/2507.10972)|null|\n", "2507.10957": "|**2025-07-15**|**Modeling Understanding of Story-Based Analogies Using Large Language Models**|Kalit Inani et.al.|[2507.10957](http://arxiv.org/abs/2507.10957)|null|\n", "2507.10933": "|**2025-07-15**|**Artificial Finance: How AI Thinks About Money**|Orhan Erdem et.al.|[2507.10933](http://arxiv.org/abs/2507.10933)|null|\n", "2507.10917": "|**2025-07-17**|**LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation**|Ziyan Wang et.al.|[2507.10917](http://arxiv.org/abs/2507.10917)|null|\n", "2507.10906": "|**2025-07-15**|**Evaluating Generated Commit Messages with Large Language Models**|Qunhong Zeng et.al.|[2507.10906](http://arxiv.org/abs/2507.10906)|null|\n", "2507.10778": "|**2025-07-14**|**Warehouse Spatial Question Answering with LLM Agent**|Hsiang-Wei Huang et.al.|[2507.10778](http://arxiv.org/abs/2507.10778)|null|\n", "2507.11500": "|**2025-07-14**|**ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning**|Zhengyue Zhao et.al.|[2507.11500](http://arxiv.org/abs/2507.11500)|null|\n", "2507.10630": "|**2025-07-14**|**Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs**|Ye Yang et.al.|[2507.10630](http://arxiv.org/abs/2507.10630)|null|\n", "2507.10628": "|**2025-07-16**|**GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning**|Ziru Liu et.al.|[2507.10628](http://arxiv.org/abs/2507.10628)|null|\n", "2507.10624": "|**2025-07-14**|**Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning**|Zheng Zhang et.al.|[2507.10624](http://arxiv.org/abs/2507.10624)|null|\n", "2507.10621": "|**2025-07-14**|**Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats**|Quanyan Zhu et.al.|[2507.10621](http://arxiv.org/abs/2507.10621)|null|\n", "2507.10616": "|**2025-07-13**|**Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them**|Neel Rajani et.al.|[2507.10616](http://arxiv.org/abs/2507.10616)|null|\n", "2507.10599": "|**2025-07-12**|**Emergence of Hierarchical Emotion Organization in Large Language Models**|Bo Zhao et.al.|[2507.10599](http://arxiv.org/abs/2507.10599)|null|\n", "2507.10596": "|**2025-07-12**|**PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification**|Yogachandran Rahulamathavan et.al.|[2507.10596](http://arxiv.org/abs/2507.10596)|null|\n", "2507.10580": "|**2025-07-11**|**An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation**|Vimaleswar A et.al.|[2507.10580](http://arxiv.org/abs/2507.10580)|null|\n", "2507.10576": "|**2025-07-11**|**Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?**|Bhakti Khera et.al.|[2507.10576](http://arxiv.org/abs/2507.10576)|null|\n", "2507.11953": "|**2025-07-16**|**IAM: Efficient Inference through Attention Mapping between Different-scale LLMs**|Yi Zhao et.al.|[2507.11953_(ACL)](http://arxiv.org/abs/2507.11953)|null|\n", "2507.12391": "|**2025-07-16**|**Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning**|Jacinto Colan et.al.|[2507.12391](http://arxiv.org/abs/2507.12391)|null|\n", "2507.12372": "|**2025-07-16**|**Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics**|Meysam Alizadeh et.al.|[2507.12372](http://arxiv.org/abs/2507.12372)|null|\n", "2507.12314": "|**2025-07-16**|**Thought Purity: Defense Paradigm For Chain-of-Thought Attack**|Zihao Xue et.al.|[2507.12314](http://arxiv.org/abs/2507.12314)|null|\n", "2507.12284": "|**2025-07-17**|**MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks**|Artem Chervyakov et.al.|[2507.12284](http://arxiv.org/abs/2507.12284)|null|\n", "2507.12215": "|**2025-07-16**|**Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning**|Yuhao Chen et.al.|[2507.12215](http://arxiv.org/abs/2507.12215)|null|\n", "2507.12079": "|**2025-07-16**|**Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning**|Tosin Adewumi et.al.|[2507.12079](http://arxiv.org/abs/2507.12079)|null|\n", "2507.12059": "|**2025-07-16**|**Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited**|Anthony G Cohn et.al.|[2507.12059](http://arxiv.org/abs/2507.12059)|null|\n", "2507.11988": "|**2025-07-17**|**Aime: Towards Fully-Autonomous Multi-Agent Framework**|Yexuan Shi et.al.|[2507.11988](http://arxiv.org/abs/2507.11988)|null|\n", "2507.11968": "|**2025-07-16**|**Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation**|Sahid Hossain Mustakim et.al.|[2507.11968](http://arxiv.org/abs/2507.11968)|null|\n", "2507.11959": "|**2025-07-16**|**PoTPTQ: A Two-step Power-of-Two Post-training for LLMs**|Xinyu Wang et.al.|[2507.11959](http://arxiv.org/abs/2507.11959)|null|\n", "2507.11954": "|**2025-07-16**|**The benefits of query-based KGQA systems for complex and temporal questions in LLM era**|Artem Alekseev et.al.|[2507.11954](http://arxiv.org/abs/2507.11954)|null|\n", "2507.11932": "|**2025-07-16**|**Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs**|Mohammad Shahab Sepehri et.al.|[2507.11932](http://arxiv.org/abs/2507.11932)|null|\n", "2507.11633": "|**2025-07-15**|**General Modular Harness for LLM Agents in Multi-Turn Gaming Environments**|Yuxuan Zhang et.al.|[2507.11633](http://arxiv.org/abs/2507.11633)|null|\n", "2507.13353": "|**2025-07-17**|**VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding**|Shihao Wang et.al.|[2507.13353](http://arxiv.org/abs/2507.13353)|null|\n", "2507.13348": "|**2025-07-17**|**VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning**|Senqiao Yang et.al.|[2507.13348](http://arxiv.org/abs/2507.13348)|**[link](https://github.com/dvlab-research/VisionThink)**|\n", "2507.13335": "|**2025-07-17**|**Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes**|Tyler Loakman et.al.|[2507.13335](http://arxiv.org/abs/2507.13335)|null|\n", "2507.13334": "|**2025-07-21**|**A Survey of Context Engineering for Large Language Models**|Lingrui Mei et.al.|[2507.13334](http://arxiv.org/abs/2507.13334)|null|\n", "2507.13332": "|**2025-07-17**|**The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner**|Zhouqi Hua et.al.|[2507.13332](http://arxiv.org/abs/2507.13332)|null|\n", "2507.13266": "|**2025-07-17**|**QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation**|Jiazheng Li et.al.|[2507.13266](http://arxiv.org/abs/2507.13266)|null|\n", "2507.13238": "|**2025-07-23**|**Multilingual LLMs Are Not Multilingual Thinkers: Evidence from Hindi Analogy Evaluation**|Ashray Gupta et.al.|[2507.13238](http://arxiv.org/abs/2507.13238)|null|\n", "2507.13158": "|**2025-07-17**|**Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities**|Hao Sun et.al.|[2507.13158](http://arxiv.org/abs/2507.13158)|null|\n", "2507.13152": "|**2025-07-25**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al.|[2507.13152](http://arxiv.org/abs/2507.13152)|null|\n", "2507.13038": "|**2025-07-17**|**MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems**|Yu Cui et.al.|[2507.13038](http://arxiv.org/abs/2507.13038)|null|\n", "2507.12948": "|**2025-07-17**|**Probabilistic Soundness Guarantees in LLM Reasoning Chains**|Weiqiu You et.al.|[2507.12948](http://arxiv.org/abs/2507.12948)|null|\n", "2507.12901": "|**2025-07-24**|**Agentar-DeepFinance-100K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization**|Xiaoke Zhao et.al.|[2507.12901](http://arxiv.org/abs/2507.12901)|null|\n", "2507.12885": "|**2025-07-17**|**VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks**|Jian Yao et.al.|[2507.12885](http://arxiv.org/abs/2507.12885)|null|\n", "2507.12855": "|**2025-07-17**|**DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning**|Rahel Rickenbach et.al.|[2507.12855](http://arxiv.org/abs/2507.12855)|null|\n", "2507.12774": "|**2025-07-17**|**A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models**|Weijieying Ren et.al.|[2507.12774](http://arxiv.org/abs/2507.12774)|null|\n", "2507.12753": "|**2025-07-17**|**osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning**|Fujing Xie et.al.|[2507.12753](http://arxiv.org/abs/2507.12753)|null|\n", "2507.12724": "|**2025-07-17**|**TransEvalnia: Reasoning-based Evaluation and Ranking of Translations**|Richard Sproat et.al.|[2507.12724](http://arxiv.org/abs/2507.12724)|null|\n", "2507.12507": "|**2025-07-16**|**Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training**|Mingjie Liu et.al.|[2507.12507](http://arxiv.org/abs/2507.12507)|null|\n", "2507.12482": "|**2025-07-14**|**Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding**|Ishraq Khan et.al.|[2507.12482](http://arxiv.org/abs/2507.12482)|null|\n", "2507.12480": "|**2025-07-12**|**LLM-Powered Quantum Code Transpilation**|Nazanin Siavash et.al.|[2507.12480](http://arxiv.org/abs/2507.12480)|null|\n", "2507.13681": "|**2025-07-18**|**LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues**|Haoyang Li et.al.|[2507.13681](http://arxiv.org/abs/2507.13681)|null|\n", "2507.14111": "|**2025-07-22**|**CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning**|Xiaoya Li et.al.|[2507.14111](http://arxiv.org/abs/2507.14111)|null|\n", "2507.14088": "|**2025-07-18**|**DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration**|Xiyun Li et.al.|[2507.14088](http://arxiv.org/abs/2507.14088)|null|\n", "2507.14017": "|**2025-07-18**|**Efficient Temporal Tokenization for Mobility Prediction with Large Language Models**|Haoyu He et.al.|[2507.14017](http://arxiv.org/abs/2507.14017)|null|\n", "2507.13957": "|**2025-07-18**|**DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation**|Yitong Li et.al.|[2507.13957](http://arxiv.org/abs/2507.13957)|null|\n", "2507.13956": "|**2025-07-18**|**Cross-modal Causal Intervention for Alzheimer's Disease Prediction**|Yutao Jin et.al.|[2507.13956](http://arxiv.org/abs/2507.13956)|null|\n", "2507.13858": "|**2025-07-18**|**InTraVisTo: Inside Transformer Visualisation Tool**|Nicol\u00f2 Brunello et.al.|[2507.13858](http://arxiv.org/abs/2507.13858)|null|\n", "2507.13833": "|**2025-07-23**|**DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training**|Zhixin Wang et.al.|[2507.13833](http://arxiv.org/abs/2507.13833)|null|\n", "2507.13820": "|**2025-07-18**|**Team of One: Cracking Complex Video QA with Model Synergy**|Jun Xie et.al.|[2507.13820](http://arxiv.org/abs/2507.13820)|null|\n", "2507.13758": "|**2025-07-22**|**Reasoning Models Can be Easily Hacked by Fake Reasoning Bias**|Qian Wang et.al.|[2507.13758](http://arxiv.org/abs/2507.13758)|null|\n", "2507.13629": "|**2025-07-18**|**Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques**|Niveen O. Jaffal et.al.|[2507.13629](http://arxiv.org/abs/2507.13629)|null|\n", "2507.13625": "|**2025-07-18**|**BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety**|Yuxin Zhang et.al.|[2507.13625](http://arxiv.org/abs/2507.13625)|null|\n", "2507.13618": "|**2025-07-25**|**Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters**|Shanbo Cheng et.al.|[2507.13618](http://arxiv.org/abs/2507.13618)|null|\n", "2507.13525": "|**2025-07-17**|**Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation**|Genki Kusano et.al.|[2507.13525_(RecSys)](http://arxiv.org/abs/2507.13525)|null|\n", "2507.13474": "|**2025-07-17**|**Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers**|Liang Lin et.al.|[2507.13474](http://arxiv.org/abs/2507.13474)|null|\n", "2507.13390": "|**2025-07-16**|**PARAM-1 BharatGen 2.9B Model**|Kundeshwar Pundalik et.al.|[2507.13390](http://arxiv.org/abs/2507.13390)|null|\n", "2507.14204": "|**2025-07-14**|**LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models**|Dachuan Shi et.al.|[2507.14204_(ICML)](http://arxiv.org/abs/2507.14204)|**[link](https://github.com/GATECH-EIC/LaCache)**|\n", "2507.15855": "|**2025-07-25**|**Gemini 2.5 Pro Capable of Winning Gold at IMO 2025**|Yichen Huang et.al.|[2507.15855](http://arxiv.org/abs/2507.15855)|null|\n", "2507.15849": "|**2025-07-21**|**The Impact of Language Mixing on Bilingual LLM Reasoning**|Yihao Li et.al.|[2507.15849](http://arxiv.org/abs/2507.15849)|null|\n", "2507.15788": "|**2025-07-21**|**Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning**|Sneheel Sarangi et.al.|[2507.15788](http://arxiv.org/abs/2507.15788)|null|\n", "2507.15778": "|**2025-07-21**|**Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR**|Jiakang Wang et.al.|[2507.15778](http://arxiv.org/abs/2507.15778)|null|\n", "2507.15770": "|**2025-07-21**|**A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining**|Yifan Shen et.al.|[2507.15770](http://arxiv.org/abs/2507.15770)|null|\n", "2507.15736": "|**2025-07-21**|**Understanding Large Language Models' Ability on Interdisciplinary Research**|Yuanhao Shen et.al.|[2507.15736](http://arxiv.org/abs/2507.15736)|null|\n", "2507.15717": "|**2025-07-21**|**BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning**|Sahana Srinivasan et.al.|[2507.15717](http://arxiv.org/abs/2507.15717)|null|\n", "2507.15707": "|**2025-07-21**|**Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?**|Seok Hwan Song et.al.|[2507.15707](http://arxiv.org/abs/2507.15707)|null|\n", "2507.15698": "|**2025-07-21**|**CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models**|Congmin Zheng et.al.|[2507.15698](http://arxiv.org/abs/2507.15698)|null|\n", "2507.15675": "|**2025-07-21**|**P3: Prompts Promote Prompting**|Xinyu Zhang et.al.|[2507.15675_(ACL)](http://arxiv.org/abs/2507.15675)|null|\n", "2507.15671": "|**2025-07-21**|**BugScope: Learn to Find Bugs Like Human**|Jinyao Guo et.al.|[2507.15671](http://arxiv.org/abs/2507.15671)|null|\n", "2507.15586": "|**2025-07-30**|**Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation**|Xinping Zhao et.al.|[2507.15586](http://arxiv.org/abs/2507.15586)|null|\n", "2507.15550": "|**2025-07-21**|**PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors**|Yimeng Chen et.al.|[2507.15550](http://arxiv.org/abs/2507.15550)|null|\n", "2507.15521": "|**2025-07-21**|**LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning**|Cole Robertson et.al.|[2507.15521_(NeurIPS)](http://arxiv.org/abs/2507.15521)|null|\n", "2507.15512": "|**2025-07-21**|**Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models**|Kaiyan Chang et.al.|[2507.15512](http://arxiv.org/abs/2507.15512)|null|\n", "2507.15378": "|**2025-07-21**|**AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming**|Jierui Li et.al.|[2507.15378](http://arxiv.org/abs/2507.15378)|null|\n", "2507.15343": "|**2025-08-04**|**StackTrans: From Large Language Model to Large Pushdown Automata Model**|Kechi Zhang et.al.|[2507.15343](http://arxiv.org/abs/2507.15343)|null|\n", "2507.15337": "|**2025-07-21**|**Reasoning Models are Test Exploiters: Rethinking Multiple-Choice**|Narun Raman et.al.|[2507.15337](http://arxiv.org/abs/2507.15337)|null|\n", "2507.15251": "|**2025-07-21**|**Input Reduction Enhanced LLM-based Program Repair**|Boyang Yang et.al.|[2507.15251](http://arxiv.org/abs/2507.15251)|null|\n", "2507.15245": "|**2025-07-21**|**SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search**|Xiaofeng Shi et.al.|[2507.15245](http://arxiv.org/abs/2507.15245)|null|\n", "2507.15241": "|**2025-07-21**|**FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents**|Vikram Nitin et.al.|[2507.15241](http://arxiv.org/abs/2507.15241)|null|\n", "2507.15225": "|**2025-07-21**|**Solving Formal Math Problems by Decomposition and Iterative Reflection**|Yichi Zhou et.al.|[2507.15225](http://arxiv.org/abs/2507.15225)|null|\n", "2507.15066": "|**2025-08-01**|**Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback**|Yiyuan Yang et.al.|[2507.15066](http://arxiv.org/abs/2507.15066)|null|\n", "2507.15061": "|**2025-07-20**|**WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization**|Zhengwei Tao et.al.|[2507.15061](http://arxiv.org/abs/2507.15061)|null|\n", "2507.15028": "|**2025-07-20**|**Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding**|Yuanhan Zhang et.al.|[2507.15028_(ICC)](http://arxiv.org/abs/2507.15028)|**[link](https://zhangyuanhan-ai.github.io/video-tt/)**|\n", "2507.15024": "|**2025-07-20**|**RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback**|Qiaoyu Tang et.al.|[2507.15024](http://arxiv.org/abs/2507.15024)|null|\n", "2507.15015": "|**2025-07-20**|**EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems**|Xinmeng Hou et.al.|[2507.15015](http://arxiv.org/abs/2507.15015)|null|\n", "2507.14987": "|**2025-07-20**|**AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning**|Yi Zhang et.al.|[2507.14987](http://arxiv.org/abs/2507.14987)|null|\n", "2507.14958": "|**2025-07-20**|**MUR: Momentum Uncertainty guided Reasoning for Large Language Models**|Hang Yan et.al.|[2507.14958](http://arxiv.org/abs/2507.14958)|null|\n", "2507.14944": "|**2025-07-20**|**LEKIA: A Framework for Architectural Alignment via Expert Knowledge Injection**|Boning Zhao et.al.|[2507.14944](http://arxiv.org/abs/2507.14944)|null|\n", "2507.14906": "|**2025-07-20**|**Feedback-Induced Performance Decline in LLM-Based Decision-Making**|Xiao Yang et.al.|[2507.14906](http://arxiv.org/abs/2507.14906)|null|\n", "2507.14899": "|**2025-07-20**|**InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis**|Jiale Liu et.al.|[2507.14899](http://arxiv.org/abs/2507.14899)|null|\n", "2507.14887": "|**2025-07-20**|**MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction**|Shiyi Mu et.al.|[2507.14887_(CogSci)](http://arxiv.org/abs/2507.14887)|null|\n", "2507.14800": "|**2025-07-20**|**Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control**|Xu Yang et.al.|[2507.14800](http://arxiv.org/abs/2507.14800)|null|\n", "2507.14785": "|**2025-07-20**|**Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs**|Erfan Pirmorad et.al.|[2507.14785](http://arxiv.org/abs/2507.14785)|null|\n", "2507.14784": "|**2025-07-20**|**LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering**|Xinxin Dong et.al.|[2507.14784](http://arxiv.org/abs/2507.14784)|null|\n", "2507.14783": "|**2025-07-24**|**Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al.|[2507.14783](http://arxiv.org/abs/2507.14783)|null|\n", "2507.14688": "|**2025-07-19**|**Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations**|Mohammed Alkhowaiter et.al.|[2507.14688](http://arxiv.org/abs/2507.14688)|null|\n", "2507.14633": "|**2025-07-19**|**Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches**|Xiaozheng Gao et.al.|[2507.14633](http://arxiv.org/abs/2507.14633)|null|\n", "2507.14615": "|**2025-07-19**|**Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper**|Fred Mutisya et.al.|[2507.14615](http://arxiv.org/abs/2507.14615)|null|\n", "2507.14586": "|**2025-07-19**|**What do Large Language Models know about materials?**|Adrian Ehrenhofer et.al.|[2507.14586](http://arxiv.org/abs/2507.14586)|null|\n", "2507.14584": "|**2025-07-19**|**Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption**|Kester Wong et.al.|[2507.14584](http://arxiv.org/abs/2507.14584)|null|\n", "2507.14513": "|**2025-07-19**|**Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy**|Hongyi Yang et.al.|[2507.14513](http://arxiv.org/abs/2507.14513)|null|\n", "2507.14430": "|**2025-07-22**|**X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display**|Xiaolin Yan et.al.|[2507.14430](http://arxiv.org/abs/2507.14430)|null|\n", "2507.14406": "|**2025-07-18**|**Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering**|Michael J. Zellinger et.al.|[2507.14406](http://arxiv.org/abs/2507.14406)|null|\n", "2507.14403": "|**2025-07-18**|**NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers**|Sarunas Kalade et.al.|[2507.14403](http://arxiv.org/abs/2507.14403)|null|\n", "2507.14398": "|**2025-07-18**|**NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation**|Md. Kamrul Hossain et.al.|[2507.14398](http://arxiv.org/abs/2507.14398)|null|\n", "2507.14335": "|**2025-07-18**|**ProofCompass: Enhancing Specialized Provers with LLM Guidance**|Nicolas Wischermann et.al.|[2507.14335_(CHI)](http://arxiv.org/abs/2507.14335)|null|\n", "2507.14307": "|**2025-07-18**|**How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs**|Karin de Langis et.al.|[2507.14307](http://arxiv.org/abs/2507.14307)|null|\n", "2507.14295": "|**2025-07-18**|**A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning**|Licheng Liu et.al.|[2507.14295](http://arxiv.org/abs/2507.14295)|null|\n", "2507.14256": "|**2025-07-18**|**Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models**|Jakub Walczak et.al.|[2507.14256](http://arxiv.org/abs/2507.14256)|null|\n", "2507.14230": "|**2025-07-17**|**Intent-Based Network for RAN Management with Large Language Models**|Fransiscus Asisi Bimo et.al.|[2507.14230](http://arxiv.org/abs/2507.14230)|null|\n", "2507.16784": "|**2025-07-22**|**Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning**|Hongyin Luo et.al.|[2507.16784](http://arxiv.org/abs/2507.16784)|null|\n", "2507.16768": "|**2025-07-22**|**WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding**|Ran Wang et.al.|[2507.16768](http://arxiv.org/abs/2507.16768)|null|\n", "2507.16217": "|**2025-07-22**|**Towards Compute-Optimal Many-Shot In-Context Learning**|Shahriar Golchin et.al.|[2507.16217](http://arxiv.org/abs/2507.16217)|null|\n", "2507.16815": "|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Chi-Pin Huang et.al.|[2507.16815](http://arxiv.org/abs/2507.16815)|**[link](https://jasper0314-huang.github.io/thinkact-vla/)**|\n", "2507.16809": "|**2025-07-24**|**LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs**|Da-Chen Lian et.al.|[2507.16809](http://arxiv.org/abs/2507.16809)|null|\n", "2507.16802": "|**2025-07-27**|**Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning**|Yanjun Zheng et.al.|[2507.16802](http://arxiv.org/abs/2507.16802)|null|\n", "2507.16773": "|**2025-07-22**|**When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs**|Yue Li et.al.|[2507.16773](http://arxiv.org/abs/2507.16773)|null|\n", "2507.16656": "|**2025-07-22**|**P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs**|Dongjun Jang et.al.|[2507.16656](http://arxiv.org/abs/2507.16656)|null|\n", "2507.16507": "|**2025-07-22**|**Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications**|Jean Lelong et.al.|[2507.16507](http://arxiv.org/abs/2507.16507)|null|\n", "2507.16473": "|**2025-07-24**|**Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs**|Chang Li et.al.|[2507.16473](http://arxiv.org/abs/2507.16473)|null|\n", "2507.16395": "|**2025-07-22**|**LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning**|Bo Hou et.al.|[2507.16395](http://arxiv.org/abs/2507.16395)|null|\n", "2507.16331": "|**2025-07-25**|**Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny**|Chuanhao Yan et.al.|[2507.16331](http://arxiv.org/abs/2507.16331)|null|\n", "2507.16322": "|**2025-07-22**|**Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens**|Fred Mutisya et.al.|[2507.16322](http://arxiv.org/abs/2507.16322)|null|\n", "2507.16307": "|**2025-07-22**|**Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design**|Xin-De Wang et.al.|[2507.16307](http://arxiv.org/abs/2507.16307)|null|\n", "2507.16199": "|**2025-07-29**|**WakenLLM: Evaluating Reasoning Potential and Stability in LLMs via Fine-Grained Benchmarking**|Zipeng Ling et.al.|[2507.16199](http://arxiv.org/abs/2507.16199)|null|\n", "2507.16196": "|**2025-07-22**|**Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task**|Jared Moore et.al.|[2507.16196](http://arxiv.org/abs/2507.16196)|null|\n", "2507.16184": "|**2025-07-22**|**Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)**|Myung Ho Kim et.al.|[2507.16184](http://arxiv.org/abs/2507.16184)|null|\n", "2507.16110": "|**2025-07-21**|**Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization**|Shengchao Liu et.al.|[2507.16110](http://arxiv.org/abs/2507.16110)|null|\n", "2507.16075": "|**2025-07-21**|**Deep Researcher with Test-Time Diffusion**|Rujun Han et.al.|[2507.16075](http://arxiv.org/abs/2507.16075)|null|\n", "2507.16003": "|**2025-07-21**|**Learning without training: The implicit dynamics of in-context learning**|Benoit Dherin et.al.|[2507.16003](http://arxiv.org/abs/2507.16003)|null|\n", "2507.15974": "|**2025-07-21**|**Does More Inference-Time Compute Really Help Robustness?**|Tong Wu et.al.|[2507.15974](http://arxiv.org/abs/2507.15974)|null|\n", "2507.15917": "|**2025-07-23**|**HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs**|Adrian Kaiser et.al.|[2507.15917](http://arxiv.org/abs/2507.15917)|null|\n", "2507.15874": "|**2025-07-17**|**Why Braking? Scenario Extraction and Reasoning Utilizing LLM**|Yin Wu et.al.|[2507.15874](http://arxiv.org/abs/2507.15874)|null|\n", "2507.17699": "|**2025-07-23**|**Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations**|Zhao Song et.al.|[2507.17699](http://arxiv.org/abs/2507.17699)|null|\n", "2507.17695": "|**2025-07-23**|**Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks**|Ilias Chatzistefanidis et.al.|[2507.17695](http://arxiv.org/abs/2507.17695)|null|\n", "2507.17548": "|**2025-07-23**|**CodeReasoner: Enhancing the Code Reasoning Ability with Reinforcement Learning**|Lingxiao Tang et.al.|[2507.17548](http://arxiv.org/abs/2507.17548)|null|\n", "2507.17512": "|**2025-07-23**|**Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning**|Yu Li et.al.|[2507.17512](http://arxiv.org/abs/2507.17512)|null|\n", "2507.17477": "|**2025-07-23**|**An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models**|Haoran Sun et.al.|[2507.17477](http://arxiv.org/abs/2507.17477)|null|\n", "2507.17476": "|**2025-07-23**|**MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs**|Alexander R. Fabbri et.al.|[2507.17476](http://arxiv.org/abs/2507.17476)|null|\n", "2507.17448": "|**2025-07-23**|**Reasoning-Driven Retrosynthesis Prediction with Large Language Models via Reinforcement Learning**|Situo Zhang et.al.|[2507.17448](http://arxiv.org/abs/2507.17448)|null|\n", "2507.17394": "|**2025-07-23**|**HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs**|Zhaolin Cai et.al.|[2507.17394_(ACM MM)](http://arxiv.org/abs/2507.17394)|null|\n", "2507.17365": "|**2025-07-23**|**DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning**|Chuzhan Hao et.al.|[2507.17365](http://arxiv.org/abs/2507.17365)|null|\n", "2507.17307": "|**2025-08-05**|**R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning**|Zhuokun Chen et.al.|[2507.17307](http://arxiv.org/abs/2507.17307)|null|\n", "2507.17288": "|**2025-07-23**|**Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge**|Miaomiao Gao et.al.|[2507.17288](http://arxiv.org/abs/2507.17288)|null|\n", "2507.17273": "|**2025-07-23**|**Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance**|Rishi Parekh et.al.|[2507.17273](http://arxiv.org/abs/2507.17273)|null|\n", "2507.17257": "|**2025-07-23**|**Agent Identity Evals: Measuring Agentic Identity**|Elija Perrier et.al.|[2507.17257](http://arxiv.org/abs/2507.17257)|null|\n", "2507.17249": "|**2025-07-23**|**R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems**|Hao Gu et.al.|[2507.17249_(RecSys)](http://arxiv.org/abs/2507.17249)|null|\n", "2507.17209": "|**2025-07-23**|**HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery**|Haoran Jiang et.al.|[2507.17209](http://arxiv.org/abs/2507.17209)|null|\n", "2507.17168": "|**2025-07-23**|**Improving LLMs' Generalized Reasoning Abilities by Graph Problems**|Qifan Zhang et.al.|[2507.17168](http://arxiv.org/abs/2507.17168)|null|\n", "2507.17147": "|**2025-07-23**|**CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning with Implicit Rule-Based Rewards**|Cheng Liu et.al.|[2507.17147](http://arxiv.org/abs/2507.17147)|null|\n", "2507.17134": "|**2025-07-23**|**Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination**|Mariam ALMutairi et.al.|[2507.17134](http://arxiv.org/abs/2507.17134)|null|\n", "2507.17075": "|**2025-07-22**|**LoRA is All You Need for Safety Alignment of Reasoning LLMs**|Yihao Xue et.al.|[2507.17075](http://arxiv.org/abs/2507.17075)|null|\n", "2507.17047": "|**2025-07-22**|**Controllable Hybrid Captioner for Improved Long-form Video Understanding**|Kuleen Sasse et.al.|[2507.17047](http://arxiv.org/abs/2507.17047)|null|\n", "2507.16971": "|**2025-07-22**|**Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning**|Aleksandr Perevalov et.al.|[2507.16971_(ICIP)](http://arxiv.org/abs/2507.16971)|null|\n", "2507.16940": "|**2025-07-22**|**AURA: A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation**|Nima Fathi et.al.|[2507.16940](http://arxiv.org/abs/2507.16940)|null|\n", "2507.16878": "|**2025-07-22**|**CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos**|Xuchen Li et.al.|[2507.16878](http://arxiv.org/abs/2507.16878)|null|\n", "2508.05012": "|**2025-08-07**|**Making Prompts First-Class Citizens for Adaptive LLM Pipelines**|Ugur Cetintemel et.al.|[2508.05012](http://arxiv.org/abs/2508.05012)|null|\n", "2508.04581": "|**2025-08-06**|**Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning**|Magauiya Zhussip et.al.|[2508.04581](http://arxiv.org/abs/2508.04581)|null|\n", "2508.04462": "|**2025-08-06**|**CARD: Cache-Assisted Parallel Speculative Decoding for Efficient Large Language Model Inference**|Enyu Zhou et.al.|[2508.04462](http://arxiv.org/abs/2508.04462)|null|\n", "2508.04257": "|**2025-08-06**|**KVSink: Understanding and Enhancing the Preservation of Attention Sinks in KV Cache Quantization for LLMs**|Zunhai Su et.al.|[2508.04257](http://arxiv.org/abs/2508.04257)|null|\n", "2508.03258": "|**2025-08-05**|**SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization**|Yueyue Liu et.al.|[2508.03258](http://arxiv.org/abs/2508.03258)|null|\n", "2508.02558": "|**2025-08-04**|**Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction**|Yuerong Song et.al.|[2508.02558](http://arxiv.org/abs/2508.02558)|null|\n", "2508.02401": "|**2025-08-04**|**CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation**|Xiaolin Lin et.al.|[2508.02401](http://arxiv.org/abs/2508.02401)|null|\n", "2508.02215": "|**2025-08-04**|**LeanK: Learnable K Cache Channel Pruning for Efficient Decoding**|Yike Zhang et.al.|[2508.02215](http://arxiv.org/abs/2508.02215)|null|\n", "2508.02751": "|**2025-08-03**|**SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference**|Yi Zhao et.al.|[2508.02751](http://arxiv.org/abs/2508.02751)|null|\n", "2508.00370": "|**2025-08-06**|**EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices**|Jiyu Chen et.al.|[2508.00370](http://arxiv.org/abs/2508.00370)|null|\n", "2507.23674": "|**2025-07-31**|**TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses**|Muhammad Taha Cheema et.al.|[2507.23674](http://arxiv.org/abs/2507.23674)|null|\n", "2508.00904": "|**2025-07-29**|**Forecasting LLM Inference Performance via Hardware-Agnostic Analytical Modeling**|Rajeev Patwari et.al.|[2508.00904](http://arxiv.org/abs/2508.00904)|null|\n", "2507.20984": "|**2025-07-30**|**SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment**|Yixin Song et.al.|[2507.20984](http://arxiv.org/abs/2507.20984)|null|\n", "2507.20030": "|**2025-07-26**|**FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression**|Runchao Li et.al.|[2507.20030](http://arxiv.org/abs/2507.20030)|null|\n", "2507.19906": "|**2025-08-04**|**CaliDrop: KV Cache Compression with Calibration**|Yi Su et.al.|[2507.19906](http://arxiv.org/abs/2507.19906)|null|\n", "2507.19823": "|**2025-07-26**|**HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs**|Dongquan Yang et.al.|[2507.19823](http://arxiv.org/abs/2507.19823)|null|\n", "2507.19427": "|**2025-07-25**|**Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding**|StepFun et.al.|[2507.19427](http://arxiv.org/abs/2507.19427)|null|\n", "2504.14051": "|**2025-07-04**|**CAOTE: KV Cache Eviction for LLMs via Attention Output Error-Based Token Selection**|Raghavv Goel et.al.|[2504.14051](http://arxiv.org/abs/2504.14051)|null|\n", "2504.02441": "|**2025-04-24**|**Cognitive Memory in Large Language Models**|Lianlei Shan et.al.|[2504.02441](http://arxiv.org/abs/2504.02441)|null|\n", "2504.02268": "|**2025-04-03**|**Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and Synthetic Data**|Waris Gill et.al.|[2504.02268](http://arxiv.org/abs/2504.02268)|null|\n", "2503.24358": "|**2025-07-28**|**SQuat: Subspace-orthogonal KV Cache Quantization**|Hao Wang et.al.|[2503.24358](http://arxiv.org/abs/2503.24358)|null|\n", "2503.22196": "|**2025-03-28**|**EdgeInfinite: A Memory-Efficient Infinite-Context Transformer for Edge Devices**|Jiyu Chen et.al.|[2503.22196](http://arxiv.org/abs/2503.22196)|null|\n", "2403.09636": "|**2024-07-23**|**Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference**|Piotr Nawrot et.al.|[2403.09636](http://arxiv.org/abs/2403.09636)|null|\n", "2403.08058": "|**2024-04-27**|**CHAI: Clustered Head Attention for Efficient LLM Inference**|Saurabh Agarwal et.al.|[2403.08058](http://arxiv.org/abs/2403.08058)|null|\n", "2403.05821": "|**2025-04-09**|**Optimizing LLM Queries in Relational Data Analytics Workloads**|Shu Liu et.al.|[2403.05821](http://arxiv.org/abs/2403.05821)|null|\n", "2403.01876": "|**2024-03-04**|**D\u00e9j\u00e0Vu: KV-cache Streaming for Fast, Fault-tolerant Generative LLM Serving**|Foteini Strati et.al.|[2403.01876](http://arxiv.org/abs/2403.01876)|null|\n", "2402.14808": "|**2024-05-30**|**RelayAttention for Efficient Large Language Model Serving with Long System Prompts**|Lei Zhu et.al.|[2402.14808_(ACL)](http://arxiv.org/abs/2402.14808)|null|\n", "2402.14480": "|**2024-02-22**|**MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation**|Guanyu Wang et.al.|[2402.14480](http://arxiv.org/abs/2402.14480)|null|\n", "2402.02750": "|**2024-07-25**|**KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache**|Zirui Liu et.al.|[2402.02750_(ICML)](http://arxiv.org/abs/2402.02750)|null|\n", "2401.18079": "|**2025-05-28**|**KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization**|Coleman Hooper et.al.|[2401.18079_(NeurIPS)](http://arxiv.org/abs/2401.18079)|null|\n", "2401.06761": "|**2024-01-12**|**APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding**|Mingdao Liu et.al.|[2401.06761](http://arxiv.org/abs/2401.06761)|null|\n", "2312.05516": "|**2024-10-07**|**Stateful Large Language Model Serving with Pensieve**|Lingfan Yu et.al.|[2312.05516](http://arxiv.org/abs/2312.05516)|null|\n", "2310.07240": "|**2024-07-19**|**CacheGen: KV Cache Compression and Streaming for Fast Large Language Model Serving**|Yuhan Liu et.al.|[2310.07240_(SIGCOMM)](http://arxiv.org/abs/2310.07240)|null|\n", "2310.01796": "|**2024-03-22**|**LILAC: Log Parsing using LLMs with Adaptive Parsing Cache**|Zhihan Jiang et.al.|[2310.01796_(FSE)](http://arxiv.org/abs/2310.01796)|null|\n", "2309.06180": "|**2023-09-12**|**Efficient Memory Management for Large Language Model Serving with PagedAttention**|Woosuk Kwon et.al.|[2309.06180_(SOSP)](http://arxiv.org/abs/2309.06180)|null|\n", "2503.11816": "|**2025-04-22**|**Key, Value, Compress: A Systematic Exploration of KV Cache Compression Techniques**|Neusha Javidnia et.al.|[2503.11816_(ICC)](http://arxiv.org/abs/2503.11816)|null|\n", "2503.10714": "|**2025-04-06**|**ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs**|Xin Liu et.al.|[2503.10714](http://arxiv.org/abs/2503.10714)|null|\n", "2504.03661": "|**2025-04-08**|**MILLION: Mastering Long-Context LLM Inference Via Outlier-Immunized KV Product Quantization**|Zongwu Wang et.al.|[2504.03661](http://arxiv.org/abs/2504.03661)|null|\n", "2503.08879": "|**2025-03-11**|**LLMs Know What to Drop: Self-Attention Guided KV Cache Eviction for Efficient Long-Context Inference**|Guangtao Wang et.al.|[2503.08879](http://arxiv.org/abs/2503.08879)|null|\n", "2503.06594": "|**2025-06-01**|**Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation**|Yingfeng Luo et.al.|[2503.06594_(ACL)](http://arxiv.org/abs/2503.06594)|**[link](https://github.com/NiuTrans/LaMaTE)**|\n", "2503.05530": "|**2025-03-07**|**Leveraging Approximate Caching for Faster Retrieval-Augmented Generation**|Shai Bergman et.al.|[2503.05530](http://arxiv.org/abs/2503.05530)|null|\n", "2503.02236": "|**2025-06-30**|**VQ-LLM: High-performance Code Generation for Vector Quantization Augmented LLM Inference**|Zihan Liu et.al.|[2503.02236](http://arxiv.org/abs/2503.02236)|null|\n", "2503.00979": "|**2025-06-07**|**Dialogue Without Limits: Constant-Sized KV Caches for Extended Responses in LLMs**|Ravi Ghadia et.al.|[2503.00979_(CHI)](http://arxiv.org/abs/2503.00979)|null|\n", "2502.17599": "|**2025-03-13**|**MEDA: Dynamic KV Cache Allocation for Efficient Multimodal Long-Context Inference**|Zhongwei Wan et.al.|[2502.17599_(ACL)](http://arxiv.org/abs/2502.17599)|null|\n", "2502.17139": "|**2025-02-24**|**CodeSwift: Accelerating LLM Inference for Efficient Code Generation**|Qianhui Zhao et.al.|[2502.17139](http://arxiv.org/abs/2502.17139)|null|\n", "2502.16886": "|**2025-06-09**|**DBudgetKV: Dynamic Budget in KV Cache Compression for Ensuring Optimal Performance**|Xuanfan Ni et.al.|[2502.16886](http://arxiv.org/abs/2502.16886)|null|\n", "2503.00022": "|**2025-02-24**|**KVCrush: Key value cache size-reduction using similarity in head-behaviour**|Gopi Krishna Jha et.al.|[2503.00022](http://arxiv.org/abs/2503.00022)|null|\n", "2502.16002": "|**2025-07-19**|**KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse**|Jingbo Yang et.al.|[2502.16002](http://arxiv.org/abs/2502.16002)|null|\n", "2502.17501": "|**2025-02-21**|**CoKV: Optimizing KV Cache Allocation via Cooperative Game**|Qiheng Sun et.al.|[2502.17501](http://arxiv.org/abs/2502.17501)|null|\n", "2502.15304": "|**2025-02-21**|**SVDq: 1.25-bit and 410x Key Cache Compression for LLM Attention**|Hong Yankun et.al.|[2502.15304](http://arxiv.org/abs/2502.15304)|null|\n", "2502.14837": "|**2025-02-20**|**Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs**|Tao Ji et.al.|[2502.14837](http://arxiv.org/abs/2502.14837)|null|\n", "2502.14051": "|**2025-06-30**|**RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression**|Payman Behnam et.al.|[2502.14051_(ICML)](http://arxiv.org/abs/2502.14051)|null|\n", "2502.13502": "|**2025-02-22**|**PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference**|Burc Gokden et.al.|[2502.13502](http://arxiv.org/abs/2502.13502)|null|\n", "2502.12574": "|**2025-02-18**|**HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading**|Cheng Luo et.al.|[2502.12574](http://arxiv.org/abs/2502.12574)|null|\n", "2502.13176": "|**2025-02-24**|**BaKlaVa -- Budgeted Allocation of KV cache for Long-context Inference**|Ahmed Burak Gulhan et.al.|[2502.13176](http://arxiv.org/abs/2502.13176)|null|\n", "2502.12224": "|**2025-05-07**|**Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate**|Zhiyuan Fang et.al.|[2502.12224](http://arxiv.org/abs/2502.12224)|null|\n", "2502.12216": "|**2025-02-17**|**Tactic: Adaptive Sparse Attention with Clustering and Distribution Fitting for Long-Context LLMs**|Kan Zhu et.al.|[2502.12216](http://arxiv.org/abs/2502.12216)|null|\n", "2502.11101": "|**2025-02-16**|**CacheFocus: Dynamic Cache Re-Positioning for Efficient Retrieval-Augmented Generation**|Kun-Hui Lee et.al.|[2502.11101](http://arxiv.org/abs/2502.11101)|null|\n", "2502.14882": "|**2025-03-24**|**CalibQuant: 1-Bit KV Cache Quantization for Multimodal LLMs**|Insu Han et.al.|[2502.14882](http://arxiv.org/abs/2502.14882)|null|\n", "2502.10659": "|**2025-02-15**|**Pushing up to the Limit of Memory Bandwidth and Capacity Utilization for Efficient LLM Decoding on Embedded FPGA**|Jindong Li et.al.|[2502.10659_(DATE)](http://arxiv.org/abs/2502.10659)|null|\n", "2502.09921": "|**2025-02-14**|**INF^2: High-Throughput Generative Inference of Large Language Models using Near-Storage Processing**|Hongsun Jang et.al.|[2502.09921](http://arxiv.org/abs/2502.09921)|null|\n", "2502.08910": "|**2025-02-13**|**InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU**|Heejun Lee et.al.|[2502.08910](http://arxiv.org/abs/2502.08910)|null|\n", "2502.07578": "|**2025-05-03**|**PIM Is All You Need: A CXL-Enabled GPU-Free System for Large Language Model Inference**|Yufeng Gu et.al.|[2502.07578_(ASPLOS)](http://arxiv.org/abs/2502.07578)|null|\n", "2502.06901": "|**2025-02-09**|**Enabling Autoregressive Models to Fill In Masked Tokens**|Daniel Israel et.al.|[2502.06901](http://arxiv.org/abs/2502.06901)|null|\n", "2502.04077": "|**2025-02-26**|**AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference**|Qingyue Yang et.al.|[2502.04077](http://arxiv.org/abs/2502.04077)|null|\n", "2502.03805": "|**2025-02-06**|**Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective**|Yuan Feng et.al.|[2502.03805](http://arxiv.org/abs/2502.03805)|null|\n", "2502.03771": "|**2025-05-27**|**vCache: Verified Semantic Prompt Caching**|Luis Gaspar Schroeder et.al.|[2502.03771](http://arxiv.org/abs/2502.03771)|null|\n", "2502.10424": "|**2025-02-05**|**QuantSpec: Self-Speculative Decoding with Hierarchical Quantized KV Cache**|Rishabh Tiwari et.al.|[2502.10424](http://arxiv.org/abs/2502.10424)|null|\n", "2502.03589": "|**2025-02-05**|**HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference**|Zeyu Zhang et.al.|[2502.03589](http://arxiv.org/abs/2502.03589)|null|\n", "2502.02493": "|**2025-02-04**|**EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization**|Yize Wu et.al.|[2502.02493](http://arxiv.org/abs/2502.02493)|null|\n", "2502.01068": "|**2025-05-21**|**FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation**|Dongwon Jo et.al.|[2502.01068](http://arxiv.org/abs/2502.01068)|null|\n", "2502.00299": "|**2025-06-27**|**ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference**|Xiang Liu et.al.|[2502.00299](http://arxiv.org/abs/2502.00299)|null|\n", "2501.19392": "|**2025-02-28**|**Cache Me If You Must: Adaptive Key-Value Quantization for Large Language Models**|Alina Shutova et.al.|[2501.19392](http://arxiv.org/abs/2501.19392)|null|\n", "2501.12959": "|**2025-02-05**|**Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference**|Weizhi Fei et.al.|[2501.12959](http://arxiv.org/abs/2501.12959)|null|\n", "2501.11779": "|**2025-02-11**|**Glinthawk: A Two-Tiered Architecture for Offline LLM Inference**|Pouya Hamadanian et.al.|[2501.11779](http://arxiv.org/abs/2501.11779)|null|\n", "2508.05613": "|**2025-08-07**|**Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models**|Haitao Hong et.al.|[2508.05613](http://arxiv.org/abs/2508.05613)|**[link](https://zju-real.github.io/cooper)**|\n", "2508.05606": "|**2025-08-07**|**Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision**|Luozheng Qin et.al.|[2508.05606](http://arxiv.org/abs/2508.05606)|**[link](https://sais-fuxi.github.io/projects/uni-cot/)**|\n", "2508.05592": "|**2025-08-11**|**MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy**|Shaoxiong Zhan et.al.|[2508.05592](http://arxiv.org/abs/2508.05592)|null|\n", "2508.05585": "|**2025-08-07**|**DART: Dual Adaptive Refinement Transfer for Open-Vocabulary Multi-Label Recognition**|Haijing Liu et.al.|[2508.05585_(ACM MM)](http://arxiv.org/abs/2508.05585)|null|\n", "2508.05581": "|**2025-08-07**|**Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models**|Guilherme Seidyo Imai Aldeia et.al.|[2508.05581_(ALT)](http://arxiv.org/abs/2508.05581)|null|\n", "2508.05525": "|**2025-08-07**|**The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities**|Harsh Nishant Lalai et.al.|[2508.05525](http://arxiv.org/abs/2508.05525)|null|\n", "2508.05509": "|**2025-08-11**|**LAG: Logic-Augmented Generation from a Cartesian Perspective**|Yilin Xiao et.al.|[2508.05509](http://arxiv.org/abs/2508.05509)|null|\n", "2508.05508": "|**2025-08-07**|**Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation**|Roshita Bhonsle et.al.|[2508.05508](http://arxiv.org/abs/2508.05508)|null|\n", "2508.05498": "|**2025-08-07**|**GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning**|Ge Chang et.al.|[2508.05498](http://arxiv.org/abs/2508.05498)|null|\n", "2508.05496": "|**2025-08-12**|**InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities**|Shuo Cai et.al.|[2508.05496](http://arxiv.org/abs/2508.05496)|null|\n", "2508.05468": "|**2025-08-07**|**TASE: Token Awareness and Structured Evaluation for Multilingual Language Models**|Chenzhuo Zhao et.al.|[2508.05468](http://arxiv.org/abs/2508.05468)|null|\n", "2508.05428": "|**2025-08-07**|**Group Causal Policy Optimization for Post-Training Large Language Models**|Ziyin Gu et.al.|[2508.05428](http://arxiv.org/abs/2508.05428)|null|\n", "2508.05427": "|**2025-08-07**|**Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation**|Kartar Kumar Lohana Tharwani et.al.|[2508.05427](http://arxiv.org/abs/2508.05427)|null|\n", "2508.05366": "|**2025-08-07**|**Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025**|Samy Ateia et.al.|[2508.05366](http://arxiv.org/abs/2508.05366)|null|\n", "2508.05344": "|**2025-08-07**|**NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making**|Asutosh Hota et.al.|[2508.05344](http://arxiv.org/abs/2508.05344)|null|\n", "2508.05342": "|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Shunlei Li et.al.|[2508.05342](http://arxiv.org/abs/2508.05342)|null|\n", "2508.05311": "|**2025-08-07**|**A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents**|Andrew Kiruluta et.al.|[2508.05311](http://arxiv.org/abs/2508.05311)|null|\n", "2508.05294": "|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](http://arxiv.org/abs/2508.05294)|null|\n", "2508.05282": "|**2025-08-07**|**ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs**|Dongxu Zhang et.al.|[2508.05282](http://arxiv.org/abs/2508.05282)|null|\n", "2508.05269": "|**2025-08-07**|**B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding**|Changho Choi et.al.|[2508.05269_(ACM MM)](http://arxiv.org/abs/2508.05269)|null|\n", "2508.05267": "|**2025-08-07**|**An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication**|V\u00edtor N. Louren\u00e7o et.al.|[2508.05267_(ISWC)](http://arxiv.org/abs/2508.05267)|null|\n", "2508.05266": "|**2025-08-07**|**Understanding and Mitigating Errors of LLM-Generated RTL Code**|Jiazheng Zhang et.al.|[2508.05266](http://arxiv.org/abs/2508.05266)|null|\n", "2508.05234": "|**2025-08-07**|**Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation**|Haonan Shangguan et.al.|[2508.05234](http://arxiv.org/abs/2508.05234)|null|\n", "2508.05232": "|**2025-08-07**|**Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs**|Feifan Xia et.al.|[2508.05232](http://arxiv.org/abs/2508.05232)|null|\n", "2508.05193": "|**2025-08-07**|**STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning**|Kaiwen Yan et.al.|[2508.05193](http://arxiv.org/abs/2508.05193)|null|\n", "2508.05170": "|**2025-08-07**|**Posterior-GRPO: Rewarding Reasoning Processes in Code Generation**|Lishui Fan et.al.|[2508.05170](http://arxiv.org/abs/2508.05170)|null|\n", "2508.05132": "|**2025-08-07**|**Towards Assessing Medical Ethics from Knowledge to Practice**|Chang Hong et.al.|[2508.05132](http://arxiv.org/abs/2508.05132)|null|\n", "2508.05129": "|**2025-08-07**|**Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning**|Wuqiang Zheng et.al.|[2508.05129](http://arxiv.org/abs/2508.05129)|null|\n", "2508.05118": "|**2025-08-08**|**Exploring Superior Function Calls via Reinforcement Learning**|Bingguang Hao et.al.|[2508.05118](http://arxiv.org/abs/2508.05118)|null|\n", "2508.05087": "|**2025-08-07**|**JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering**|Renmiao Chen et.al.|[2508.05087](http://arxiv.org/abs/2508.05087)|null|\n", "2508.05053": "|**2025-08-07**|**Finding Needles in Images: Can Multimodal LLMs Locate Fine Details?**|Parth Thakkar et.al.|[2508.05053_(ACL)](http://arxiv.org/abs/2508.05053)|null|\n", "2508.05015": "|**2025-08-07**|**SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models**|Dai Do et.al.|[2508.05015](http://arxiv.org/abs/2508.05015)|null|\n", "2508.05009": "|**2025-08-07**|**Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses**|Bin Han et.al.|[2508.05009](http://arxiv.org/abs/2508.05009)|null|\n", "2508.05005": "|**2025-08-07**|**Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic**|Gang Xu et.al.|[2508.05005](http://arxiv.org/abs/2508.05005)|null|\n", "2508.05004": "|**2025-08-07**|**R-Zero: Self-Evolving Reasoning LLM from Zero Data**|Chengsong Huang et.al.|[2508.05004](http://arxiv.org/abs/2508.05004)|null|\n", "2508.04975": "|**2025-08-07**|**Sentiment-Aware Stock Price Prediction with Transformer and LLM-Generated Formulaic Alpha**|Qizhao Chen et.al.|[2508.04975](http://arxiv.org/abs/2508.04975)|null|\n", "2508.04903": "|**2025-08-10**|**RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory**|Jun Liu et.al.|[2508.04903](http://arxiv.org/abs/2508.04903)|null|\n", "2508.04848": "|**2025-08-06**|**Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning**|Chang Tian et.al.|[2508.04848](http://arxiv.org/abs/2508.04848)|null|\n", "2508.04826": "|**2025-08-06**|**Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History**|Tommaso Tosato et.al.|[2508.04826](http://arxiv.org/abs/2508.04826)|null|\n", "2508.04664": "|**2025-08-06**|**Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management**|Mo Li et.al.|[2508.04664](http://arxiv.org/abs/2508.04664)|null|\n", "2508.04531": "|**2025-08-06**|**Unveiling the Landscape of Clinical Depression Assessment: From Behavioral Signatures to Psychiatric Reasoning**|Zhuang Chen et.al.|[2508.04531](http://arxiv.org/abs/2508.04531)|null|\n", "2508.04495": "|**2025-08-06**|**Causal Reflection with Language Models**|Abi Aryan et.al.|[2508.04495](http://arxiv.org/abs/2508.04495)|null|\n", "2508.04474": "|**2025-08-06**|**TRAIL: Joint Inference and Refinement of Knowledge Graphs with Large Language Models**|Xinkui Zhao et.al.|[2508.04474](http://arxiv.org/abs/2508.04474)|null|\n", "2508.04460": "|**2025-08-06**|**From \"Aha Moments\" to Controllable Thinking: Toward Meta-Cognitive Reasoning in Large Reasoning Models via Decoupled Reasoning and Control**|Rui Ha et.al.|[2508.04460](http://arxiv.org/abs/2508.04460)|null|\n", "2508.04448": "|**2025-08-06**|**Large Language Models Versus Static Code Analysis Tools: A Systematic Benchmark for Vulnerability Detection**|Damian Gnieciak et.al.|[2508.04448](http://arxiv.org/abs/2508.04448)|null|\n", "2508.04755": "|**2025-08-06**|**Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle**|Zhiyao Luo et.al.|[2508.04755](http://arxiv.org/abs/2508.04755)|null|\n", "2508.04440": "|**2025-08-06**|**StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion**|Yutong Wu et.al.|[2508.04440](http://arxiv.org/abs/2508.04440)|null|\n", "2508.04428": "|**2025-08-06**|**\\textsc{SimInstruct}: A Responsible Tool for Collecting Scaffolding Dialogues Between Experts and LLM-Simulated Novices**|Si Chen et.al.|[2508.04428](http://arxiv.org/abs/2508.04428)|null|\n", "2508.04350": "|**2025-08-06**|**Chain of Questions: Guiding Multimodal Curiosity in Language Models**|Nima Iji et.al.|[2508.04350](http://arxiv.org/abs/2508.04350)|null|\n", "2508.04349": "|**2025-08-06**|**GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy**|Hongze Tan et.al.|[2508.04349](http://arxiv.org/abs/2508.04349)|null|\n", "2508.04339": "|**2025-08-06**|**Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models**|Anran Xu et.al.|[2508.04339](http://arxiv.org/abs/2508.04339)|null|\n", "2508.04289": "|**2025-08-07**|**Method-Based Reasoning for Large Language Models: Extraction, Reuse, and Continuous Improvement**|Hong Su et.al.|[2508.04289](http://arxiv.org/abs/2508.04289)|null|\n", "2508.04280": "|**2025-08-06**|**Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success**|George Bredis et.al.|[2508.04280](http://arxiv.org/abs/2508.04280)|null|\n", "2508.04279": "|**2025-08-06**|**Mockingbird: How does LLM perform in general machine learning tasks?**|Haoyu Jia et.al.|[2508.04279](http://arxiv.org/abs/2508.04279)|null|\n", "2508.04276": "|**2025-08-06**|**A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models**|Jiayi Wen et.al.|[2508.04276](http://arxiv.org/abs/2508.04276)|null|\n", "2508.04748": "|**2025-08-06**|**AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models**|Xuan Lin et.al.|[2508.04748](http://arxiv.org/abs/2508.04748)|null|\n", "2508.04199": "|**2025-08-06**|**Reasoning Beyond Labels: Measuring LLM Sentiment in Low-Resource, Culturally Nuanced Contexts**|Millicent Ochieng et.al.|[2508.04199](http://arxiv.org/abs/2508.04199)|null|\n", "2508.04196": "|**2025-08-06**|**Eliciting and Analyzing Emergent Misalignment in State-of-the-Art Large Language Models**|Siddhant Panpatil et.al.|[2508.04196](http://arxiv.org/abs/2508.04196)|null|\n", "2508.04175": "|**2025-08-06**|**AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization**|Jingyi Liao et.al.|[2508.04175](http://arxiv.org/abs/2508.04175)|null|\n", "2508.04138": "|**2025-08-06**|**COPO: Consistency-Aware Policy Optimization**|Jinghang Han et.al.|[2508.04138](http://arxiv.org/abs/2508.04138)|null|\n", "2508.04117": "|**2025-08-06**|**Unveiling Over-Memorization in Finetuning LLMs for Reasoning Tasks**|Zhiwen Ruan et.al.|[2508.04117](http://arxiv.org/abs/2508.04117)|null|\n", "2508.04080": "|**2025-08-06**|**GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement**|Jinfan Tang et.al.|[2508.04080](http://arxiv.org/abs/2508.04080)|null|\n", "2508.04072": "|**2025-08-06**|**KG-Augmented Executable CoT for Mathematical Coding**|Xingyu Chen et.al.|[2508.04072](http://arxiv.org/abs/2508.04072)|null|\n", "2508.04038": "|**2025-08-06**|**ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents**|Zechen Li et.al.|[2508.04038](http://arxiv.org/abs/2508.04038)|null|\n", "2508.04032": "|**2025-08-06**|**Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge Graphs with Large Language Models**|Qian Yong et.al.|[2508.04032](http://arxiv.org/abs/2508.04032)|null|\n", "2508.04031": "|**2025-08-06**|**BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases**|Lianggui Weng et.al.|[2508.04031](http://arxiv.org/abs/2508.04031)|null|\n", "2508.03999": "|**2025-08-06**|**Tensorized Clustered LoRA Merging for Multi-Task Interference**|Zhan Su et.al.|[2508.03999](http://arxiv.org/abs/2508.03999)|null|\n", "2508.03979": "|**2025-08-06**|**Confidence-Weighted Token Set Cover for Early Hypothesis Pruning in Self-Consistency**|Md Arafat Sultan et.al.|[2508.03979](http://arxiv.org/abs/2508.03979)|null|\n", "2508.03963": "|**2025-08-08**|**Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?**|Zewen Liu et.al.|[2508.03963](http://arxiv.org/abs/2508.03963)|null|\n", "2508.03860": "|**2025-08-05**|**Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models**|Subhey Sadi Rahman et.al.|[2508.03860](http://arxiv.org/abs/2508.03860)|null|\n", "2508.03686": "|**2025-08-05**|**CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward**|Shudong Liu et.al.|[2508.03686](http://arxiv.org/abs/2508.03686)|null|\n", "2508.03622": "|**2025-08-05**|**Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework**|Jialin Li et.al.|[2508.03622](http://arxiv.org/abs/2508.03622)|null|\n", "2508.03556": "|**2025-08-05**|**VRPRM: Process Reward Modeling via Visual Reasoning**|Xinquan Chen et.al.|[2508.03556](http://arxiv.org/abs/2508.03556)|null|\n", "2508.03550": "|**2025-08-05**|**Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations**|Peng Lai et.al.|[2508.03550](http://arxiv.org/abs/2508.03550)|null|\n", "2508.03527": "|**2025-08-05**|**MoKA: Mixture of Kronecker Adapters**|Mohammadreza Sadeghi et.al.|[2508.03527](http://arxiv.org/abs/2508.03527)|null|\n", "2508.03501": "|**2025-08-05**|**Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning**|Alexander Golubev et.al.|[2508.03501](http://arxiv.org/abs/2508.03501)|null|\n", "2508.03500": "|**2025-08-05**|**Error Detection and Correction for Interpretable Mathematics in Large Language Models**|Yijin Yang et.al.|[2508.03500](http://arxiv.org/abs/2508.03500)|null|\n", "2508.03470": "|**2025-08-05**|**On the Evaluation of Large Language Models in Multilingual Vulnerability Repair**|Dong wang et.al.|[2508.03470](http://arxiv.org/abs/2508.03470)|null|\n", "2508.03444": "|**2025-08-05**|**An Auditable Agent Platform For Automated Molecular Optimisation**|Atabey \u00dcnl\u00fc et.al.|[2508.03444](http://arxiv.org/abs/2508.03444)|null|\n", "2508.03440": "|**2025-08-07**|**LLMs are Single-threaded Reasoners: Demystifying the Working Mechanism of Soft Thinking**|Ch\u00fcnhung Wu et.al.|[2508.03440](http://arxiv.org/abs/2508.03440)|null|\n", "2508.03396": "|**2025-08-05**|**Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis**|Rui Zou et.al.|[2508.03396](http://arxiv.org/abs/2508.03396)|null|\n", "2508.03379": "|**2025-08-06**|**Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams**|Wenxin Mao et.al.|[2508.03379](http://arxiv.org/abs/2508.03379)|null|\n", "2508.03368": "|**2025-08-05**|**Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play**|Lucia Cipolina-Kun et.al.|[2508.03368](http://arxiv.org/abs/2508.03368)|null|\n", "2508.03366": "|**2025-08-05**|**A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning**|Michael K. Chen et.al.|[2508.03366](http://arxiv.org/abs/2508.03366)|null|\n", "2508.03346": "|**2025-08-05**|**Compressing Chain-of-Thought in LLMs via Step Entropy**|Zeju Li et.al.|[2508.03346](http://arxiv.org/abs/2508.03346)|null|\n", "2508.03262": "|**2025-08-05**|**Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?**|Junhyuk Choi et.al.|[2508.03262](http://arxiv.org/abs/2508.03262)|null|\n", "2508.03247": "|**2025-08-05**|**Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs**|Shintaro Sakai et.al.|[2508.03247](http://arxiv.org/abs/2508.03247)|null|\n", "2508.03178": "|**2025-08-05**|**Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following**|Chenyang Wang et.al.|[2508.03178](http://arxiv.org/abs/2508.03178)|null|\n", "2508.03159": "|**2025-08-05**|**CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction**|Jueon Park et.al.|[2508.03159](http://arxiv.org/abs/2508.03159)|null|\n", "2508.04720": "|**2025-08-05**|**Who is a Better Player: LLM against LLM**|Yingjie Zhou et.al.|[2508.04720](http://arxiv.org/abs/2508.04720)|null|\n", "2508.03140": "|**2025-08-05**|**RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior**|Junyao Yang et.al.|[2508.03140](http://arxiv.org/abs/2508.03140)|null|\n", "2508.03120": "|**2025-08-05**|**Can Large Language Models Identify Materials from Radar Signals?**|Jiangyou Zhu et.al.|[2508.03120](http://arxiv.org/abs/2508.03120)|null|\n", "2508.03109": "|**2025-08-05**|**AgentSME for Simulating Diverse Communication Modes in Smart Education**|Wen-Xi Yang et.al.|[2508.03109](http://arxiv.org/abs/2508.03109)|null|\n", "2508.03099": "|**2025-08-05**|**Point2Act: Efficient 3D Distillation of Multimodal LLMs for Zero-Shot Context-Aware Grasping**|Sang Min Kim et.al.|[2508.03099](http://arxiv.org/abs/2508.03099)|null|\n", "2508.03092": "|**2025-08-05**|**Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework**|Zikun Cui et.al.|[2508.03092](http://arxiv.org/abs/2508.03092)|null|\n", "2508.03080": "|**2025-08-05**|**ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts**|Shuang Liu et.al.|[2508.03080](http://arxiv.org/abs/2508.03080)|null|\n", "2508.03054": "|**2025-08-05**|**Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning**|Rui Pu et.al.|[2508.03054](http://arxiv.org/abs/2508.03054)|null|\n", "2508.03038": "|**2025-08-05**|**Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree**|Qi Peng et.al.|[2508.03038_(ACM MM)](http://arxiv.org/abs/2508.03038)|null|\n", "2508.03012": "|**2025-08-06**|**Tool-integrated Reinforcement Learning for Repo Deep Search**|Zexiong Ma et.al.|[2508.03012](http://arxiv.org/abs/2508.03012)|null|\n", "2508.04719": "|**2025-08-05**|**GeoFlow: Agentic Workflow Automation for Geospatial Tasks**|Amulya Bhattaram et.al.|[2508.04719_(SIGSPATIAL)](http://arxiv.org/abs/2508.04719)|null|\n", "2508.02999": "|**2025-08-05**|**AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots**|Xinjie Zhao et.al.|[2508.02999_(CIKM)](http://arxiv.org/abs/2508.02999)|null|\n", "2508.02994": "|**2025-08-05**|**When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs**|Fangyi Yu et.al.|[2508.02994](http://arxiv.org/abs/2508.02994)|null|\n", "2508.02962": "|**2025-08-04**|**Robot builds a robot's brain: AI generated drone command and control station hosted in the sky**|Peter Burke et.al.|[2508.02962](http://arxiv.org/abs/2508.02962)|null|\n", "2508.02961": "|**2025-08-04**|**Defend LLMs Through Self-Consciousness**|Boshi Huang et.al.|[2508.02961_(KDD)](http://arxiv.org/abs/2508.02961)|null|\n", "2508.02926": "|**2025-08-06**|**GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics**|Arthur Cho et.al.|[2508.02926](http://arxiv.org/abs/2508.02926)|null|\n", "2508.02913": "|**2025-08-04**|**Enhancing Japanese Large Language Models with Reasoning Vectors**|Carolina Minami Oguchi et.al.|[2508.02913](http://arxiv.org/abs/2508.02913)|null|\n", "2508.02886": "|**2025-08-04**|**Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models**|Wenjie Luo et.al.|[2508.02886](http://arxiv.org/abs/2508.02886)|null|\n", "2508.02866": "|**2025-08-04**|**PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows**|Renan Souza et.al.|[2508.02866](http://arxiv.org/abs/2508.02866)|null|\n", "2508.02789": "|**2025-08-04**|**Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science**|Newman Cheng et.al.|[2508.02789](http://arxiv.org/abs/2508.02789)|null|\n", "2508.02591": "|**2025-08-06**|**CharBench: Evaluating the Role of Tokenization in Character-Level Tasks**|Omri Uzan et.al.|[2508.02591](http://arxiv.org/abs/2508.02591)|null|\n", "2508.02584": "|**2025-08-04**|**MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification**|Ming Pok Ng et.al.|[2508.02584](http://arxiv.org/abs/2508.02584)|null|\n", "2508.02583": "|**2025-08-07**|**CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge**|Lei Zan et.al.|[2508.02583](http://arxiv.org/abs/2508.02583)|null|\n", "2508.02511": "|**2025-08-04**|**Test-time Prompt Intervention**|Chenxu Yang et.al.|[2508.02511](http://arxiv.org/abs/2508.02511)|null|\n", "2508.02506": "|**2025-08-04**|**Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms**|Xiaowei Yuan et.al.|[2508.02506](http://arxiv.org/abs/2508.02506)|null|\n", "2508.02458": "|**2025-08-05**|**From Stimuli to Minds: Enhancing Psychological Reasoning in LLMs via Bilateral Reinforcement Learning**|Feng Yichao et.al.|[2508.02458](http://arxiv.org/abs/2508.02458)|null|\n", "2508.02435": "|**2025-08-04**|**Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking**|Shengbo Gong et.al.|[2508.02435](http://arxiv.org/abs/2508.02435)|null|\n", "2508.02419": "|**2025-08-04**|**Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens**|Haohan Zheng et.al.|[2508.02419](http://arxiv.org/abs/2508.02419)|null|\n", "2508.02366": "|**2025-08-04**|**Language Model Guided Reinforcement Learning in Quantitative Trading**|Adam Darmanin et.al.|[2508.02366](http://arxiv.org/abs/2508.02366)|null|\n", "2508.02344": "|**2025-08-04**|**Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems**|Xingchen Zou et.al.|[2508.02344](http://arxiv.org/abs/2508.02344)|null|\n", "2508.02343": "|**2025-08-04**|**MicroMix: Efficient Mixed-Precision Quantization with Microscaling Formats for Large Language Models**|Wenyuan Liu et.al.|[2508.02343](http://arxiv.org/abs/2508.02343)|null|\n", "2508.02298": "|**2025-08-04**|**CAPO: Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment**|Guofu Xie et.al.|[2508.02298](http://arxiv.org/abs/2508.02298)|null|\n", "2508.02276": "|**2025-08-04**|**CellForge: Agentic Design of Virtual Cell Models**|Xiangru Tang et.al.|[2508.02276](http://arxiv.org/abs/2508.02276)|null|\n", "2508.02260": "|**2025-08-04**|**Decomposing the Entropy-Performance Exchange: The Missing Keys to Unlocking Effective Reinforcement Learning**|Jia Deng et.al.|[2508.02260](http://arxiv.org/abs/2508.02260)|null|\n", "2508.02243": "|**2025-08-04**|**I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking**|Ziyan Liu et.al.|[2508.02243](http://arxiv.org/abs/2508.02243)|null|\n", "2508.02134": "|**2025-08-04**|**Free-MoRef: Instantly Multiplexing Context Perception Capabilities of Video-MLLMs within Single Inference**|Kuo Wang et.al.|[2508.02134_(ICC)](http://arxiv.org/abs/2508.02134)|null|\n", "2508.02121": "|**2025-08-04**|**A Survey on AgentOps: Categorization, Challenges, and Future Directions**|Zexin Wang et.al.|[2508.02121](http://arxiv.org/abs/2508.02121)|null|\n", "2508.02120": "|**2025-08-04**|**Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models**|Linan Yue et.al.|[2508.02120](http://arxiv.org/abs/2508.02120)|null|\n", "2508.02110": "|**2025-08-04**|**Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools**|Kanghua Mo et.al.|[2508.02110](http://arxiv.org/abs/2508.02110)|null|\n", "2508.02766": "|**2025-08-04**|**The Silicon Reasonable Person: Can AI Predict How Ordinary People Judge Reasonableness?**|Yonathan A. Arbel et.al.|[2508.02766](http://arxiv.org/abs/2508.02766)|null|\n", "2508.02085": "|**2025-08-07**|**SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents**|Jiaye Lin et.al.|[2508.02085](http://arxiv.org/abs/2508.02085)|null|\n", "2508.02076": "|**2025-08-04**|**Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games**|Yunhao Liang et.al.|[2508.02076](http://arxiv.org/abs/2508.02076)|null|\n", "2508.02074": "|**2025-08-07**|**The SMeL Test: A simple benchmark for media literacy in language models**|Gustaf Ahdritz et.al.|[2508.02074](http://arxiv.org/abs/2508.02074)|null|\n", "2508.02066": "|**2025-08-04**|**MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs**|Guojiang Zhao et.al.|[2508.02066](http://arxiv.org/abs/2508.02066)|null|\n", "2508.05669": "|**2025-08-04**|**Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports**|Jin Khye Tan et.al.|[2508.05669](http://arxiv.org/abs/2508.05669)|**[link](https://github.com/jinkhye/MyFinMarkdown.)**|\n", "2508.02037": "|**2025-08-04**|**Diagnosing Memorization in Chain-of-Thought Reasoning, One Token at a Time**|Huihan Li et.al.|[2508.02037](http://arxiv.org/abs/2508.02037)|null|\n", "2508.01999": "|**2025-08-04**|**Prompting Large Language Models to Detect Dementia Family Caregivers**|Md Badsha Biswas et.al.|[2508.01999](http://arxiv.org/abs/2508.01999)|null|\n", "2508.01977": "|**2025-08-04**|**TIBSTC-CoT: A Multi-Domain Instruction Dataset for Chain-of-Thought Reasoning in Language Models**|Fan Gao et.al.|[2508.01977](http://arxiv.org/abs/2508.01977)|null|\n", "2508.01969": "|**2025-08-04**|**Accelerating LLM Reasoning via Early Rejection with Partial Reward Modeling**|Seyyed Saeid Cheshmi et.al.|[2508.01969](http://arxiv.org/abs/2508.01969)|null|\n", "2508.01930": "|**2025-08-03**|**Word Overuse and Alignment in Large Language Models: The Influence of Learning from Human Feedback**|Tom S. Juzek et.al.|[2508.01930_(KDD)](http://arxiv.org/abs/2508.01930)|null|\n", "2508.01832": "|**2025-08-03**|**MLP Memory: Language Modeling with Retriever-pretrained External Memory**|Rubin Wei et.al.|[2508.01832](http://arxiv.org/abs/2508.01832)|null|\n", "2508.01724": "|**2025-08-03**|**ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection**|Shijie Cao et.al.|[2508.01724](http://arxiv.org/abs/2508.01724)|null|\n", "2508.01696": "|**2025-08-05**|**Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy**|Yi Jiang et.al.|[2508.01696](http://arxiv.org/abs/2508.01696)|**[link](https://github.com/liunian-Jay/CoCoA)**|\n", "2508.01682": "|**2025-08-03**|**The Bidirectional Process Reward Model**|Lingyin Zhang et.al.|[2508.01682](http://arxiv.org/abs/2508.01682)|null|\n", "2508.01680": "|**2025-08-03**|**T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval**|Dong Li et.al.|[2508.01680](http://arxiv.org/abs/2508.01680)|null|\n", "2508.01670": "|**2025-08-03**|**QCBench: Evaluating Large Language Models on Domain-Specific Quantitative Chemistry**|Jiaqing Xie et.al.|[2508.01670](http://arxiv.org/abs/2508.01670)|null|\n", "2508.01623": "|**2025-08-03**|**A Multi-Agent Pokemon Tournament for Evaluating Strategic Reasoning of Large Language Models**|Tadisetty Sai Yashwanth et.al.|[2508.01623](http://arxiv.org/abs/2508.01623)|null|\n", "2508.01617": "|**2025-08-03**|**LLaDA-MedV: Exploring Large Language Diffusion Models for Biomedical Image Understanding**|Xuanzhao Dong et.al.|[2508.01617](http://arxiv.org/abs/2508.01617)|null|\n", "2508.01608": "|**2025-08-03**|**From Pixels to Places: A Systematic Benchmark for Evaluating Image Geolocalization Ability in Large Language Models**|Lingyao Li et.al.|[2508.01608](http://arxiv.org/abs/2508.01608)|null|\n", "2508.01604": "|**2025-08-03**|**Enhancing Math Reasoning in Small-sized LLMs via Preview Difficulty-Aware Intervention**|Xinhan Di et.al.|[2508.01604_(ICML)](http://arxiv.org/abs/2508.01604)|null|\n", "2508.01523": "|**2025-08-02**|**Exploring Direct Instruction and Summary-Mediated Prompting in LLM-Assisted Code Modification**|Ningzhi Tang et.al.|[2508.01523](http://arxiv.org/abs/2508.01523)|null|\n", "2508.01491": "|**2025-08-02**|**The Homogenizing Effect of Large Language Models on Human Expression and Thought**|Zhivar Sourati et.al.|[2508.01491](http://arxiv.org/abs/2508.01491)|null|\n", "2508.01450": "|**2025-08-02**|**Towards Efficient Medical Reasoning with Minimal Fine-Tuning Data**|Xinlin Zhuang et.al.|[2508.01450](http://arxiv.org/abs/2508.01450)|null|\n", "2508.01432": "|**2025-08-02**|**TripTailor: A Real-World Benchmark for Personalized Travel Planning**|Yuanzhe Shen et.al.|[2508.01432_(ACL)](http://arxiv.org/abs/2508.01432)|null|\n", "2508.01424": "|**2025-08-02**|**From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs**|Haonan Bian et.al.|[2508.01424](http://arxiv.org/abs/2508.01424)|null|\n", "2508.01309": "|**2025-08-02**|**D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation**|Weibo Zhou et.al.|[2508.01309](http://arxiv.org/abs/2508.01309)|null|\n", "2508.01306": "|**2025-08-02**|**PUZZLED: Jailbreaking LLMs through Word-Based Puzzles**|Yelim Ahn et.al.|[2508.01306](http://arxiv.org/abs/2508.01306)|null|\n", "2508.01300": "|**2025-08-02**|**How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective**|Ma'ayan Armony et.al.|[2508.01300](http://arxiv.org/abs/2508.01300)|null|\n", "2508.01290": "|**2025-08-02**|**Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities**|Zhichao Yan et.al.|[2508.01290](http://arxiv.org/abs/2508.01290)|null|\n", "2508.01273": "|**2025-08-05**|**KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs**|Xianda Zheng et.al.|[2508.01273](http://arxiv.org/abs/2508.01273)|null|\n", "2508.01263": "|**2025-08-02**|**Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025**|Long S. T. Nguyen et.al.|[2508.01263](http://arxiv.org/abs/2508.01263)|**[link](https://sites.google.com/view/trns-ai/challenge/)**|\n", "2508.01255": "|**2025-08-02**|**TestWeaver: Execution-aware, Feedback-driven Regression Testing Generation with Large Language Models**|Cuong Chi Le et.al.|[2508.01255](http://arxiv.org/abs/2508.01255)|null|\n", "2508.01249": "|**2025-08-02**|**AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection**|Peiran Wang et.al.|[2508.01249](http://arxiv.org/abs/2508.01249)|null|\n", "2508.01191": "|**2025-08-05**|**Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens**|Chengshuai Zhao et.al.|[2508.01191](http://arxiv.org/abs/2508.01191)|null|\n", "2508.01186": "|**2025-08-02**|**A Survey on Agent Workflow -- Status and Future**|Chaojia Yu et.al.|[2508.01186](http://arxiv.org/abs/2508.01186)|**[link](https://ieeexplore.ieee.org/document/11082076)**|\n", "2508.01166": "|**2025-08-02**|**Hearing More with Less: Multi-Modal Retrieval-and-Selection Augmented Conversational LLM-Based ASR**|Bingshen Mu et.al.|[2508.01166](http://arxiv.org/abs/2508.01166)|null|\n", "2508.02736": "|**2025-08-02**|**AgentSight: System-Level Observability for AI Agents Using eBPF**|Yusheng Zheng et.al.|[2508.02736](http://arxiv.org/abs/2508.02736)|null|\n", "2508.01136": "|**2025-08-02**|**DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs**|Wei Zhou et.al.|[2508.01136_(ALT)](http://arxiv.org/abs/2508.01136)|**[link](https://github.com/weAIDB/DBAIOps/)**|\n", "2508.01119": "|**2025-08-05**|**The Promise of RL for Autoregressive Image Editing**|Saba Ahmadi et.al.|[2508.01119](http://arxiv.org/abs/2508.01119)|null|\n", "2508.02733": "|**2025-08-01**|**What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus**|Rijul Jain et.al.|[2508.02733](http://arxiv.org/abs/2508.02733)|null|\n", "2508.01055": "|**2025-08-05**|**FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models**|Xuan Liu et.al.|[2508.01055](http://arxiv.org/abs/2508.01055)|null|\n", "2508.00788": "|**2025-08-01**|**Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models**|Xushuo Tang et.al.|[2508.00788](http://arxiv.org/abs/2508.00788)|null|\n", "2501.16607": "|**2025-08-03**|**MCTS-SQL: Light-Weight LLMs can Master the Text-to-SQL through Monte Carlo Tree Search**|Shuozhi Yuan et.al.|[2501.16607](http://arxiv.org/abs/2501.16607)|null|\n", "2412.04449": "|**2025-08-06**|**p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay**|Jun Zhang et.al.|[2412.04449_(ICC)](http://arxiv.org/abs/2412.04449)|**[link](https://github.com/MCG-NJU/p-MoD)**|\n", "2508.06447": "|**2025-08-08**|**SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning**|Lingkun Long et.al.|[2508.06447](http://arxiv.org/abs/2508.06447)|null|\n", "2508.06297": "|**2025-08-08**|**KV Cache Compression for Inference Efficiency in LLMs: A Review**|Yanyu Liu et.al.|[2508.06297](http://arxiv.org/abs/2508.06297)|null|\n", "2508.06133": "|**2025-08-08**|**LLM Serving Optimization with Variable Prefill and Decode Lengths**|Meixuan Wang et.al.|[2508.06133](http://arxiv.org/abs/2508.06133)|null|\n", "2503.18773": "|**2025-03-24**|**BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache**|Dayou Du et.al.|[2503.18773](http://arxiv.org/abs/2503.18773)|null|\n", "2503.17603": "|**2025-03-22**|**A Generative Caching System for Large Language Models**|Arun Iyengar et.al.|[2503.17603](http://arxiv.org/abs/2503.17603)|null|\n", "2503.16870": "|**2025-07-24**|**Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs**|Anshumann et.al.|[2503.16870_(ACL)](http://arxiv.org/abs/2503.16870)|**[link](https://github.com/akhilkedia/RandomSamplingKD)**|\n", "2503.14647": "|**2025-03-18**|**Towards More Economical Context-Augmented LLM Generation by Reusing Stored KV Cache**|Hanchen Li et.al.|[2503.14647](http://arxiv.org/abs/2503.14647)|null|\n", "2503.12988": "|**2025-03-17**|**ROMA: a Read-Only-Memory-based Accelerator for QLoRA-based On-Device LLM**|Wenqiang Wang et.al.|[2503.12988](http://arxiv.org/abs/2503.12988)|null|\n", "2503.11426": "|**2025-03-14**|**Text Compression for Efficient Language Generation**|David Gu et.al.|[2503.11426_(ACL)](http://arxiv.org/abs/2503.11426)|null|\n", "2503.10494": "|**2025-03-13**|**Source-primed Multi-turn Conversation Helps Large Language Models Translate Documents**|Hanxu Hu et.al.|[2503.10494](http://arxiv.org/abs/2503.10494)|null|\n", "2503.10337": "|**2025-03-13**|**KV-Distill: Nearly Lossless Learnable Context Compression for LLMs**|Vivek Chari et.al.|[2503.10337](http://arxiv.org/abs/2503.10337)|null|\n", "2503.07518": "|**2025-03-10**|**TokenButler: Token Importance is Predictable**|Yash Akhauri et.al.|[2503.07518](http://arxiv.org/abs/2503.07518)|null|\n", "2503.02812": "|**2025-03-04**|**Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression**|Nathan Godey et.al.|[2503.02812](http://arxiv.org/abs/2503.02812)|null|\n", "2503.01483": "|**2025-03-03**|**KurTail : Kurtosis-based LLM Quantization**|Mohammad Sadegh Akhondzadeh et.al.|[2503.01483](http://arxiv.org/abs/2503.01483)|null|\n", "2503.00540": "|**2025-03-01**|**Streaming Video Question-Answering with In-context Video KV-Cache Retrieval**|Shangzhe Di et.al.|[2503.00540_(ICLR)](http://arxiv.org/abs/2503.00540)|**[link](https://github.com/Becomebright/ReKV)**|\n", "2502.20812": "|**2025-02-28**|**Towards Reliable Vector Database Management Systems: A Software Testing Roadmap for 2030**|Shenao Wang et.al.|[2502.20812](http://arxiv.org/abs/2502.20812)|null|\n", "2502.18755": "|**2025-02-26**|**M-ANT: Efficient Low-bit Group Quantization for LLMs via Mathematically Adaptive Numerical Type**|Weiming Hu et.al.|[2502.18755](http://arxiv.org/abs/2502.18755)|null|\n", "2502.15075": "|**2025-05-23**|**Quantize What Counts: Bit Allocation Insights Informed by Spectral Gaps in Keys and Values**|Mohsen Hariri et.al.|[2502.15075](http://arxiv.org/abs/2502.15075)|null|\n", "2502.14317": "|**2025-06-09**|**ParallelComp: Parallel Long-Context Compressor for Length Extrapolation**|Jing Xiong et.al.|[2502.14317_(ICML)](http://arxiv.org/abs/2502.14317)|null|\n", "2502.14280": "|**2025-02-20**|**EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts**|Subhajit Chaudhury et.al.|[2502.14280](http://arxiv.org/abs/2502.14280)|null|\n", "2502.13145": "|**2025-03-18**|**Multimodal Mamba: Decoder-only Multimodal State Space Model via Quadratic to Linear Distillation**|Bencheng Liao et.al.|[2502.13145](http://arxiv.org/abs/2502.13145)|**[link](https://github.com/hustvl/mmMamba)**|\n", "2502.15779": "|**2025-02-17**|**Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer**|Euntae Choi et.al.|[2502.15779](http://arxiv.org/abs/2502.15779)|null|\n", "2502.09720": "|**2025-07-26**|**NestQuant: Nested Lattice Quantization for Matrix Products and LLMs**|Semyon Savkin et.al.|[2502.09720_(CHI)](http://arxiv.org/abs/2502.09720)|null|\n", "2502.09003": "|**2025-06-06**|**RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models**|Quan Wei et.al.|[2502.09003_(ICML)](http://arxiv.org/abs/2502.09003)|null|\n", "2502.08363": "|**2025-02-12**|**Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding**|Konstantin Berestizshevsky et.al.|[2502.08363_(ISS)](http://arxiv.org/abs/2502.08363)|null|\n", "2502.07776": "|**2025-07-13**|**Auditing Prompt Caching in Language Model APIs**|Chenchen Gu et.al.|[2502.07776_(ICML)](http://arxiv.org/abs/2502.07776)|null|\n", "2502.02770": "|**2025-02-06**|**Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning**|Chaofan Lin et.al.|[2502.02770](http://arxiv.org/abs/2502.02770)|null|\n", "2502.02617": "|**2025-02-04**|**PolarQuant: Quantizing KV Caches with Polar Transformation**|Insu Han et.al.|[2502.02617](http://arxiv.org/abs/2502.02617)|null|\n", "2501.19300": "|**2025-05-29**|**Offline Learning for Combinatorial Multi-armed Bandits**|Xutong Liu et.al.|[2501.19300](http://arxiv.org/abs/2501.19300)|null|\n", "2501.18824": "|**2025-01-31**|**Memory-Efficient Fine-Tuning of Transformers via Token Selection**|Antoine Simoulin et.al.|[2501.18824_(EMNLP)](http://arxiv.org/abs/2501.18824)|null|\n", "2501.15021": "|**2025-01-25**|**AKVQ-VL: Attention-Aware KV Cache Adaptive 2-Bit Quantization for Vision-Language Models**|Zunhai Su et.al.|[2501.15021](http://arxiv.org/abs/2501.15021)|null|\n", "2501.09383": "|**2025-01-16**|**Adaptive Contextual Caching for Mobile Edge Large Language Model Service**|Guangyuan Liu et.al.|[2501.09383](http://arxiv.org/abs/2501.09383)|null|\n", "2501.07523": "|**2025-01-23**|**Parallel Key-Value Cache Fusion for Position Invariant RAG**|Philhoon Oh et.al.|[2501.07523](http://arxiv.org/abs/2501.07523)|null|\n", "2501.06807": "|**2025-01-12**|**MPCache: MPC-Friendly KV Cache Eviction for Efficient Private Large Language Model Inference**|Wenxuan Zeng et.al.|[2501.06807](http://arxiv.org/abs/2501.06807)|null|\n", "2501.04987": "|**2025-05-16**|**TreeKV: Smooth Key-Value Cache Compression with Tree Structures**|Ziwei He et.al.|[2501.04987](http://arxiv.org/abs/2501.04987)|null|\n", "2501.03940": "|**2025-07-14**|**Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection**|Pablo Miralles-Gonz\u00e1lez et.al.|[2501.03940](http://arxiv.org/abs/2501.03940)|null|\n", "2501.01792": "|**2025-01-03**|**Efficient LLM Inference with Activation Checkpointing and Hybrid Caching**|Sanghyeon Lee et.al.|[2501.01792](http://arxiv.org/abs/2501.01792)|null|\n", "2412.20677": "|**2025-07-26**|**Align Attention Heads Before Merging Them: An Effective Way for Converting MHA to GQA**|Qingyun Jin et.al.|[2412.20677](http://arxiv.org/abs/2412.20677)|null|\n", "2412.20504": "|**2025-03-24**|**ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video Understanding**|Xiao Wang et.al.|[2412.20504_(DATE)](http://arxiv.org/abs/2412.20504)|null|\n", "2412.20166": "|**2025-01-15**|**LoL-PIM: Long-Context LLM Decoding with Scalable DRAM-PIM System**|Hyucksung Kwon et.al.|[2412.20166](http://arxiv.org/abs/2412.20166)|null|\n", "2412.15605": "|**2025-02-23**|**Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks**|Brian J Chan et.al.|[2412.15605_(WWW)](http://arxiv.org/abs/2412.15605)|null|\n", "2412.14838": "|**2025-05-27**|**DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**|Xiabin Zhou et.al.|[2412.14838](http://arxiv.org/abs/2412.14838)|null|\n", "2412.14363": "|**2025-02-03**|**ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals**|Utkarsh Saxena et.al.|[2412.14363](http://arxiv.org/abs/2412.14363)|null|\n", "2412.12706": "|**2025-02-20**|**More Tokens, Lower Precision: Towards the Optimal Token-Precision Trade-off in KV Cache Compression**|Jiebin Zhang et.al.|[2412.12706](http://arxiv.org/abs/2412.12706)|null|\n", "2412.12486": "|**2025-05-23**|**Boosting Long-Context Management via Query-Guided Activation Refilling**|Hongjin Qian et.al.|[2412.12486_(ACL)](http://arxiv.org/abs/2412.12486)|null|\n", "2412.12094": "|**2025-06-02**|**SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator**|Guoxuan Chen et.al.|[2412.12094_(ICML)](http://arxiv.org/abs/2412.12094)|null|\n", "2412.11685": "|**2024-12-16**|**Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite Pixel Learning**|Xingchi Chen et.al.|[2412.11685](http://arxiv.org/abs/2412.11685)|null|\n", "2412.14201": "|**2025-02-03**|**The \"Huh?\" Button: Improving Understanding in Educational Videos with Large Language Models**|Boris Ruf et.al.|[2412.14201](http://arxiv.org/abs/2412.14201)|null|\n", "2412.15246": "|**2024-12-14**|**Accelerating Retrieval-Augmented Generation**|Derrick Quinn et.al.|[2412.15246](http://arxiv.org/abs/2412.15246)|null|\n", "2412.10319": "|**2025-03-11**|**SCBench: A KV Cache-Centric Analysis of Long-Context Methods**|Yucheng Li et.al.|[2412.10319_(ICLR)](http://arxiv.org/abs/2412.10319)|null|\n", "2412.12178": "|**2025-01-31**|**Activation Sparsity Opportunities for Compressing General Large Language Models**|Nobel Dhar et.al.|[2412.12178_(CCC)](http://arxiv.org/abs/2412.12178)|null|\n", "2412.09036": "|**2024-12-12**|**ZigZagkv: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty**|Meizhi Zhong et.al.|[2412.09036](http://arxiv.org/abs/2412.09036)|null|\n", "2412.08890": "|**2024-12-12**|**Lexico: Extreme KV Cache Compression via Sparse Coding over Universal Dictionaries**|Junhyuck Kim et.al.|[2412.08890](http://arxiv.org/abs/2412.08890)|null|\n", "2412.08585": "|**2024-12-17**|**TurboAttention: Efficient Attention Approximation For High Throughputs LLMs**|Hao Kang et.al.|[2412.08585](http://arxiv.org/abs/2412.08585)|null|\n", "2412.08521": "|**2025-02-27**|**EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance**|Yingxin Li et.al.|[2412.08521](http://arxiv.org/abs/2412.08521)|null|\n", "2412.08176": "|**2024-12-11**|**TextRefiner: Internal Visual Feature as Efficient Refiner for Vision-Language Models Prompt Tuning**|Jingjing Xie et.al.|[2412.08176_(AAAI)](http://arxiv.org/abs/2412.08176)|null|\n", "2412.08063": "|**2024-12-11**|**ContextModule: Improving Code Completion via Repository-level Contextual Information**|Zhanming Guan et.al.|[2412.08063](http://arxiv.org/abs/2412.08063)|null|\n", "2412.05896": "|**2024-12-08**|**XKV: Personalized KV Cache Memory Reduction for Long-Context LLM Inference**|Weizhuo Li et.al.|[2412.05896](http://arxiv.org/abs/2412.05896)|null|\n", "2412.05693": "|**2025-07-03**|**Batch-Max: Higher LLM Throughput using Larger Batch Sizes and KV Cache Compression**|Michael R. Metel et.al.|[2412.05693](http://arxiv.org/abs/2412.05693)|null|\n", "2412.04652": "|**2024-12-05**|**Cross-Self KV Cache Pruning for Efficient Vision-Language Inference**|Xiaohuan Pei et.al.|[2412.04652](http://arxiv.org/abs/2412.04652)|null|\n", "2412.02252": "|**2025-08-04**|**Compressing KV Cache for Long-Context LLM Inference with Inter-Layer Attention Similarity**|Da Ma et.al.|[2412.02252](http://arxiv.org/abs/2412.02252)|null|\n", "2412.01380": "|**2025-04-03**|**Efficient LLM Inference using Dynamic Input Pruning and Cache-Aware Masking**|Marco Federici et.al.|[2412.01380](http://arxiv.org/abs/2412.01380)|null|\n", "2412.00099": "|**2025-06-24**|**Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference**|Andrii Skliar et.al.|[2412.00099_(CHI)](http://arxiv.org/abs/2412.00099)|null|\n", "2411.18191": "|**2024-11-29**|**InputSnatch: Stealing Input in LLM Services via Timing Side-Channel Attacks**|Xinyao Zheng et.al.|[2411.18191](http://arxiv.org/abs/2411.18191)|null|\n", "2411.17116": "|**2025-05-30**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116_(ICML)](http://arxiv.org/abs/2411.17116)|null|\n", "2411.15102": "|**2025-03-21**|**AttriBoT: A Bag of Tricks for Efficiently Approximating Leave-One-Out Context Attribution**|Fengyuan Liu et.al.|[2411.15102_(ICLR)](http://arxiv.org/abs/2411.15102)|null|\n", "2411.11843": "|**2024-11-18**|**Bi-Mamba: Towards Accurate 1-Bit State Space Models**|Shengkun Tang et.al.|[2411.11843](http://arxiv.org/abs/2411.11843)|null|\n", "2411.09317": "|**2024-11-14**|**Pie: Pooling CPU Memory for LLM Inference**|Yi Xu et.al.|[2411.09317](http://arxiv.org/abs/2411.09317)|null|\n", "2411.06681": "|**2024-11-11**|**WDMoE: Wireless Distributed Mixture of Experts for Large Language Models**|Nan Xue et.al.|[2411.06681](http://arxiv.org/abs/2411.06681)|null|\n", "2411.06680": "|**2024-11-11**|**Anchor Attention, Small Cache: Code Generation with Large Language Models**|Xiangyu Zhang et.al.|[2411.06680](http://arxiv.org/abs/2411.06680)|null|\n", "2411.05787": "|**2025-03-03**|**RefreshKV: Updating Small KV Cache During Long-form Generation**|Fangyuan Xu et.al.|[2411.05787](http://arxiv.org/abs/2411.05787)|null|\n", "2411.05555": "|**2024-11-08**|**AcceLLM: Accelerating LLM Inference using Redundancy for Load Balancing and Data Locality**|Ilias Bournias et.al.|[2411.05555](http://arxiv.org/abs/2411.05555)|null|\n", "2411.05276": "|**2024-12-09**|**GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic Embedding Caching**|Sajal Regmi et.al.|[2411.05276](http://arxiv.org/abs/2411.05276)|null|\n", "2411.04965": "|**2024-11-07**|**BitNet a4.8: 4-bit Activations for 1-bit LLMs**|Hongyu Wang et.al.|[2411.04965](http://arxiv.org/abs/2411.04965)|null|\n", "2411.02886": "|**2025-03-03**|**TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection**|Wei Wu et.al.|[2411.02886](http://arxiv.org/abs/2411.02886)|null|\n", "2411.01433": "|**2024-11-06**|**HOBBIT: A Mixed Precision Expert Offloading System for Fast MoE Inference**|Peng Tang et.al.|[2411.01433](http://arxiv.org/abs/2411.01433)|null|\n", "2410.23079": "|**2024-10-30**|**BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference**|Junqi Zhao et.al.|[2410.23079](http://arxiv.org/abs/2410.23079)|null|\n", "2410.23317": "|**2024-10-29**|**VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration**|Dezhan Tu et.al.|[2410.23317](http://arxiv.org/abs/2410.23317)|null|\n", "2410.22118": "|**2025-06-05**|**The Impact of Inference Acceleration on Bias of LLMs**|Elisabeth Kirsten et.al.|[2410.22118](http://arxiv.org/abs/2410.22118)|null|\n", "2410.21035": "|**2025-02-06**|**Beyond Autoregression: Fast LLMs via Self-Distillation Through Time**|Justin Deschenaux et.al.|[2410.21035](http://arxiv.org/abs/2410.21035)|null|\n", "2410.19937": "|**2024-10-25**|**RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction**|Tanqiu Jiang et.al.|[2410.19937](http://arxiv.org/abs/2410.19937)|null|\n", "2410.19274": "|**2024-10-29**|**Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management**|Tuowei Wang et.al.|[2410.19274](http://arxiv.org/abs/2410.19274)|null|\n", "2410.18517": "|**2024-10-24**|**KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing**|Yifei Yang et.al.|[2410.18517_(ICLR)](http://arxiv.org/abs/2410.18517)|null|\n", "2410.15704": "|**2024-10-21**|**Residual vector quantization for KV cache compression in large language model**|Ankur Kumar et.al.|[2410.15704](http://arxiv.org/abs/2410.15704)|null|\n", "2410.14442": "|**2025-02-05**|**A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference**|You Wu et.al.|[2410.14442_(ACL)](http://arxiv.org/abs/2410.14442)|null|\n", "2410.13212": "|**2024-10-17**|**AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations**|Qian Tao et.al.|[2410.13212](http://arxiv.org/abs/2410.13212)|null|\n", "2410.12513": "|**2025-07-09**|**FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction**|Akriti Jain et.al.|[2410.12513](http://arxiv.org/abs/2410.12513)|null|\n", "2410.14731": "|**2025-05-16**|**MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection**|Bokai Lin et.al.|[2410.14731](http://arxiv.org/abs/2410.14731)|null|\n", "2410.11417": "|**2024-10-15**|**VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models**|Xiaohan Lan et.al.|[2410.11417](http://arxiv.org/abs/2410.11417)|null|\n", "2410.12876": "|**2025-04-17**|**In-context KV-Cache Eviction for LLMs via Attention-Gate**|Zihao Zeng et.al.|[2410.12876](http://arxiv.org/abs/2410.12876)|null|\n", "2410.10819": "|**2024-10-14**|**DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads**|Guangxuan Xiao et.al.|[2410.10819](http://arxiv.org/abs/2410.10819)|null|\n", "2410.09397": "|**2024-10-12**|**Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes**|Xiaoyu Li et.al.|[2410.09397](http://arxiv.org/abs/2410.09397)|null|\n", "2410.12850": "|**2024-10-10**|**RecurFormer: Not All Transformer Heads Need Self-Attention**|Ruiqing Yan et.al.|[2410.12850](http://arxiv.org/abs/2410.12850)|null|\n", "2410.07295": "|**2025-03-02**|**IterGen: Iterative Semantic-aware Structured LLM Generation with Backtracking**|Shubham Ugare et.al.|[2410.07295_(ICLR)](http://arxiv.org/abs/2410.07295)|null|\n", "2410.05076": "|**2024-10-07**|**TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention**|Lijie Yang et.al.|[2410.05076](http://arxiv.org/abs/2410.05076)|null|\n", "2410.10859": "|**2024-10-18**|**FAME: Towards Factual Multi-Task Model Editing**|Li Zeng et.al.|[2410.10859_(EMNLP)](http://arxiv.org/abs/2410.10859)|null|\n", "2410.03090": "|**2024-10-04**|**UNComp: Uncertainty-Aware Long-Context Compressor for Efficient Large Language Model Inference**|Jing Xiong et.al.|[2410.03090](http://arxiv.org/abs/2410.03090)|null|\n", "2410.01805": "|**2025-01-30**|**Locret: Enhancing Eviction in Long-Context LLM Inference with Trained Retaining Heads on Consumer-Grade Devices**|Yuxiang Huang et.al.|[2410.01805](http://arxiv.org/abs/2410.01805)|null|\n", "2410.01518": "|**2024-10-02**|**InfiniPot: Infinite Context Processing on Memory-Constrained LLMs**|Minsoo Kim et.al.|[2410.01518_(EMNLP)](http://arxiv.org/abs/2410.01518)|null|\n", "2409.16546": "|**2024-10-21**|**AlignedKV: Reducing Memory Access of KV-Cache with Precision-Aligned Quantization**|Yifan Tan et.al.|[2409.16546](http://arxiv.org/abs/2409.16546)|null|\n", "2409.12490": "|**2024-09-23**|**CritiPrefill: A Segment-wise Criticality-based Approach for Prefilling Acceleration in LLMs**|Junlin Lv et.al.|[2409.12490](http://arxiv.org/abs/2409.12490)|null|\n", "2409.10593": "|**2024-10-18**|**CSKV: Training-Efficient Channel Shrinking for KV Cache in Long-Context Scenarios**|Luning Wang et.al.|[2409.10593_(NeurIPS)](http://arxiv.org/abs/2409.10593)|null|\n", "2409.09398": "|**2025-03-21**|**Language-Queried Target Sound Extraction Without Parallel Training Data**|Hao Ma et.al.|[2409.09398_(ICASSP)](http://arxiv.org/abs/2409.09398)|null|\n", "2409.04992": "|**2024-09-08**|**InstInfer: In-Storage Attention Offloading for Cost-Effective Long-Context LLM Inference**|Xiurui Pan et.al.|[2409.04992](http://arxiv.org/abs/2409.04992)|null|\n", "2408.16967": "|**2024-08-30**|**MemLong: Memory-Augmented Retrieval for Long Text Modeling**|Weijie Liu et.al.|[2408.16967](http://arxiv.org/abs/2408.16967)|null|\n", "2408.16730": "|**2024-08-29**|**VideoLLM-MoD: Efficient Video-Language Streaming with Mixture-of-Depths Vision Computation**|Shiwei Wu et.al.|[2408.16730](http://arxiv.org/abs/2408.16730)|null|\n", "2408.15766": "|**2025-02-26**|**Learning Harmonized Representations for Speculative Sampling**|Lefan Zhang et.al.|[2408.15766_(ICLR)](http://arxiv.org/abs/2408.15766)|null|\n", "2408.10746": "|**2024-08-20**|**Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-Tuning**|Bei Ouyang et.al.|[2408.10746_(ICPP)](http://arxiv.org/abs/2408.10746)|null|\n", "2408.10284": "|**2024-08-19**|**AdapMoE: Adaptive Sensitivity-based Expert Gating and Management for Efficient MoE Inference**|Shuzhang Zhong et.al.|[2408.10284](http://arxiv.org/abs/2408.10284)|null|\n", "2408.04870": "|**2024-10-23**|**ConfusedPilot: Confused Deputy Risks in RAG-based LLMs**|Ayush RoyChowdhury et.al.|[2408.04870](http://arxiv.org/abs/2408.04870)|null|\n", "2408.04107": "|**2025-06-08**|**FDC: Fast KV Dimensionality Compression for Efficient LLM Inference**|Zeyu Zhang et.al.|[2408.04107](http://arxiv.org/abs/2408.04107)|null|\n", "2408.03675": "|**2024-08-08**|**NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time**|Yilong Chen et.al.|[2408.03675_(ACL)](http://arxiv.org/abs/2408.03675)|null|\n", "2408.02999": "|**2024-08-06**|**LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning**|Lekai Chen et.al.|[2408.02999](http://arxiv.org/abs/2408.02999)|null|\n", "2408.01890": "|**2024-08-04**|**Cross-layer Attention Sharing for Large Language Models**|Yongyu Mu et.al.|[2408.01890](http://arxiv.org/abs/2408.01890)|null|\n", "2407.21118": "|**2024-11-04**|**Palu: Compressing KV-Cache with Low-Rank Projection**|Chi-Chih Chang et.al.|[2407.21118](http://arxiv.org/abs/2407.21118)|null|\n", "2407.20485": "|**2024-07-31**|**A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder**|Hyun-rae Jo et.al.|[2407.20485](http://arxiv.org/abs/2407.20485)|null|\n", "2407.18121": "|**2024-07-25**|**Efficient Inference of Vision Instruction-Following Models with Elastic Cache**|Zuyan Liu et.al.|[2407.18121_(ECCV)](http://arxiv.org/abs/2407.18121)|null|\n", "2407.18003": "|**2024-11-20**|**Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**|Luohe Shi et.al.|[2407.18003](http://arxiv.org/abs/2407.18003)|null|\n", "2407.20272": "|**2024-07-25**|**An Efficient Inference Framework for Early-exit Large Language Models**|Ruijie Miao et.al.|[2407.20272](http://arxiv.org/abs/2407.20272)|null|\n", "2407.16286": "|**2024-07-23**|**A deeper look at depth pruning of LLMs**|Shoaib Ahmed Siddiqui et.al.|[2407.16286](http://arxiv.org/abs/2407.16286)|null|\n", "2407.15891": "|**2024-07-22**|**RazorAttention: Efficient KV Cache Compression Through Retrieval Heads**|Hanlin Tang et.al.|[2407.15891](http://arxiv.org/abs/2407.15891)|null|\n", "2407.14057": "|**2024-07-19**|**LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference**|Qichen Fu et.al.|[2407.14057](http://arxiv.org/abs/2407.14057)|null|\n", "2407.11550": "|**2025-01-26**|**Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference**|Yuan Feng et.al.|[2407.11550](http://arxiv.org/abs/2407.11550)|null|\n", "2407.12866": "|**2024-07-13**|**Beyond KV Caching: Shared Attention for Efficient LLMs**|Bingli Liao et.al.|[2407.12866](http://arxiv.org/abs/2407.12866)|null|\n", "2407.07304": "|**2024-07-10**|**Inference Performance Optimization for Large Language Models on CPUs**|Pujiang He et.al.|[2407.07304_(ICML)](http://arxiv.org/abs/2407.07304)|null|\n", "2407.18921": "|**2025-03-20**|**Mobile Edge Intelligence for Large Language Models: A Contemporary Survey**|Guanqiao Qu et.al.|[2407.18921](http://arxiv.org/abs/2407.18921)|null|\n", "2407.05690": "|**2024-07-08**|**Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations**|Bowen Shen et.al.|[2407.05690_(ACL)](http://arxiv.org/abs/2407.05690)|null|\n", "2407.03637": "|**2024-09-06**|**QET: Enhancing Quantized LLM Parameters and KV cache Compression through Element Substitution and Residual Clustering**|Yanshu Wang et.al.|[2407.03637](http://arxiv.org/abs/2407.03637)|null|\n", "2407.03157": "|**2025-03-04**|**Let the Code LLM Edit Itself When You Edit the Code**|Zhenyu He et.al.|[2407.03157_(ICLR)](http://arxiv.org/abs/2407.03157)|null|\n", "2407.02486": "|**2024-07-02**|**Neurocache: Efficient Vector Retrieval for Long-range Language Modeling**|Ali Safaya et.al.|[2407.02486_(ACL)](http://arxiv.org/abs/2407.02486)|null|\n", "2407.02328": "|**2024-07-02**|**Efficient Sparse Attention needs Adaptive Token Release**|Chaoran Zhang et.al.|[2407.02328_(ACL)](http://arxiv.org/abs/2407.02328)|null|\n", "2406.18139": "|**2024-06-26**|**LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference**|Zhongwei Wan et.al.|[2406.18139](http://arxiv.org/abs/2406.18139)|null|\n", "2406.18133": "|**2024-06-26**|**ConvoCache: Smart Re-Use of Chatbot Responses**|Conor Atkins et.al.|[2406.18133](http://arxiv.org/abs/2406.18133)|null|\n", "2406.17808": "|**2025-03-31**|**Training-Free Exponential Context Extension via Cascading KV Cache**|Jeffrey Willette et.al.|[2406.17808](http://arxiv.org/abs/2406.17808)|null|\n", "2406.13035": "|**2025-03-13**|**D2O: Dynamic Discriminative Operations for Efficient Long-Context Inference of Large Language Models**|Zhongwei Wan et.al.|[2406.13035_(ICLR)](http://arxiv.org/abs/2406.13035)|null|\n", "2406.12335": "|**2024-10-02**|**Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters**|Zhiyu Guo et.al.|[2406.12335_(EMNLP)](http://arxiv.org/abs/2406.12335)|null|\n", "2406.12018": "|**2024-10-08**|**CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling**|Yu Bai et.al.|[2406.12018_(EMNLP)](http://arxiv.org/abs/2406.12018)|null|\n", "2406.10981": "|**2024-06-16**|**ViD-GPT: Introducing GPT-style Autoregressive Generation in Video Diffusion Models**|Kaifeng Gao et.al.|[2406.10981](http://arxiv.org/abs/2406.10981)|**[link](https://github.com/Dawn-LX/Causal-VideoGen)**|\n", "2406.10774": "|**2024-08-26**|**Quest: Query-Aware Sparsity for Efficient Long-Context LLM Inference**|Jiaming Tang et.al.|[2406.10774_(ICML)](http://arxiv.org/abs/2406.10774)|null|\n", "2406.07467": "|**2025-08-08**|**LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs**|Fatemeh Hadadi et.al.|[2406.07467](http://arxiv.org/abs/2406.07467)|null|\n", "2406.07056": "|**2024-06-11**|**Effectively Compress KV Heads for LLM**|Hao Yu et.al.|[2406.07056](http://arxiv.org/abs/2406.07056)|null|\n", "2406.05317": "|**2024-10-25**|**LoCoCo: Dropping In Convolutions for Long Context Compression**|Ruisi Cai et.al.|[2406.05317](http://arxiv.org/abs/2406.05317)|null|\n", "2406.02542": "|**2024-11-07**|**Loki: Low-rank Keys for Efficient Sparse Attention**|Prajwal Singhania et.al.|[2406.02542](http://arxiv.org/abs/2406.02542)|null|\n", "2406.02532": "|**2024-11-30**|**SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices**|Ruslan Svirschevski et.al.|[2406.02532](http://arxiv.org/abs/2406.02532)|null|\n", "2406.06567": "|**2024-12-07**|**DHA: Learning Decoupled-Head Attention from Transformer Checkpoints via Adaptive Heads Fusion**|Yilong Chen et.al.|[2406.06567_(NeurIPS)](http://arxiv.org/abs/2406.06567)|null|\n", "2405.16178": "|**2024-05-25**|**Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection**|Yun Zhu et.al.|[2405.16178](http://arxiv.org/abs/2405.16178)|null|\n", "2405.14366": "|**2024-09-07**|**MiniCache: KV Cache Compression in Depth Dimension for Large Language Models**|Akide Liu et.al.|[2405.14366](http://arxiv.org/abs/2405.14366)|**[link](https://minicache.vmv.re)**|\n", "2405.12981": "|**2024-05-21**|**Reducing Transformer Key-Value Cache Size with Cross-Layer Attention**|William Brandon et.al.|[2405.12981](http://arxiv.org/abs/2405.12981)|null|\n", "2405.12591": "|**2024-05-21**|**Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression**|Peiyu Liu et.al.|[2405.12591](http://arxiv.org/abs/2405.12591)|null|\n", "2405.12532": "|**2024-06-05**|**PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference**|Dongjie Yang et.al.|[2405.12532_(ACL)](http://arxiv.org/abs/2405.12532)|null|\n", "2405.05329": "|**2024-05-13**|**KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation**|Minsik Cho et.al.|[2405.05329_(ICML)](http://arxiv.org/abs/2405.05329)|null|\n", "2405.04065": "|**2025-06-13**|**FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference**|Runheng Liu et.al.|[2405.04065_(ACL)](http://arxiv.org/abs/2405.04065)|null|\n", "2405.03917": "|**2024-05-07**|**KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization**|Tianyi Zhang et.al.|[2405.03917](http://arxiv.org/abs/2405.03917)|null|\n", "2404.18057": "|**2024-04-28**|**Efficient LLM Inference with Kcache**|Qiaozhi He et.al.|[2404.18057](http://arxiv.org/abs/2404.18057)|null|\n", "2404.15949": "|**2024-06-21**|**CORM: Cache Optimization with Recent Message for Large Language Model Inference**|Jincheng Dai et.al.|[2404.15949](http://arxiv.org/abs/2404.15949)|null|\n", "2404.15420": "|**2024-11-01**|**XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference**|Jo\u00e3o Monteiro et.al.|[2404.15420](http://arxiv.org/abs/2404.15420)|null|\n", "2404.12457": "|**2024-04-25**|**RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**|Chao Jin et.al.|[2404.12457](http://arxiv.org/abs/2404.12457)|null|\n", "2404.07979": "|**2024-10-17**|**LLoCO: Learning Long Contexts Offline**|Sijun Tan et.al.|[2404.07979_(EMNLP)](http://arxiv.org/abs/2404.07979)|null|\n", "2404.06954": "|**2024-04-10**|**Accelerating Inference in Large Language Models with a Unified Layer Skipping Strategy**|Yijin Liu et.al.|[2404.06954](http://arxiv.org/abs/2404.06954)|**[link](https://github.com/Adaxry/Unified_Layer_Skipping)**|\n", "2404.06003": "|**2024-04-09**|**FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models**|Zhuohao Yu et.al.|[2404.06003](http://arxiv.org/abs/2404.06003)|**[link](https://github.com/WisdomShell/FreeEval)**|\n", "2404.04793": "|**2024-10-10**|**SqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget**|Zihao Wang et.al.|[2404.04793](http://arxiv.org/abs/2404.04793)|null|\n", "2404.02690": "|**2025-02-12**|**How Sparse Attention Approximates Exact Attention? Your Attention is Naturally $n^C$-Sparse**|Yichuan Deng et.al.|[2404.02690](http://arxiv.org/abs/2404.02690)|null|\n", "2404.00456": "|**2024-10-29**|**QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs**|Saleh Ashkboos et.al.|[2404.00456](http://arxiv.org/abs/2404.00456)|null|\n", "2403.20137": "|**2024-03-29**|**Accurate Block Quantization in LLMs with Outliers**|Nikita Trukhanov et.al.|[2403.20137](http://arxiv.org/abs/2403.20137)|null|\n", "2403.20041": "|**2024-07-05**|**Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs**|Luchang Li et.al.|[2403.20041](http://arxiv.org/abs/2403.20041)|null|\n", "2403.09054": "|**2024-04-06**|**Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient Generative Inference**|Muhammad Adnan et.al.|[2403.09054](http://arxiv.org/abs/2403.09054)|null|\n", "2403.05527": "|**2024-09-30**|**GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM**|Hao Kang et.al.|[2403.05527](http://arxiv.org/abs/2403.05527)|null|\n", "2403.02694": "|**2025-03-07**|**MeanCache: User-Centric Semantic Caching for LLM Web Services**|Waris Gill et.al.|[2403.02694_(DIS)](http://arxiv.org/abs/2403.02694)|null|\n", "2403.01241": "|**2024-05-25**|**IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact**|Ruikang Liu et.al.|[2403.01241_(ACL)](http://arxiv.org/abs/2403.01241)|null|\n", "2402.18096": "|**2024-02-28**|**No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization**|June Yong Yang et.al.|[2402.18096](http://arxiv.org/abs/2402.18096)|null|\n", "2402.12280": "|**2025-04-13**|**Plato: Plan to Efficiently Decode for Large Language Model Inference**|Shuowei Jin et.al.|[2402.12280](http://arxiv.org/abs/2402.12280)|null|\n", "2402.09398": "|**2024-06-12**|**Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference**|Harry Dong et.al.|[2402.09398](http://arxiv.org/abs/2402.09398)|null|\n", "2402.09360": "|**2024-02-14**|**HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference**|Yashas Samaga B L et.al.|[2402.09360](http://arxiv.org/abs/2402.09360)|null|\n", "2402.07616": "|**2024-06-01**|**Anchor-based Large Language Models**|Jianhui Pang et.al.|[2402.07616_(ACL)](http://arxiv.org/abs/2402.07616)|null|\n", "2402.06262": "|**2024-02-17**|**On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference**|Siyu Ren et.al.|[2402.06262](http://arxiv.org/abs/2402.06262)|null|\n", "2402.01173": "|**2024-02-02**|**Efficient Prompt Caching via Embedding Similarity**|Hanlin Zhu et.al.|[2402.01173](http://arxiv.org/abs/2402.01173)|null|\n", "2401.15569": "|**2024-07-24**|**Efficient Tuning and Inference for Large Language Models on Textual Graphs**|Yun Zhu et.al.|[2401.15569_(IJCAI)](http://arxiv.org/abs/2401.15569)|null|\n", "2401.14361": "|**2025-03-12**|**MoE-Infinity: Efficient MoE Inference on Personal Machines with Sparsity-Aware Expert Cache**|Leyang Xue et.al.|[2401.14361](http://arxiv.org/abs/2401.14361)|null|\n", "2401.10774": "|**2024-06-14**|**Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads**|Tianle Cai et.al.|[2401.10774_(FAST)](http://arxiv.org/abs/2401.10774)|**[link](https://github.com/FasterDecoding/Medusa)**|\n", "2401.09486": "|**2024-02-04**|**LoMA: Lossless Compressed Memory Attention**|Yumeng Wang et.al.|[2401.09486](http://arxiv.org/abs/2401.09486)|null|\n", "2401.03462": "|**2024-10-11**|**Long Context Compression with Activation Beacon**|Peitian Zhang et.al.|[2401.03462](http://arxiv.org/abs/2401.03462)|null|\n", "2401.05391": "|**2024-06-23**|**Efficient LLM inference solution on Intel GPU**|Hui Wu et.al.|[2401.05391](http://arxiv.org/abs/2401.05391)|null|\n", "2311.08263": "|**2024-06-04**|**Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads to Answers Faster**|Hongxuan Zhang et.al.|[2311.08263](http://arxiv.org/abs/2311.08263)|null|\n", "2311.04934": "|**2024-04-25**|**Prompt Cache: Modular Attention Reuse for Low-Latency Inference**|In Gim et.al.|[2311.04934](http://arxiv.org/abs/2311.04934)|null|\n", "2310.08152": "|**2023-10-15**|**Context Compression for Auto-regressive Transformers with Sentinel Tokens**|Siyu Ren et.al.|[2310.08152_(EMNLP)](http://arxiv.org/abs/2310.08152)|null|\n", "2310.04205": "|**2023-10-29**|**Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface**|Anupam Purwar et.al.|[2310.04205](http://arxiv.org/abs/2310.04205)|null|\n", "2310.01801": "|**2024-10-29**|**Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs**|Suyu Ge et.al.|[2310.01801_(ICLR)](http://arxiv.org/abs/2310.01801)|null|\n", "2309.03905": "|**2023-09-11**|**ImageBind-LLM: Multi-modality Instruction Tuning**|Jiaming Han et.al.|[2309.03905](http://arxiv.org/abs/2309.03905)|**[link](https://github.com/OpenGVLab/LLaMA-Adapter)**|\n", "2307.02628": "|**2023-07-05**|**SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference**|Luciano Del Corro et.al.|[2307.02628](http://arxiv.org/abs/2307.02628)|null|\n", "2306.14048": "|**2023-12-18**|**H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models**|Zhenyu Zhang et.al.|[2306.14048](http://arxiv.org/abs/2306.14048)|null|\n", "2306.02003": "|**2023-08-29**|**On Optimal Caching and Model Multiplexing for Large Model Inference**|Banghua Zhu et.al.|[2306.02003](http://arxiv.org/abs/2306.02003)|null|\n", "2305.17118": "|**2023-08-28**|**Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time**|Zichang Liu et.al.|[2305.17118](http://arxiv.org/abs/2305.17118)|null|\n", "2303.06865": "|**2023-06-12**|**FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU**|Ying Sheng et.al.|[2303.06865](http://arxiv.org/abs/2303.06865)|null|\n", "2508.00743": "|**2025-08-01**|**Agentic large language models improve retrieval-based radiology question answering**|Sebastian Wind et.al.|[2508.00743](http://arxiv.org/abs/2508.00743)|null|\n", "2508.00741": "|**2025-08-01**|**Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data**|Sohaib Imran et.al.|[2508.00741](http://arxiv.org/abs/2508.00741)|null|\n", "2508.00719": "|**2025-08-01**|**Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA**|Yingxu Wang et.al.|[2508.00719](http://arxiv.org/abs/2508.00719)|null|\n", "2508.00709": "|**2025-08-01**|**NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System**|Shubham Kumar Nigam et.al.|[2508.00709](http://arxiv.org/abs/2508.00709)|null|\n", "2508.00669": "|**2025-08-01**|**Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications**|Wenxuan Wang et.al.|[2508.00669](http://arxiv.org/abs/2508.00669)|null|\n", "2508.00579": "|**2025-08-01**|**MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval**|Ziyu Gong et.al.|[2508.00579](http://arxiv.org/abs/2508.00579)|null|\n", "2508.00574": "|**2025-08-01**|**SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought**|Jianwei Wang et.al.|[2508.00574](http://arxiv.org/abs/2508.00574)|null|\n", "2508.00957": "|**2025-08-01**|**Small sample-based adaptive text classification through iterative and contrastive description refinement**|Amrit Rajeev et.al.|[2508.00957](http://arxiv.org/abs/2508.00957)|null|\n", "2508.00507": "|**2025-08-01**|**Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection**|Yiming Xu et.al.|[2508.00507](http://arxiv.org/abs/2508.00507)|null|\n", "2508.00459": "|**2025-08-01**|**Thinking Machines: Mathematical Reasoning in the Age of LLMs**|Andrea Asperti et.al.|[2508.00459](http://arxiv.org/abs/2508.00459)|null|\n", "2508.00429": "|**2025-08-05**|**ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network**|Minghao Guo et.al.|[2508.00429](http://arxiv.org/abs/2508.00429)|null|\n", "2508.00422": "|**2025-08-01**|**Automated Type Annotation in Python Using Large Language Models**|Varun Bharti et.al.|[2508.00422](http://arxiv.org/abs/2508.00422)|null|\n", "2508.00419": "|**2025-08-01**|**Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers**|Varun Bharti et.al.|[2508.00419](http://arxiv.org/abs/2508.00419)|null|\n", "2508.00410": "|**2025-08-01**|**Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement**|Zizhuo Zhang et.al.|[2508.00410](http://arxiv.org/abs/2508.00410)|null|\n", "2508.00408": "|**2025-08-01**|**Benchmarking LLMs for Unit Test Generation from Real-World Functions**|Dong Huang et.al.|[2508.00408](http://arxiv.org/abs/2508.00408)|null|\n", "2508.00385": "|**2025-08-01**|**Multi-Layer Attention is the Amplifier of Demonstration Effectiveness**|Dingzirui Wang et.al.|[2508.00385](http://arxiv.org/abs/2508.00385)|null|\n", "2508.00344": "|**2025-08-01**|**PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning**|Keer Lu et.al.|[2508.00344](http://arxiv.org/abs/2508.00344)|null|\n", "2508.00321": "|**2025-08-01**|**Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes**|Shuning Zhang et.al.|[2508.00321](http://arxiv.org/abs/2508.00321)|null|\n", "2508.00285": "|**2025-08-01**|**Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering**|Peixian Li et.al.|[2508.00285](http://arxiv.org/abs/2508.00285)|null|\n", "2508.00222": "|**2025-08-06**|**RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization**|Yihong Dong et.al.|[2508.00222](http://arxiv.org/abs/2508.00222)|null|\n", "2508.00217": "|**2025-07-31**|**Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges**|Xiaofeng Wu et.al.|[2508.00217](http://arxiv.org/abs/2508.00217)|null|\n", "2508.00198": "|**2025-08-04**|**Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems**|Cleyton Magalhaes et.al.|[2508.00198](http://arxiv.org/abs/2508.00198)|null|\n", "2508.00079": "|**2025-07-31**|**PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems**|Oshayer Siddique et.al.|[2508.00079](http://arxiv.org/abs/2508.00079)|null|\n", "2507.23776": "|**2025-07-31**|**Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities**|Yunxiang Yan et.al.|[2507.23776](http://arxiv.org/abs/2507.23776)|null|\n", "2507.23773": "|**2025-07-31**|**SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model**|Mingkai Deng et.al.|[2507.23773](http://arxiv.org/abs/2507.23773)|null|\n", "2507.23751": "|**2025-07-31**|**CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks**|Ping Yu et.al.|[2507.23751](http://arxiv.org/abs/2507.23751)|null|\n", "2507.23726": "|**2025-08-01**|**Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving**|Luoxin Chen et.al.|[2507.23726](http://arxiv.org/abs/2507.23726)|null|\n", "2507.23701": "|**2025-07-31**|**TextQuests: How Good are LLMs at Text-Based Video Games?**|Long Phan et.al.|[2507.23701](http://arxiv.org/abs/2507.23701)|null|\n", "2508.00943": "|**2025-07-31**|**LLMs Can Covertly Sandbag on Capability Evaluations Against Chain-of-Thought Monitoring**|Chloe Li et.al.|[2508.00943](http://arxiv.org/abs/2508.00943)|null|\n", "2507.23589": "|**2025-07-31**|**Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study**|Kai Goebel et.al.|[2507.23589](http://arxiv.org/abs/2507.23589)|null|\n", "2507.23581": "|**2025-07-31**|**GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning**|Chuanyue Yu et.al.|[2507.23581](http://arxiv.org/abs/2507.23581)|null|\n", "2507.23554": "|**2025-07-31**|**DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer**|Ruoyu Wang et.al.|[2507.23554](http://arxiv.org/abs/2507.23554)|null|\n", "2507.23541": "|**2025-08-02**|**Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning**|Keer Lu et.al.|[2507.23541](http://arxiv.org/abs/2507.23541)|null|\n", "2507.23540": "|**2025-07-31**|**A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving**|Yi Zhang et.al.|[2507.23540](http://arxiv.org/abs/2507.23540)|null|\n", "2507.23429": "|**2025-07-31**|**Chatting with your ERP: A Recipe**|Jorge Ruiz G\u00f3mez et.al.|[2507.23429_(Performance)](http://arxiv.org/abs/2507.23429)|null|\n", "2507.23377": "|**2025-07-31**|**LLM4Rail: An LLM-Augmented Railway Service Consulting Platform**|Zhuo Li et.al.|[2507.23377](http://arxiv.org/abs/2507.23377)|null|\n", "2507.23370": "|**2025-07-31**|**Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling**|Trae Research Team et.al.|[2507.23370](http://arxiv.org/abs/2507.23370)|null|\n", "2507.23348": "|**2025-07-31**|**SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution**|Han Li et.al.|[2507.23348](http://arxiv.org/abs/2507.23348)|**[link](https://github.com/YerbaPage/SWE-Debate)**|\n", "2507.23279": "|**2025-07-31**|**Unveiling Super Experts in Mixture-of-Experts Large Language Models**|Zunhai Su et.al.|[2507.23279](http://arxiv.org/abs/2507.23279)|null|\n", "2507.23261": "|**2025-07-31**|**DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System**|Hui Yi Leong et.al.|[2507.23261](http://arxiv.org/abs/2507.23261)|null|\n", "2507.23247": "|**2025-07-31**|**P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication**|Sneha Oram et.al.|[2507.23247](http://arxiv.org/abs/2507.23247)|null|\n", "2507.23229": "|**2025-07-31**|**Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation**|Yufei Chen et.al.|[2507.23229](http://arxiv.org/abs/2507.23229)|null|\n", "2507.23227": "|**2025-07-31**|**Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs**|Sophie Kearney et.al.|[2507.23227](http://arxiv.org/abs/2507.23227)|null|\n", "2507.23194": "|**2025-07-31**|**Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks**|Jianghui Wang et.al.|[2507.23194](http://arxiv.org/abs/2507.23194)|null|\n", "2508.02711": "|**2025-07-31**|**A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models**|Yidong Chai et.al.|[2508.02711](http://arxiv.org/abs/2508.02711)|null|\n", "2507.23170": "|**2025-08-02**|**BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning**|Jinan Zhou et.al.|[2507.23170](http://arxiv.org/abs/2507.23170)|null|\n", "2507.23163": "|**2025-07-30**|**Argumentatively Coherent Judgmental Forecasting**|Deniz Gorur et.al.|[2507.23163](http://arxiv.org/abs/2507.23163)|null|\n", "2507.23146": "|**2025-07-30**|**Lightweight Language Models are Prone to Reasoning Errors for Complex Computational Phenotyping Tasks**|Sarah Pungitore et.al.|[2507.23146](http://arxiv.org/abs/2507.23146)|null|\n", "2507.22887": "|**2025-07-30**|**Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning**|Kwesi Cobbina et.al.|[2507.22887](http://arxiv.org/abs/2507.22887)|null|\n", "2507.22879": "|**2025-07-31**|**RecGPT Technical Report**|Chao Yi et.al.|[2507.22879](http://arxiv.org/abs/2507.22879)|null|\n", "2507.22805": "|**2025-08-05**|**MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention**|Yuqi Pang et.al.|[2507.22805](http://arxiv.org/abs/2507.22805)|null|\n", "2507.22800": "|**2025-07-30**|**The Multi-Agent Fault Localization System Based on Monte Carlo Tree Search Approach**|Rui Ren et.al.|[2507.22800](http://arxiv.org/abs/2507.22800)|null|\n", "2507.22716": "|**2025-08-06**|**From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in Retrieval-Augmented Reasoning for LLMs**|Jie He et.al.|[2507.22716](http://arxiv.org/abs/2507.22716)|null|\n", "2507.22581": "|**2025-07-31**|**Unveiling the Influence of Amplifying Language-Specific Neurons**|Inaya Rahmanisa et.al.|[2507.22581](http://arxiv.org/abs/2507.22581)|**[link](https://github.com/tauimbz/lang-task-neuron)**|\n", "2507.22580": "|**2025-07-30**|**RePaCA: Leveraging Reasoning Large Language Models for Static Automated Patch Correctness Assessment**|Marcos Fuster-Pena et.al.|[2507.22580](http://arxiv.org/abs/2507.22580)|null|\n", "2507.22545": "|**2025-08-01**|**ControlMed: Adding Reasoning Control to Medical Language Model**|Sung-Min Lee et.al.|[2507.22545](http://arxiv.org/abs/2507.22545)|null|\n", "2507.22478": "|**2025-07-30**|**SLM-SQL: An Exploration of Small Language Models for Text-to-SQL**|Lei Sheng et.al.|[2507.22478](http://arxiv.org/abs/2507.22478)|null|\n", "2507.22467": "|**2025-07-30**|**Towards Simulating Social Influence Dynamics with LLM-based Multi-agents**|Hsien-Tsung Lin et.al.|[2507.22467](http://arxiv.org/abs/2507.22467)|null|\n", "2507.22457": "|**2025-07-30**|**What is an \"Abstract Reasoner\"? Revisiting Experiments and Arguments about Large Language Models**|Tian Yun et.al.|[2507.22457_(CoNLL)](http://arxiv.org/abs/2507.22457)|**[link](https://abstract-reasoner-llm.github.io/)**|\n", "2508.00031": "|**2025-07-30**|**Git Context Controller: Manage the Context of LLM-based Agents like Git**|Junde Wu et.al.|[2508.00031](http://arxiv.org/abs/2508.00031)|null|\n", "2507.22448": "|**2025-07-30**|**Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance**|Jingwei Zuo et.al.|[2507.22448](http://arxiv.org/abs/2507.22448)|null|\n", "2507.22411": "|**2025-07-30**|**NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models**|Hyeonseok Moon et.al.|[2507.22411](http://arxiv.org/abs/2507.22411)|null|\n", "2507.22337": "|**2025-07-30**|**A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers**|Roxana Petcu et.al.|[2507.22337](http://arxiv.org/abs/2507.22337)|null|\n", "2508.03725": "|**2025-07-30**|**A Large Language Model Powered Integrated Circuit Footprint Geometry Understanding**|Yida Wang et.al.|[2508.03725](http://arxiv.org/abs/2508.03725)|null|\n", "2507.22281": "|**2025-07-29**|**CoEx -- Co-evolving World-model and Exploration**|Minsoo Kim et.al.|[2507.22281](http://arxiv.org/abs/2507.22281)|null|\n", "2507.22955": "|**2025-07-29**|**LLMs Between the Nodes: Community Discovery Beyond Vectors**|Ekta Gujral et.al.|[2507.22955](http://arxiv.org/abs/2507.22955)|null|\n", "2508.00914": "|**2025-07-29**|**Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis**|Dominic Simon et.al.|[2508.00914_(IJCAI)](http://arxiv.org/abs/2508.00914)|null|\n", "2508.00912": "|**2025-07-29**|**Predictive Auditing of Hidden Tokens in LLM APIs via Reasoning Length Estimation**|Ziyao Wang et.al.|[2508.00912](http://arxiv.org/abs/2508.00912)|null|\n", "2507.22050": "|**2025-07-30**|**DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router**|Minghao Guo et.al.|[2507.22050](http://arxiv.org/abs/2507.22050)|null|\n", "2507.22034": "|**2025-07-29**|**UserBench: An Interactive Gym Environment for User-Centric Agents**|Cheng Qian et.al.|[2507.22034](http://arxiv.org/abs/2507.22034)|null|\n", "2507.21990": "|**2025-07-30**|**ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge**|Zihan Zhao et.al.|[2507.21990](http://arxiv.org/abs/2507.21990)|null|\n", "2507.21980": "|**2025-07-29**|**Predicting Microbial Ontology and Pathogen Risk from Environmental Metadata with Large Language Models**|Hyunwoo Yoo et.al.|[2507.21980](http://arxiv.org/abs/2507.21980)|null|\n", "2507.21974": "|**2025-07-29**|**Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks**|Mohamed Sana et.al.|[2507.21974](http://arxiv.org/abs/2507.21974)|null|\n", "2507.21969": "|**2025-07-29**|**Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation**|Adam Kostka et.al.|[2507.21969_(CogSci)](http://arxiv.org/abs/2507.21969)|null|\n", "2507.21931": "|**2025-07-29**|**Post-Training Large Language Models via Reinforcement Learning from Self-Feedback**|Carel van Niekerk et.al.|[2507.21931](http://arxiv.org/abs/2507.21931)|null|\n", "2507.21924": "|**2025-07-29**|**MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning**|Tianhong Gao et.al.|[2507.21924](http://arxiv.org/abs/2507.21924)|null|\n", "2507.21892": "|**2025-07-29**|**Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning**|Haoran Luo et.al.|[2507.21892](http://arxiv.org/abs/2507.21892)|null|\n", "2507.21848": "|**2025-07-29**|**EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity**|Xingjian Zhang et.al.|[2507.21848](http://arxiv.org/abs/2507.21848)|null|\n", "2507.21836": "|**2025-07-29**|**AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning**|Yifan Wei et.al.|[2507.21836](http://arxiv.org/abs/2507.21836)|null|\n", "2507.21830": "|**2025-07-30**|**DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework**|Kuiye Ding et.al.|[2507.21830_(ACM MM)](http://arxiv.org/abs/2507.21830)|null|\n", "2507.21790": "|**2025-07-29**|**Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities**|Georges Sfeir et.al.|[2507.21790](http://arxiv.org/abs/2507.21790)|null|\n", "2507.21778": "|**2025-07-29**|**AU-LLM: Micro-Expression Action Unit Detection via Enhanced LLM-Based Feature Fusion**|Zhishu Liu et.al.|[2507.21778](http://arxiv.org/abs/2507.21778)|null|\n", "2507.21653": "|**2025-07-29**|**DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs**|Yuan Li et.al.|[2507.21653](http://arxiv.org/abs/2507.21653)|null|\n", "2507.21636": "|**2025-07-29**|**StaffPro: an LLM Agent for Joint Staffing and Profiling**|Alessio Maritan et.al.|[2507.21636](http://arxiv.org/abs/2507.21636)|null|\n", "2507.21545": "|**2025-07-29**|**Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning**|Haoming Ye et.al.|[2507.21545](http://arxiv.org/abs/2507.21545)|null|\n", "2507.21544": "|**2025-07-29**|**MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation**|Jungyeon Lee et.al.|[2507.21544](http://arxiv.org/abs/2507.21544)|null|\n", "2507.21524": "|**2025-07-29**|**Large Language Models for Wireless Communications: From Adaptation to Autonomy**|Le Liang et.al.|[2507.21524](http://arxiv.org/abs/2507.21524)|null|\n", "2507.21476": "|**2025-07-29**|**Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench**|Reuben Narad et.al.|[2507.21476](http://arxiv.org/abs/2507.21476)|null|\n", "2507.21471": "|**2025-07-29**|**An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning**|Zujie Xie et.al.|[2507.21471](http://arxiv.org/abs/2507.21471)|null|\n", "2507.21447": "|**2025-07-29**|**LLM4VV: Evaluating Cutting-Edge LLMs for Generation and Evaluation of Directive-Based Parallel Programming Model Compiler Tests**|Zachariah Sollenberger et.al.|[2507.21447](http://arxiv.org/abs/2507.21447)|null|\n", "2507.21438": "|**2025-07-29**|**Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models**|Vishal Raman et.al.|[2507.21438](http://arxiv.org/abs/2507.21438)|null|\n", "2507.21432": "|**2025-07-29**|**Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour**|Tareq Alsaleh et.al.|[2507.21432](http://arxiv.org/abs/2507.21432)|null|\n", "2507.21428": "|**2025-07-29**|**MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations**|Elias Lumer et.al.|[2507.21428](http://arxiv.org/abs/2507.21428)|null|\n", "2507.21391": "|**2025-07-30**|**Multimodal LLMs as Customized Reward Models for Text-to-Image Generation**|Shijie Zhou et.al.|[2507.21391_(ICC)](http://arxiv.org/abs/2507.21391)|**[link](https://github.com/sjz5202/LLaVA-Reward)**|\n", "2508.00902": "|**2025-07-28**|**An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models**|Kenneth Payne et.al.|[2508.00902](http://arxiv.org/abs/2508.00902)|null|\n", "2507.21046": "|**2025-08-01**|**A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence**|Huan-ang Gao et.al.|[2507.21046](http://arxiv.org/abs/2507.21046)|null|\n", "2507.20999": "|**2025-07-28**|**LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient LLM Fine-Tuning**|Yining Huang et.al.|[2507.20999](http://arxiv.org/abs/2507.20999)|null|\n", "2507.20936": "|**2025-07-28**|**Dissecting Persona-Driven Reasoning in Language Models via Activation Patching**|Ansh Poonia et.al.|[2507.20936](http://arxiv.org/abs/2507.20936)|null|\n", "2507.20870": "|**2025-07-28**|**A Human-in-the-loop Approach to Robot Action Replanning through LLM Common-Sense Reasoning**|Elena Merlo et.al.|[2507.20870](http://arxiv.org/abs/2507.20870)|null|\n", "2507.20796": "|**2025-07-28**|**Aligning Large Language Model Agents with Rational and Moral Preferences: A Supervised Fine-Tuning Approach**|Wei Lu et.al.|[2507.20796](http://arxiv.org/abs/2507.20796)|null|\n", "2507.21199": "|**2025-07-28**|**Advancing Compositional LLM Reasoning with Structured Task Relations in Interactive Multimodal Communications**|Xinye Cao et.al.|[2507.21199](http://arxiv.org/abs/2507.21199)|null|\n", "2507.20643": "|**2025-07-28**|**Ontology-Enhanced Knowledge Graph Completion using Large Language Models**|Wenbin Guo et.al.|[2507.20643](http://arxiv.org/abs/2507.20643)|null|\n", "2507.20527": "|**2025-07-29**|**SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers**|Chaitanya Manem et.al.|[2507.20527](http://arxiv.org/abs/2507.20527)|null|\n", "2507.20526": "|**2025-07-28**|**Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition**|Andy Zou et.al.|[2507.20526](http://arxiv.org/abs/2507.20526)|null|\n", "2507.20509": "|**2025-07-28**|**LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models**|Zhongchao Zhou et.al.|[2507.20509](http://arxiv.org/abs/2507.20509)|null|\n", "2507.20491": "|**2025-07-28**|**Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems**|Tuan Bui et.al.|[2507.20491](http://arxiv.org/abs/2507.20491)|**[link](https://2025.ijcnn.org)**|\n", "2507.20395": "|**2025-07-27**|**MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models**|Hafsteinn Einarsson et.al.|[2507.20395](http://arxiv.org/abs/2507.20395)|null|\n", "2507.20370": "|**2025-07-27**|**Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation**|Michele Grimaldi et.al.|[2507.20370](http://arxiv.org/abs/2507.20370)|null|\n", "2507.21188": "|**2025-07-27**|**Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs**|Raj Krishnan Vijayaraj et.al.|[2507.21188](http://arxiv.org/abs/2507.21188)|null|\n", "2507.20342": "|**2025-07-27**|**VLMPlanner: Integrating Visual Language Models with Motion Planning**|Zhipeng Tang et.al.|[2507.20342_(ACM MM)](http://arxiv.org/abs/2507.20342)|null|\n", "2507.20322": "|**2025-07-27**|**Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting**|Manish Verma et.al.|[2507.20322_(SC)](http://arxiv.org/abs/2507.20322)|null|\n", "2507.20278": "|**2025-07-27**|**MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning**|Kang Yang et.al.|[2507.20278](http://arxiv.org/abs/2507.20278)|null|\n", "2507.20227": "|**2025-08-02**|**CTR-Driven Ad Text Generation via Online Feedback Preference Optimization**|Yanda Chen et.al.|[2507.20227](http://arxiv.org/abs/2507.20227)|null|\n", "2507.20152": "|**2025-07-27**|**Goal Alignment in LLM-Based User Simulators for Conversational AI**|Shuhaib Mehri et.al.|[2507.20152](http://arxiv.org/abs/2507.20152)|null|\n", "2507.20150": "|**2025-07-27**|**The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models**|Xingcheng Xu et.al.|[2507.20150](http://arxiv.org/abs/2507.20150)|null|\n", "2507.20067": "|**2025-07-26**|**PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training**|Sarat Chandra Bobbili et.al.|[2507.20067](http://arxiv.org/abs/2507.20067)|null|\n", "2507.20021": "|**2025-07-26**|**When Engineering Outruns Intelligence: A Re-evaluation of Instruction-Guided Navigation**|Matin Aghaei et.al.|[2507.20021](http://arxiv.org/abs/2507.20021)|null|\n", "2507.20000": "|**2025-07-26**|**Matching Game Preferences Through Dialogical Large Language Models: A Perspective**|Renaud Fabre et.al.|[2507.20000_(SC)](http://arxiv.org/abs/2507.20000)|null|\n", "2507.19990": "|**2025-07-26**|**Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model**|Sinnyum Choi et.al.|[2507.19990](http://arxiv.org/abs/2507.19990)|null|\n", "2507.21179": "|**2025-07-26**|**LLM-Adapted Interpretation Framework for Machine Learning Models**|Yuqi Jin et.al.|[2507.21179](http://arxiv.org/abs/2507.21179)|null|\n", "2507.19980": "|**2025-07-29**|**Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory**|Dan Song et.al.|[2507.19980](http://arxiv.org/abs/2507.19980)|null|\n", "2507.19969": "|**2025-07-26**|**Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text**|Mizanur Rahman et.al.|[2507.19969](http://arxiv.org/abs/2507.19969)|null|\n", "2507.19885": "|**2025-07-26**|**Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam**|Cesar Augusto Madid Truyts et.al.|[2507.19885](http://arxiv.org/abs/2507.19885)|null|\n", "2507.19855": "|**2025-07-29**|**Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning**|Aditya Sharma et.al.|[2507.19855](http://arxiv.org/abs/2507.19855)|null|\n", "2507.19849": "|**2025-07-26**|**Agentic Reinforced Policy Optimization**|Guanting Dong et.al.|[2507.19849](http://arxiv.org/abs/2507.19849)|null|\n", "2507.19766": "|**2025-07-26**|**UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities**|Dong Du et.al.|[2507.19766](http://arxiv.org/abs/2507.19766)|null|\n", "2507.19749": "|**2025-07-26**|**Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)**|Lin Ren et.al.|[2507.19749](http://arxiv.org/abs/2507.19749)|**[link](https://github.com/HomuraT/ASPBench)**|\n", "2507.19748": "|**2025-07-26**|**JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models**|Yifan Hao et.al.|[2507.19748](http://arxiv.org/abs/2507.19748)|null|\n", "2507.19703": "|**2025-07-30**|**The wall confronting large language models**|Peter V. Coveney et.al.|[2507.19703](http://arxiv.org/abs/2507.19703)|null|\n", "2507.19666": "|**2025-07-25**|**RoD-TAL: A Benchmark for Answering Questions in Romanian Driving License Exams**|Andrei Vlad Man et.al.|[2507.19666](http://arxiv.org/abs/2507.19666)|null|\n", "2507.19586": "|**2025-07-25**|**Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning**|Shengyuan Wang et.al.|[2507.19586](http://arxiv.org/abs/2507.19586)|null|\n", "2507.19477": "|**2025-07-25**|**Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts**|Sang-Woo Lee et.al.|[2507.19477](http://arxiv.org/abs/2507.19477)|null|\n", "2507.19457": "|**2025-07-25**|**GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning**|Lakshya A Agrawal et.al.|[2507.19457](http://arxiv.org/abs/2507.19457)|null|\n", "2508.00017": "|**2025-07-25**|**Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation**|Nikolai Sergeev et.al.|[2508.00017_(CHI)](http://arxiv.org/abs/2508.00017)|null|\n", "2507.19364": "|**2025-07-25**|**Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges**|Patrick Taillandier et.al.|[2507.19364](http://arxiv.org/abs/2507.19364)|null|\n", "2507.19333": "|**2025-07-25**|**Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation**|Minghao Tang et.al.|[2507.19333](http://arxiv.org/abs/2507.19333)|null|\n", "2507.19254": "|**2025-07-25**|**DBMS-LLM Integration Strategies in Industrial and Business Applications: Current Status and Future Challenges**|Zhengtong Yan et.al.|[2507.19254](http://arxiv.org/abs/2507.19254)|null|\n", "2507.21166": "|**2025-07-25**|**AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation**|Ren Zhuang et.al.|[2507.21166](http://arxiv.org/abs/2507.21166)|null|\n", "2507.19232": "|**2025-07-25**|**Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene**|Donggeun Lim et.al.|[2507.19232](http://arxiv.org/abs/2507.19232)|**[link](https://rms0329.github.io/Event-Driven-Storytelling/)**|\n", "2507.19227": "|**2025-07-25**|**Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation**|Yuanhe Zhang et.al.|[2507.19227](http://arxiv.org/abs/2507.19227)|null|\n", "2507.22940": "|**2025-08-02**|**Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes**|Rui Jiao et.al.|[2507.22940](http://arxiv.org/abs/2507.22940)|null|\n", "2507.19027": "|**2025-07-25**|**SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews**|Aleksi Huotala et.al.|[2507.19027](http://arxiv.org/abs/2507.19027)|null|\n", "2507.18973": "|**2025-07-25**|**A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation**|Bohan Yao et.al.|[2507.18973](http://arxiv.org/abs/2507.18973)|null|\n", "2507.18932": "|**2025-07-25**|**Benchmarking Multimodal Understanding and Complex Reasoning for ESG Tasks**|Lei Zhang et.al.|[2507.18932](http://arxiv.org/abs/2507.18932)|null|\n", "2507.18884": "|**2025-07-25**|**MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service**|Ming Gong et.al.|[2507.18884](http://arxiv.org/abs/2507.18884)|null|\n", "2507.18857": "|**2025-07-25**|**PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning**|Mohammad Kachuee et.al.|[2507.18857](http://arxiv.org/abs/2507.18857)|null|\n", "2507.18755": "|**2025-07-24**|**Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback**|Chandra Maddila et.al.|[2507.18755](http://arxiv.org/abs/2507.18755)|null|\n", "2507.18618": "|**2025-07-24**|**TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards**|Andreea Nica et.al.|[2507.18618](http://arxiv.org/abs/2507.18618)|null|\n", "2507.18584": "|**2025-07-24**|**AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs**|Xiaopeng Ke et.al.|[2507.18584](http://arxiv.org/abs/2507.18584)|null|\n", "2507.18523": "|**2025-07-24**|**The Moral Gap of Large Language Models**|Maciej Skorski et.al.|[2507.18523](http://arxiv.org/abs/2507.18523)|null|\n", "2507.18479": "|**2025-07-24**|**How Well Do LLMs Predict Prerequisite Skills? Zero-Shot Comparison to Expert-Defined Concepts**|Ngoc Luyen Le et.al.|[2507.18479](http://arxiv.org/abs/2507.18479)|null|\n", "2507.18476": "|**2025-07-24**|**Automated Code Review Using Large Language Models with Symbolic Reasoning**|Busra Icoz et.al.|[2507.18476](http://arxiv.org/abs/2507.18476)|null|\n", "2507.18452": "|**2025-07-24**|**DIFFA: Large Language Diffusion Models Can Listen and Understand**|Jiaming Zhou et.al.|[2507.18452](http://arxiv.org/abs/2507.18452)|null|\n", "2507.18442": "|**2025-07-24**|**AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data**|Rana Alshaikh et.al.|[2507.18442](http://arxiv.org/abs/2507.18442)|null|\n", "2507.18392": "|**2025-07-24**|**CLEAR: Error Analysis via LLM-as-a-Judge Made Easy**|Asaf Yehudai et.al.|[2507.18392](http://arxiv.org/abs/2507.18392)|null|\n", "2507.18391": "|**2025-07-24**|**Revisiting LLM Reasoning via Information Bottleneck**|Shiye Lei et.al.|[2507.18391](http://arxiv.org/abs/2507.18391)|null|\n", "2507.18368": "|**2025-07-24**|**Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios**|Zhuang Qiang Bok et.al.|[2507.18368_(KDD)](http://arxiv.org/abs/2507.18368)|**[link](https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/)**|\n", "2507.18305": "|**2025-07-24**|**BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit**|Biao Yi et.al.|[2507.18305](http://arxiv.org/abs/2507.18305)|null|\n", "2507.22928": "|**2025-07-24**|**How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding**|Xi Chen et.al.|[2507.22928](http://arxiv.org/abs/2507.22928)|null|\n", "2507.18252": "|**2025-07-24**|**Multimodal Behavioral Patterns Analysis with Eye-Tracking and LLM-Based Reasoning**|Dongyang Guo et.al.|[2507.18252](http://arxiv.org/abs/2507.18252)|null|\n", "2507.18671": "|**2025-07-24**|**Innovator: Scientific Continued Pretraining with Fine-grained MoE Upcycling**|Ning Liao et.al.|[2507.18671](http://arxiv.org/abs/2507.18671)|null|\n", "2507.18178": "|**2025-07-24**|**Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory**|Mutian Yang et.al.|[2507.18178](http://arxiv.org/abs/2507.18178)|null|\n", "2507.18165": "|**2025-07-24**|**ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent**|Yuheng Zhao et.al.|[2507.18165](http://arxiv.org/abs/2507.18165)|null|\n", "2507.18143": "|**2025-07-25**|**HIVMedQA: Benchmarking large language models for HIV medical decision support**|Gonzalo Cardenal-Antolin et.al.|[2507.18143](http://arxiv.org/abs/2507.18143)|null|\n", "2507.18033": "|**2025-07-24**|**OpenNav: Open-World Navigation with Multimodal Large Language Models**|Mingfeng Yuan et.al.|[2507.18033](http://arxiv.org/abs/2507.18033)|null|\n", "2507.18014": "|**2025-07-24**|**Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models**|Datta Nimmaturi et.al.|[2507.18014](http://arxiv.org/abs/2507.18014)|null|\n", "2507.19543": "|**2025-07-23**|**Agent WARPP: Workflow Adherence via Runtime Parallel Personalization**|Maria Emilia Mazzolenis et.al.|[2507.19543_(ICML)](http://arxiv.org/abs/2507.19543)|**[link](https://github.com/emiliamazzo/WARPP/)**|\n", "2507.17944": "|**2025-07-23**|**Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text**|Hulayyil Alshammari et.al.|[2507.17944](http://arxiv.org/abs/2507.17944)|null|\n", "2507.17927": "|**2025-07-23**|**SMARTAPS: Tool-augmented LLMs for Operations Management**|Timothy Tin Long Yu et.al.|[2507.17927_(AAAI)](http://arxiv.org/abs/2507.17927)|**[link](https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/)**|\n", "2507.17874": "|**2025-07-23**|**I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis**|SaiBarath Sundar et.al.|[2507.17874](http://arxiv.org/abs/2507.17874)|null|\n", "2507.17842": "|**2025-07-23**|**Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning**|Yimeng Zhang et.al.|[2507.17842](http://arxiv.org/abs/2507.17842)|null|\n", "2507.18661": "|**2025-08-04**|**Eyes Will Shut: A Vision-Based Next GPS Location Prediction Model by Reinforcement Learning from Visual Map Feed Back**|Ruixing Zhang et.al.|[2507.18661](http://arxiv.org/abs/2507.18661)|null|\n", "2507.22927": "|**2025-07-23**|**PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation**|Zhehao Tan et.al.|[2507.22927](http://arxiv.org/abs/2507.22927)|null|\n", "2507.17797": "|**2025-07-23**|**GenSelect: A Generative Approach to Best-of-N**|Shubham Toshniwal et.al.|[2507.17797_(ICML)](http://arxiv.org/abs/2507.17797)|null|\n", "2507.22925": "|**2025-07-23**|**Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents**|Haoran Sun et.al.|[2507.22925](http://arxiv.org/abs/2507.22925)|null|\n", "2507.17787": "|**2025-07-23**|**Hyperbolic Deep Learning for Foundation Models: A Survey**|Neil He et.al.|[2507.17787_(KDD)](http://arxiv.org/abs/2507.17787)|null|\n", "2507.22074": "|**2025-07-22**|**CIMR: Contextualized Iterative Multimodal Reasoning for Robust Instruction Following in LVLMs**|Yangshu Yuan et.al.|[2507.22074](http://arxiv.org/abs/2507.22074)|null|\n", "2507.21130": "|**2025-07-22**|**INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems**|Bintao Tang et.al.|[2507.21130](http://arxiv.org/abs/2507.21130)|null|\n", "2507.22920": "|**2025-07-21**|**Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey**|Jindong Li et.al.|[2507.22920](http://arxiv.org/abs/2507.22920)|null|\n", "2507.19525": "|**2025-07-20**|**MMCircuitEval: A Comprehensive Multimodal Circuit-Focused Benchmark for Evaluating LLMs**|Chenchen Zhao et.al.|[2507.19525_(ICC)](http://arxiv.org/abs/2507.19525)|null|\n", "2508.06484": "|**2025-08-08**|**Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data**|Yuvraj Virk et.al.|[2508.06484](http://arxiv.org/abs/2508.06484)|null|\n", "2508.06457": "|**2025-08-08**|**ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls**|Sanket Badhe et.al.|[2508.06457_(CHI)](http://arxiv.org/abs/2508.06457)|null|\n", "2508.06412": "|**2025-08-08**|**Sample-efficient LLM Optimization with Reset Replay**|Zichuan Liu et.al.|[2508.06412](http://arxiv.org/abs/2508.06412)|null|\n", "2508.06361": "|**2025-08-08**|**Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts**|Zhaomin Wu et.al.|[2508.06361](http://arxiv.org/abs/2508.06361)|null|\n", "2508.06328": "|**2025-08-08**|**M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation**|Zhiyou Xiao et.al.|[2508.06328](http://arxiv.org/abs/2508.06328)|null|\n", "2508.06196": "|**2025-08-08**|**EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations**|Nizi Nazar et.al.|[2508.06196](http://arxiv.org/abs/2508.06196)|null|\n", "2508.06189": "|**2025-08-08**|**MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration**|Cheng Liu et.al.|[2508.06189](http://arxiv.org/abs/2508.06189)|null|\n", "2508.06168": "|**2025-08-08**|**Improving Table Retrieval with Question Generation from Partial Tables**|Hsing-Ping Liang et.al.|[2508.06168_(ACL)](http://arxiv.org/abs/2508.06168)|null|\n", "2508.06165": "|**2025-08-08**|**UR$^2$: Unify RAG and Reasoning through Reinforcement Learning**|Weitao Li et.al.|[2508.06165](http://arxiv.org/abs/2508.06165)|null|\n", "2508.06124": "|**2025-08-08**|**AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models**|Sayantan Adak et.al.|[2508.06124](http://arxiv.org/abs/2508.06124)|null|\n", "2508.06111": "|**2025-08-08**|**SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges**|Dewi S. W. Gould et.al.|[2508.06111](http://arxiv.org/abs/2508.06111)|null|\n", "2508.06110": "|**2025-08-08**|**PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion**|Yiran Rex Ma et.al.|[2508.06110](http://arxiv.org/abs/2508.06110)|null|\n", "2508.06105": "|**2025-08-08**|**You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures**|Shengyuan Chen et.al.|[2508.06105](http://arxiv.org/abs/2508.06105)|null|\n", "2508.06094": "|**2025-08-08**|**ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline**|Morris Alper et.al.|[2508.06094](http://arxiv.org/abs/2508.06094)|**[link](https://conlangcrafter.github.io)**|\n", "2508.06060": "|**2025-08-08**|**LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences**|Sankarshan Damle et.al.|[2508.06060](http://arxiv.org/abs/2508.06060)|null|\n", "2508.06046": "|**2025-08-08**|**EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation**|Xinda Wang et.al.|[2508.06046](http://arxiv.org/abs/2508.06046)|null|\n", "2508.06042": "|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Daechul Ahn et.al.|[2508.06042](http://arxiv.org/abs/2508.06042)|null|\n", "2508.06026": "|**2025-08-08**|**Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future**|Yidong Wang et.al.|[2508.06026](http://arxiv.org/abs/2508.06026)|null|\n", "2508.05995": "|**2025-08-08**|**Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization**|Fei Xu Yu et.al.|[2508.05995](http://arxiv.org/abs/2508.05995)|null|\n", "2508.05954": "|**2025-08-08**|**Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents**|Han Lin et.al.|[2508.05954](http://arxiv.org/abs/2508.05954)|**[link](https://bifrost-1.github.io)**|\n", "2508.05928": "|**2025-08-08**|**Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting**|Si Shen et.al.|[2508.05928](http://arxiv.org/abs/2508.05928)|null|\n", "2508.05880": "|**2025-08-07**|**Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models**|Sree Bhattacharyya et.al.|[2508.05880](http://arxiv.org/abs/2508.05880)|null|\n", "2508.05782": "|**2025-08-07**|**FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification**|Xiangyan Chen et.al.|[2508.05782](http://arxiv.org/abs/2508.05782)|null|\n", "2508.05775": "|**2025-08-07**|**Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation**|Chi Zhang et.al.|[2508.05775](http://arxiv.org/abs/2508.05775)|null|\n", "2508.05766": "|**2025-08-07**|**A Framework for Inherently Safer AGI through Language-Mediated Active Inference**|Bo Wen et.al.|[2508.05766](http://arxiv.org/abs/2508.05766)|null|\n", "2508.05709": "|**2025-08-07**|**G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation**|Boyu Chen et.al.|[2508.05709](http://arxiv.org/abs/2508.05709)|null|\n", "2508.05702": "|**2025-08-07**|**Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control**|Yan Zhang et.al.|[2508.05702](http://arxiv.org/abs/2508.05702)|null|\n", "2508.05694": "|**2025-08-06**|**DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection**|Kaichuan Kong et.al.|[2508.05694_(ICDM)](http://arxiv.org/abs/2508.05694)|null|\n", "2508.07675": "|**2025-08-12**|**Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation**|Xutong Liu et.al.|[2508.07675](http://arxiv.org/abs/2508.07675)|null|\n", "2508.08243": "|**2025-08-12**|**Jinx: Unlimited LLMs for Probing Alignment Failures**|Jiahao Zhao et.al.|[2508.08243](http://arxiv.org/abs/2508.08243)|**[link](https://huggingface.co/Jinx-org)**|\n", "2508.08236": "|**2025-08-11**|**Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge**|Yunna Cai et.al.|[2508.08236](http://arxiv.org/abs/2508.08236)|null|\n", "2508.08224": "|**2025-08-11**|**Capabilities of GPT-5 on Multimodal Medical Reasoning**|Shansong Wang et.al.|[2508.08224](http://arxiv.org/abs/2508.08224)|null|\n", "2508.08221": "|**2025-08-11**|**Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning**|Zihe Liu et.al.|[2508.08221](http://arxiv.org/abs/2508.08221)|null|\n", "2508.08171": "|**2025-08-11**|**PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C**|Pedro Orvalho et.al.|[2508.08171](http://arxiv.org/abs/2508.08171)|null|\n", "2508.08149": "|**2025-08-12**|**REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation**|Wentao Jiang et.al.|[2508.08149_(DATE)](http://arxiv.org/abs/2508.08149)|null|\n", "2508.08137": "|**2025-08-11**|**MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation**|Pravallika Abbineni et.al.|[2508.08137](http://arxiv.org/abs/2508.08137)|null|\n", "2508.08120": "|**2025-08-11**|**Vision-Based Localization and LLM-based Navigation for Indoor Environments**|Keyan Rahimi et.al.|[2508.08120](http://arxiv.org/abs/2508.08120)|null|\n", "2508.08115": "|**2025-08-11**|**TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork**|Pranav Pushkar Mishra et.al.|[2508.08115](http://arxiv.org/abs/2508.08115)|null|\n", "2508.08053": "|**2025-08-11**|**AdaptFlow: Adaptive Workflow Optimization via Meta-Learning**|Runchuan Zhu et.al.|[2508.08053](http://arxiv.org/abs/2508.08053)|null|\n", "2508.08001": "|**2025-08-12**|**Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths**|Rui Yao et.al.|[2508.08001](http://arxiv.org/abs/2508.08001)|null|\n", "2508.07995": "|**2025-08-12**|**DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval**|Meixiu Long et.al.|[2508.07995](http://arxiv.org/abs/2508.07995)|null|\n", "2508.07950": "|**2025-08-11**|**FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis**|Chen Shen et.al.|[2508.07950](http://arxiv.org/abs/2508.07950)|null|\n", "2508.07935": "|**2025-08-11**|**SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows**|Jingwen Zhou et.al.|[2508.07935](http://arxiv.org/abs/2508.07935)|null|\n", "2508.07918": "|**2025-08-11**|**RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering**|Xing Zi et.al.|[2508.07918](http://arxiv.org/abs/2508.07918)|null|\n", "2508.07885": "|**2025-08-11**|**Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning**|Shoaib Ahmmad et.al.|[2508.07885](http://arxiv.org/abs/2508.07885)|null|\n", "2508.07827": "|**2025-08-11**|**Evaluating Large Language Models as Expert Annotators**|Yu-Min Tseng et.al.|[2508.07827](http://arxiv.org/abs/2508.07827)|null|\n", "2508.07809": "|**2025-08-11**|**EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning**|Huanyu Liu et.al.|[2508.07809](http://arxiv.org/abs/2508.07809)|null|\n", "2508.07805": "|**2025-08-11**|**Can You Trick the Grader? Adversarial Persuasion of LLM Judges**|Yerin Hwang et.al.|[2508.07805](http://arxiv.org/abs/2508.07805)|null|\n", "2508.07714": "|**2025-08-11**|**DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models**|Licheng Zhang et.al.|[2508.07714](http://arxiv.org/abs/2508.07714)|null|\n", "2508.07667": "|**2025-08-11**|**1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning**|Wenkai Li et.al.|[2508.07667](http://arxiv.org/abs/2508.07667)|null|\n", "2508.07646": "|**2025-08-11**|**Multi-Turn Jailbreaks Are Simpler Than They Seem**|Xiaoxue Yang et.al.|[2508.07646](http://arxiv.org/abs/2508.07646)|null|\n", "2508.07616": "|**2025-08-11**|**ThinkTuning: Instilling Cognitive Reflections without Distillation**|Aswin RRV et.al.|[2508.07616](http://arxiv.org/abs/2508.07616)|null|\n", "2508.07596": "|**2025-08-11**|**From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users**|Shahroz Tariq et.al.|[2508.07596](http://arxiv.org/abs/2508.07596)|null|\n", "2508.07595": "|**2025-08-11**|**Towards Comprehensible Recommendation with Large Language Model Fine-tuning**|Yunze Luo et.al.|[2508.07595](http://arxiv.org/abs/2508.07595)|null|\n", "2508.07534": "|**2025-08-11**|**From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR**|Jia Deng et.al.|[2508.07534](http://arxiv.org/abs/2508.07534)|null|\n", "2508.07485": "|**2025-08-10**|**Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy**|Alexander Duffy et.al.|[2508.07485](http://arxiv.org/abs/2508.07485)|null|\n", "2508.07479": "|**2025-08-10**|**Positional Biases Shift as Inputs Approach Context Window Limits**|Blerta Veseli et.al.|[2508.07479](http://arxiv.org/abs/2508.07479)|null|\n", "2508.07470": "|**2025-08-10**|**AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning**|Siminfar Samakoush Galougah et.al.|[2508.07470](http://arxiv.org/abs/2508.07470)|null|\n", "2508.07466": "|**2025-08-10**|**Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs**|Dom Huh et.al.|[2508.07466](http://arxiv.org/abs/2508.07466)|null|\n", "2508.07401": "|**2025-08-10**|**LET-US: Long Event-Text Understanding of Scenes**|Rui Chen et.al.|[2508.07401](http://arxiv.org/abs/2508.07401)|null|\n", "2508.07382": "|**2025-08-10**|**Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning**|He Kong et.al.|[2508.07382](http://arxiv.org/abs/2508.07382)|null|\n", "2508.07342": "|**2025-08-10**|**PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization**|Kepu Zhang et.al.|[2508.07342](http://arxiv.org/abs/2508.07342)|null|\n", "2508.07308": "|**2025-08-10**|**HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways**|Cristian Cosentino et.al.|[2508.07308](http://arxiv.org/abs/2508.07308)|null|\n", "2508.07284": "|**2025-08-10**|**\"Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas**|Junchen Ding et.al.|[2508.07284](http://arxiv.org/abs/2508.07284)|null|\n", "2508.07273": "|**2025-08-10**|**Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models**|Qiongqiong Wang et.al.|[2508.07273](http://arxiv.org/abs/2508.07273)|null|\n", "2508.07251": "|**2025-08-12**|**Understanding Dynamic Scenes in Ego Centric 4D Point Clouds**|Junsheng Huang et.al.|[2508.07251](http://arxiv.org/abs/2508.07251)|null|\n", "2508.07223": "|**2025-08-10**|**Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation**|Guanchen Wang et.al.|[2508.07223](http://arxiv.org/abs/2508.07223)|null|\n", "2508.07221": "|**2025-08-10**|**LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference**|Po-Han Lee et.al.|[2508.07221](http://arxiv.org/abs/2508.07221)|null|\n", "2508.07186": "|**2025-08-10**|**Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables**|Amit Dhanda et.al.|[2508.07186](http://arxiv.org/abs/2508.07186)|null|\n", "2508.07179": "|**2025-08-10**|**Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks**|Jiaqi Yin et.al.|[2508.07179](http://arxiv.org/abs/2508.07179)|null|\n", "2508.07127": "|**2025-08-10**|**How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?**|Niranjana Arun Menon et.al.|[2508.07127](http://arxiv.org/abs/2508.07127)|null|\n", "2508.07117": "|**2025-08-09**|**From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context**|Peyman Baghershahi et.al.|[2508.07117](http://arxiv.org/abs/2508.07117)|null|\n", "2508.07111": "|**2025-08-09**|**Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution**|Falaah Arif Khan et.al.|[2508.07111](http://arxiv.org/abs/2508.07111)|null|\n", "2508.07063": "|**2025-08-09**|**Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach**|Naseem Machlovi et.al.|[2508.07063](http://arxiv.org/abs/2508.07063)|null|\n", "2508.07050": "|**2025-08-09**|**ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability**|Wenhan Liu et.al.|[2508.07050](http://arxiv.org/abs/2508.07050)|null|\n", "2508.07043": "|**2025-08-09**|**K-Dense Analyst: Towards Fully Automated Scientific Analysis**|Orion Li et.al.|[2508.07043](http://arxiv.org/abs/2508.07043)|null|\n", "2508.07023": "|**2025-08-09**|**MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering**|Jingwei Peng et.al.|[2508.07023](http://arxiv.org/abs/2508.07023)|null|\n", "2508.06944": "|**2025-08-12**|**AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance**|Lixuan He et.al.|[2508.06944](http://arxiv.org/abs/2508.06944)|**[link](https://github.com/hlxtsyj/AMFT)**|\n", "2508.06832": "|**2025-08-09**|**Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges**|Haifeng Li et.al.|[2508.06832](http://arxiv.org/abs/2508.06832)|null|\n", "2508.06813": "|**2025-08-12**|**Technical Report: Full-Stack Fine-Tuning for the Q Programming Language**|Brendan R. Hogan et.al.|[2508.06813](http://arxiv.org/abs/2508.06813)|null|\n", "2508.06810": "|**2025-08-09**|**Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems**|Steven Coyne et.al.|[2508.06810_(ISS)](http://arxiv.org/abs/2508.06810)|null|\n", "2508.06600": "|**2025-08-08**|**BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent**|Zijian Chen et.al.|[2508.06600](http://arxiv.org/abs/2508.06600)|null|\n", "2508.09072": "|**2025-08-12**|**READER: Retrieval-Assisted Drafter for Efficient LLM Inference**|Maxim Divilkovskiy et.al.|[2508.09072](http://arxiv.org/abs/2508.09072)|null|\n", "2508.09001": "|**2025-08-12**|**Retrospective Sparse Attention for Efficient Long-Context Generation**|Seonghwan Choi et.al.|[2508.09001](http://arxiv.org/abs/2508.09001)|null|\n", "2508.08895": "|**2025-08-12**|**ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs**|Keyu Chen et.al.|[2508.08895](http://arxiv.org/abs/2508.08895)|null|\n", "2508.08531": "|**2025-08-12**|**Profiling Large Language Model Inference on Apple Silicon: A Quantization Perspective**|Afsara Benazir et.al.|[2508.08531](http://arxiv.org/abs/2508.08531)|null|\n", "2508.08457": "|**2025-08-11**|**Architecting Long-Context LLM Acceleration with Packing-Prefetch Scheduler and Ultra-Large Capacity On-Chip Memories**|Ming-Yen Lee et.al.|[2508.08457](http://arxiv.org/abs/2508.08457)|null|\n", "2508.08438": "|**2025-08-11**|**Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference**|Kexin Chu et.al.|[2508.08438](http://arxiv.org/abs/2508.08438)|null|\n", "2508.08343": "|**2025-08-11**|**Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving**|Ferran Agullo et.al.|[2508.08343_(SC)](http://arxiv.org/abs/2508.08343)|null|\n", "2508.08256": "|**2025-05-28**|**FIER: Fine-Grained and Efficient KV Cache Retrieval for Long-context LLM Inference**|Dongwei Wang et.al.|[2508.08256_(EMNLP)](http://arxiv.org/abs/2508.08256)|null|\n", "2508.09129": "|**2025-08-12**|**BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair**|Xianghe Pang et.al.|[2508.09129](http://arxiv.org/abs/2508.09129)|null|\n", "2508.09125": "|**2025-08-12**|**Complex Logical Instruction Generation**|Mian Zhang et.al.|[2508.09125](http://arxiv.org/abs/2508.09125)|null|\n", "2508.09124": "|**2025-08-12**|**OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows**|Weixuan Wang et.al.|[2508.09124](http://arxiv.org/abs/2508.09124)|null|\n", "2508.08987": "|**2025-08-12**|**ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation**|Ding Xia et.al.|[2508.08987](http://arxiv.org/abs/2508.08987)|null|\n", "2508.08940": "|**2025-08-12**|**Train Long, Think Short: Curriculum Learning for Efficient Reasoning**|Hasan Abed Al Kader Hammoud et.al.|[2508.08940](http://arxiv.org/abs/2508.08940)|null|\n", "2508.08930": "|**2025-08-12**|**How Does a Virtual Agent Decide Where to Look? - Symbolic Cognitive Reasoning for Embodied Head Rotation**|Juyeong Hwang et.al.|[2508.08930](http://arxiv.org/abs/2508.08930)|null|\n", "2508.08909": "|**2025-08-12**|**Compass-Thinker-7B Technical Report**|Anxiang Zeng et.al.|[2508.08909](http://arxiv.org/abs/2508.08909)|null|\n", "2508.08837": "|**2025-08-12**|**The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents**|Nicholas Sukiennik et.al.|[2508.08837_(AAAI)](http://arxiv.org/abs/2508.08837)|null|\n", "2508.08833": "|**2025-08-12**|**An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems**|Yuren Hao et.al.|[2508.08833](http://arxiv.org/abs/2508.08833)|null|\n", "2508.08821": "|**2025-08-12**|**3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs**|Noor Ahmed et.al.|[2508.08821](http://arxiv.org/abs/2508.08821)|null|\n", "2508.08791": "|**2025-08-12**|**Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments**|Junjie Ye et.al.|[2508.08791](http://arxiv.org/abs/2508.08791)|null|\n", "2508.08777": "|**2025-08-12**|**Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge**|Francesco Fabbri et.al.|[2508.08777_(RecSys)](http://arxiv.org/abs/2508.08777)|null|\n", "2508.08746": "|**2025-08-12**|**Interpretable Reward Model via Sparse Autoencoder**|Shuyi Zhang et.al.|[2508.08746](http://arxiv.org/abs/2508.08746)|null|\n", "2508.08726": "|**2025-08-12**|**Simulating Generative Social Agents via Theory-Informed Workflow Design**|Yuwei Yan et.al.|[2508.08726](http://arxiv.org/abs/2508.08726)|null|\n", "2508.08665": "|**2025-08-12**|**Aryabhata: An exam-focused language model for JEE Math**|Ritvik Rastogi et.al.|[2508.08665](http://arxiv.org/abs/2508.08665)|null|\n", "2508.08657": "|**2025-08-12**|**$\\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models**|Jiaxin Ju et.al.|[2508.08657_(IJCAI)](http://arxiv.org/abs/2508.08657)|null|\n", "2508.08653": "|**2025-08-12**|**LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement**|Rajmohan C et.al.|[2508.08653](http://arxiv.org/abs/2508.08653)|null|\n", "2508.08652": "|**2025-08-12**|**Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training**|Vishakha Lall et.al.|[2508.08652](http://arxiv.org/abs/2508.08652)|null|\n", "2508.08641": "|**2025-08-12**|**MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time**|Peter Phan et.al.|[2508.08641](http://arxiv.org/abs/2508.08641)|null|\n", "2508.08636": "|**2025-08-12**|**InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling**|Peiji Li et.al.|[2508.08636](http://arxiv.org/abs/2508.08636)|null|\n", "2508.08632": "|**2025-08-12**|**AgriGPT: a Large Language Model Ecosystem for Agriculture**|Bo Yang et.al.|[2508.08632](http://arxiv.org/abs/2508.08632)|null|\n", "2508.08509": "|**2025-08-11**|**Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression**|Jadie Adams et.al.|[2508.08509_(AAAI)](http://arxiv.org/abs/2508.08509)|null|\n", "2508.08501": "|**2025-08-11**|**GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games**|Yuchen Li et.al.|[2508.08501](http://arxiv.org/abs/2508.08501)|null|\n", "2508.08401": "|**2025-08-11**|**Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery**|Jiatong Li et.al.|[2508.08401](http://arxiv.org/abs/2508.08401)|null|\n", "2508.08386": "|**2025-08-11**|**CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation**|Shuzhou Yuan et.al.|[2508.08386](http://arxiv.org/abs/2508.08386)|null|\n", "2508.08332": "|**2025-08-10**|**Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming**|Humza Ashraf et.al.|[2508.08332](http://arxiv.org/abs/2508.08332)|null|\n", "2508.08308": "|**2025-08-08**|**First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models**|Chuanruo Fu et.al.|[2508.08308](http://arxiv.org/abs/2508.08308)|null|\n"}, "GNN": {"2506.12468": "|**2025-06-17**|**Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark**|Suyeon Kim et.al.|[2506.12468](http://arxiv.org/abs/2506.12468)|null|\n", "2506.12425": "|**2025-06-14**|**Optimizing Federated Learning using Remote Embeddings for Graph Neural Networks**|Pranjal Naman et.al.|[2506.12425_(DIS)](http://arxiv.org/abs/2506.12425)|null|\n", "2506.12197": "|**2025-06-13**|**Graph Semi-Supervised Learning for Point Classification on Data Manifolds**|Caio F. Deberaldini Netto et.al.|[2506.12197](http://arxiv.org/abs/2506.12197)|null|\n", "2505.20807": "|**2025-05-27**|**Simple yet Effective Graph Distillation via Clustering**|Yurui Lai et.al.|[2505.20807_(CLUSTER)](http://arxiv.org/abs/2505.20807)|null|\n", "2505.10806": "|**2025-05-16**|**RapidGNN: Communication Efficient Large-Scale Distributed Training of Graph Neural Networks**|Arefin Niam et.al.|[2505.10806](http://arxiv.org/abs/2505.10806)|null|\n", "2505.18177": "|**2025-05-15**|**FedGRec: Dynamic Spatio-Temporal Federated Graph Learning for Secure and Efficient Cross-Border Recommendations**|Zhizhong Tan et.al.|[2505.18177](http://arxiv.org/abs/2505.18177)|null|\n", "2505.07081": "|**2025-05-13**|**COMRECGC: Global Graph Counterfactual Explainer through Common Recourse**|Gregoire Fournier et.al.|[2505.07081_(ICML)](http://arxiv.org/abs/2505.07081)|null|\n", "2505.06810": "|**2025-05-11**|**QSeer: A Quantum-Inspired Graph Neural Network for Parameter Initialization in Quantum Approximate Optimization Algorithm Circuits**|Lei Jiang et.al.|[2505.06810](http://arxiv.org/abs/2505.06810)|null|\n", "2505.04083": "|**2025-05-07**|**Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training**|Aditya K. Ranjan et.al.|[2505.04083](http://arxiv.org/abs/2505.04083)|null|\n", "2504.18082": "|**2025-04-25**|**Efficient GNN Training Through Structure-Aware Randomized Mini-Batching**|Vignesh Balaji et.al.|[2504.18082](http://arxiv.org/abs/2504.18082)|null|\n", "2504.13266": "|**2025-04-17**|**Graph Learning at Scale: Characterizing and Optimizing Pre-Propagation GNNs**|Zichao Yue et.al.|[2504.13266](http://arxiv.org/abs/2504.13266)|null|\n", "2504.11808": "|**2025-04-16**|**Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs**|Kishan Gurumurthy et.al.|[2504.11808](http://arxiv.org/abs/2504.11808)|null|\n", "2504.04673": "|**2025-04-07**|**Sparsity-Aware Communication for Distributed Graph Neural Network Training**|Ujjaini Mukhodopadhyay et.al.|[2504.04673](http://arxiv.org/abs/2504.04673)|null|\n", "2504.04670": "|**2025-04-07**|**Scaling Graph Neural Networks for Particle Track Reconstruction**|Alok Tripathy et.al.|[2504.04670](http://arxiv.org/abs/2504.04670)|null|\n", "2503.19666": "|**2025-05-26**|**Towards Efficient Training of Graph Neural Networks: A Multiscale Approach**|Eshed Gal et.al.|[2503.19666](http://arxiv.org/abs/2503.19666)|null|\n", "2503.19173": "|**2025-03-31**|**Graph neural networks extrapolate out-of-distribution for shortest paths**|Robert R. Nerem et.al.|[2503.19173](http://arxiv.org/abs/2503.19173)|null|\n", "2503.18503": "|**2025-03-24**|**Deterministic Certification of Graph Neural Networks against Graph Poisoning Attacks with Arbitrary Perturbations**|Jiate Li et.al.|[2503.18503_(CVPR)](http://arxiv.org/abs/2503.18503)|null|\n", "2503.15360": "|**2025-03-19**|**Lyapunov-Based Graph Neural Networks for Adaptive Control of Multi-Agent Systems**|Brandon C. Fallin et.al.|[2503.15360](http://arxiv.org/abs/2503.15360)|null|\n", "2503.10544": "|**2025-03-29**|**DP-GPL: Differentially Private Graph Prompt Learning**|Jing Xu et.al.|[2503.10544](http://arxiv.org/abs/2503.10544)|null|\n", "2503.02960": "|**2025-03-04**|**Deal: Distributed End-to-End GNN Inference for All Nodes**|Shiyang Chen et.al.|[2503.02960](http://arxiv.org/abs/2503.02960)|null|\n", "2503.02959": "|**2025-03-04**|**Node-level Contrastive Unlearning on Graph Neural Networks**|Hong kyu Lee et.al.|[2503.02959](http://arxiv.org/abs/2503.02959)|null|\n", "2502.18998": "|**2025-02-26**|**Graph Neural Networks embedded into Margules model for vapor-liquid equilibria prediction**|Edgar Ivan Sanchez Medina et.al.|[2502.18998](http://arxiv.org/abs/2502.18998)|null|\n", "2502.17846": "|**2025-02-25**|**Armada: Memory-Efficient Distributed Training of Large-Scale Graph Neural Networks**|Roger Waleffe et.al.|[2502.17846](http://arxiv.org/abs/2502.17846)|null|\n", "2502.16835": "|**2025-02-24**|**Detecting Code Vulnerabilities with Heterogeneous GNN Training**|Yu Luo et.al.|[2502.16835](http://arxiv.org/abs/2502.16835)|null|\n", "2502.16703": "|**2025-02-23**|**Subsampling Graphs with GNN Performance Guarantees**|Mika Sarkin Jain et.al.|[2502.16703](http://arxiv.org/abs/2502.16703)|null|\n", "2502.12608": "|**2025-02-18**|**Unveiling Mode Connectivity in Graph Neural Networks**|Bingheng Li et.al.|[2502.12608](http://arxiv.org/abs/2502.12608)|null|\n", "2502.10776": "|**2025-02-15**|**A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction**|Zhipeng Liu et.al.|[2502.10776](http://arxiv.org/abs/2502.10776)|null|\n", "2501.02565": "|**2025-01-05**|**Efficient Graph Condensation via Gaussian Process**|Lin Wang et.al.|[2501.02565](http://arxiv.org/abs/2501.02565)|null|\n", "2412.20379": "|**2024-12-29**|**NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism**|Xin Ai et.al.|[2412.20379_(VLDB)](http://arxiv.org/abs/2412.20379)|null|\n", "2412.19229": "|**2025-02-21**|**Virtual Nodes Can Help: Tackling Distribution Shifts in Federated Graph Learning**|Xingbo Fu et.al.|[2412.19229_(AAAI)](http://arxiv.org/abs/2412.19229)|null|\n", "2412.17213": "|**2024-12-23**|**Attack by Yourself: Effective and Unnoticeable Multi-Category Graph Backdoor Attacks with Subgraph Triggers Pool**|Jiangtong Li et.al.|[2412.17213](http://arxiv.org/abs/2412.17213)|null|\n", "2412.08902": "|**2024-12-12**|**HC-SpMM: Accelerating Sparse Matrix-Matrix Multiplication for Graphs with Hybrid GPU Cores**|Zhonggen Li et.al.|[2412.08902_(ICDE)](http://arxiv.org/abs/2412.08902)|null|\n", "2412.08555": "|**2024-12-19**|**Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks Defending against Poisoning Attacks**|Ao Liu et.al.|[2412.08555](http://arxiv.org/abs/2412.08555)|null|\n", "2412.04747": "|**2024-12-06**|**Code generation and runtime techniques for enabling data-efficient deep learning training on GPUs**|Kun Wu et.al.|[2412.04747](http://arxiv.org/abs/2412.04747)|null|\n", "2412.03188": "|**2025-05-22**|**Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction**|Ivan Kralj et.al.|[2412.03188](http://arxiv.org/abs/2412.03188)|null|\n", "2411.17063": "|**2024-11-26**|**Contrastive Graph Condensation: Advancing Data Versatility through Self-Supervised Learning**|Xinyi Gao et.al.|[2411.17063](http://arxiv.org/abs/2411.17063)|null|\n", "2411.16025": "|**2025-05-26**|**Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers**|Chen Zhuang et.al.|[2411.16025](http://arxiv.org/abs/2411.16025)|null|\n", "2411.11020": "|**2024-11-17**|**Training a Label-Noise-Resistant GNN with Reduced Complexity**|Rui Zhao et.al.|[2411.11020](http://arxiv.org/abs/2411.11020)|null|\n", "2411.09476": "|**2025-07-25**|**Mean flow data assimilation using physics-constrained Graph Neural Networks**|M. Quattromini et.al.|[2411.09476](http://arxiv.org/abs/2411.09476)|null|\n", "2411.07672": "|**2024-11-12**|**Rethinking Structure Learning For Graph Neural Networks**|Yilun Zheng et.al.|[2411.07672](http://arxiv.org/abs/2411.07672)|null|\n", "2411.05693": "|**2024-11-08**|**YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural Network Training**|Yi Li et.al.|[2411.05693](http://arxiv.org/abs/2411.05693)|null|\n", "2411.02900": "|**2024-11-05**|**Distributed Graph Neural Network Design for Sum Ergodic Spectral Efficiency Maximization in Cell-Free Massive MIMO**|Nguyen Xuan Tung et.al.|[2411.02900](http://arxiv.org/abs/2411.02900)|null|\n", "2411.01109": "|**2024-11-02**|**Using Half-Precision for GNN Training**|Arnab Kanti Tarafder et.al.|[2411.01109](http://arxiv.org/abs/2411.01109)|null|\n", "2410.22697": "|**2024-11-03**|**MassiveGNN: Efficient Training via Prefetching for Massively Connected Distributed Graphs**|Aishwarya Sarkar et.al.|[2410.22697_(CLUSTER)](http://arxiv.org/abs/2410.22697)|null|\n", "2411.00843": "|**2025-02-14**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843](http://arxiv.org/abs/2411.00843)|null|\n", "2410.22120": "|**2024-10-29**|**Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act**|Barbara Hoffmann et.al.|[2410.22120](http://arxiv.org/abs/2410.22120)|null|\n", "2410.21618": "|**2024-10-28**|**Graph Sparsification for Enhanced Conformal Prediction in Graph Neural Networks**|Yuntian He et.al.|[2410.21618](http://arxiv.org/abs/2410.21618)|null|\n", "2410.16845": "|**2024-10-22**|**Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating Few-Shot Node Classification**|Yihong Luo et.al.|[2410.16845_(NeurIPS)](http://arxiv.org/abs/2410.16845)|null|\n", "2410.15556": "|**2024-10-25**|**Gradient Rewiring for Editable Graph Neural Network Training**|Zhimeng Jiang et.al.|[2410.15556_(NeurIPS)](http://arxiv.org/abs/2410.15556)|null|\n", "2410.06480": "|**2024-10-09**|**TCGU: Data-centric Graph Unlearning based on Transferable Condensation**|Fan Li et.al.|[2410.06480](http://arxiv.org/abs/2410.06480)|null|\n", "2410.05416": "|**2024-10-07**|**Haste Makes Waste: A Simple Approach for Scaling Graph Neural Networks**|Rui Xue et.al.|[2410.05416](http://arxiv.org/abs/2410.05416)|null|\n", "2410.05356": "|**2024-10-07**|**BSG4Bot: Efficient Bot Detection based on Biased Heterogeneous Subgraphs**|Hao Miao et.al.|[2410.05356](http://arxiv.org/abs/2410.05356)|null|\n", "2410.01657": "|**2024-10-02**|**Scalable and Consistent Graph Neural Networks for Distributed Mesh-based Data-driven Modeling**|Shivam Barwey et.al.|[2410.01657](http://arxiv.org/abs/2410.01657)|null|\n", "2410.02826": "|**2024-10-01**|**LinkThief: Combining Generalized Structure Knowledge with Node Similarity for Link Stealing Attack against GNN**|Yuxing Zhang et.al.|[2410.02826](http://arxiv.org/abs/2410.02826)|null|\n", "2409.19513": "|**2024-09-29**|**One Node Per User: Node-Level Federated Learning for Graph Neural Networks**|Zhidong Gao et.al.|[2409.19513](http://arxiv.org/abs/2409.19513)|null|\n", "2409.14939": "|**2024-09-23**|**FastGL: A GPU-Efficient Framework for Accelerating Sampling-Based GNN Training at Large Scale**|Zeyu Zhu et.al.|[2409.14939_(ASPLOS)](http://arxiv.org/abs/2409.14939)|null|\n", "2409.11129": "|**2024-09-17**|**Can Graph Reordering Speed Up Graph Neural Network Training? An Experimental Study**|Nikolai Merkel et.al.|[2409.11129_(VLDB)](http://arxiv.org/abs/2409.11129)|null|\n", "2409.05191": "|**2025-06-06**|**Generalization of Geometric Graph Neural Networks with Lipschitz Loss Functions**|Zhiyang Wang et.al.|[2409.05191](http://arxiv.org/abs/2409.05191)|null|\n", "2409.00657": "|**2024-09-08**|**HopGNN: Boosting Distributed GNN Training Efficiency via Feature-Centric Model Migration**|Weijian Chen et.al.|[2409.00657](http://arxiv.org/abs/2409.00657)|null|\n", "2408.13878": "|**2024-09-10**|**Generalization of Graph Neural Networks is Robust to Model Mismatch**|Zhiyang Wang et.al.|[2408.13878](http://arxiv.org/abs/2408.13878)|null|\n", "2408.13825": "|**2024-10-09**|**RoCP-GNN: Robust Conformal Prediction for Graph Neural Networks in Node-Classification**|S. Akansha et.al.|[2408.13825](http://arxiv.org/abs/2408.13825)|null|\n", "2408.11500": "|**2024-08-21**|**Slicing Input Features to Accelerate Deep Learning: A Case Study with Graph Neural Networks**|Zhengjia Xu et.al.|[2408.11500](http://arxiv.org/abs/2408.11500)|null|\n", "2408.09697": "|**2024-08-20**|**Heta: Distributed Training of Heterogeneous Graph Neural Networks**|Yuchen Zhong et.al.|[2408.09697](http://arxiv.org/abs/2408.09697)|null|\n", "2408.00232": "|**2024-08-01**|**CDFGNN: a Systematic Design of Cache-based Distributed Full-Batch Graph Neural Network Training with Communication Reduction**|Shuai Zhang et.al.|[2408.00232](http://arxiv.org/abs/2408.00232)|null|\n", "2407.15264": "|**2024-07-21**|**LSM-GNN: Large-scale Storage-based Multi-GPU GNN Training by Optimizing Data Transfer Scheme**|Jeongmin Brian Park et.al.|[2407.15264](http://arxiv.org/abs/2407.15264)|null|\n", "2407.13735": "|**2024-07-18**|**Predicting dark matter halo masses from simulated galaxy images and environments**|Austin J. Larson et.al.|[2407.13735_(ICML)](http://arxiv.org/abs/2407.13735)|null|\n", "2407.12671": "|**2024-07-17**|**GraphMuse: A Library for Symbolic Music Graph Processing**|Emmanouil Karystinaios et.al.|[2407.12671_(SMI)](http://arxiv.org/abs/2407.12671)|null|\n", "2407.08064": "|**2024-07-10**|**TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks**|Yezi Liu et.al.|[2407.08064](http://arxiv.org/abs/2407.08064)|null|\n", "2407.12860": "|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860](http://arxiv.org/abs/2407.12860)|null|\n", "2407.07912": "|**2024-07-03**|**ITEM: Improving Training and Evaluation of Message-Passing based GNNs for top-k recommendation**|Yannis Karmim et.al.|[2407.07912](http://arxiv.org/abs/2407.07912)|null|\n", "2407.11025": "|**2025-03-31**|**Backdoor Graph Condensation**|Jiahao Wu et.al.|[2407.11025_(ICDE)](http://arxiv.org/abs/2407.11025)|null|\n", "2407.02431": "|**2024-07-09**|**On the Robustness of Graph Reduction Against GNN Backdoor**|Yuxuan Zhu et.al.|[2407.02431](http://arxiv.org/abs/2407.02431)|null|\n", "2406.17611": "|**2024-06-25**|**Distributed Training of Large Graph Neural Networks with Variable Communication Rates**|Juan Cervino et.al.|[2406.17611](http://arxiv.org/abs/2406.17611)|null|\n", "2406.13984": "|**2024-06-20**|**Reducing Memory Contention and I/O Congestion for Disk-based GNN Training**|Qisheng Jiang et.al.|[2406.13984_(ICPP)](http://arxiv.org/abs/2406.13984)|null|\n", "2406.13200": "|**2025-05-11**|**RobGC: Towards Robust Graph Condensation**|Xinyi Gao et.al.|[2406.13200](http://arxiv.org/abs/2406.13200)|null|\n", "2406.10616": "|**2024-06-15**|**HiFGL: A Hierarchical Framework for Cross-silo Cross-device Federated Graph Learning**|Zhuoning Guo et.al.|[2406.10616_(KDD)](http://arxiv.org/abs/2406.10616)|null|\n", "2406.04938": "|**2024-06-07**|**SpanGNN: Towards Memory-Efficient Graph Neural Networks via Spanning Subgraph Training**|Xizhi Gu et.al.|[2406.04938](http://arxiv.org/abs/2406.04938)|null|\n", "2406.02964": "|**2024-06-05**|**Real-Time Small-Signal Security Assessment Using Graph Neural Networks**|Glory Justin et.al.|[2406.02964](http://arxiv.org/abs/2406.02964)|null|\n", "2406.00552": "|**2024-12-20**|**Graph Neural Network Training Systems: A Performance Comparison of Full-Graph and Mini-Batch**|Saurabh Bajaj et.al.|[2406.00552_(ATC)](http://arxiv.org/abs/2406.00552)|null|\n", "2405.17404": "|**2024-05-27**|**Spectral Greedy Coresets for Graph Neural Networks**|Mucong Ding et.al.|[2405.17404](http://arxiv.org/abs/2405.17404)|null|\n", "2405.17003": "|**2024-06-12**|**Graph Condensation for Open-World Graph Learning**|Xinyi Gao et.al.|[2405.17003_(KDD)](http://arxiv.org/abs/2405.17003)|null|\n", "2405.13902": "|**2024-06-06**|**LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework**|Yiran Qiao et.al.|[2405.13902](http://arxiv.org/abs/2405.13902)|null|\n", "2405.13707": "|**2025-01-23**|**Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition**|Xinyi Gao et.al.|[2405.13707_(WWW)](http://arxiv.org/abs/2405.13707)|null|\n", "2405.12521": "|**2024-05-21**|**Unleash Graph Neural Networks from Heavy Tuning**|Lequan Lin et.al.|[2405.12521](http://arxiv.org/abs/2405.12521)|null|\n", "2405.12295": "|**2024-11-19**|**Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks**|Marcin Podhajski et.al.|[2405.12295](http://arxiv.org/abs/2405.12295)|null|\n", "2405.10757": "|**2024-07-12**|**Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective**|Zhiwei Zhang et.al.|[2405.10757_(KDD)](http://arxiv.org/abs/2405.10757)|null|\n", "2405.06247": "|**2024-05-10**|**Disttack: Graph Adversarial Attacks Toward Distributed GNN Training**|Yuxiang Zhang et.al.|[2405.06247_(DIS)](http://arxiv.org/abs/2405.06247)|null|\n", "2405.05231": "|**2025-02-15**|**DiskGNN: Bridging I/O Efficiency and Model Accuracy for Out-of-Core GNN Training**|Renjie Liu et.al.|[2405.05231](http://arxiv.org/abs/2405.05231)|null|\n", "2405.00476": "|**2024-05-01**|**A Comprehensive Survey of Dynamic Graph Neural Networks: Models, Frameworks, Benchmarks, Experiments and Challenges**|ZhengZhao Feng et.al.|[2405.00476_(VLDB)](http://arxiv.org/abs/2405.00476)|null|\n", "2404.09544": "|**2024-04-15**|**GNNavigator: Towards Adaptive Training of Graph Neural Networks via Automatic Guideline Exploration**|Tong Qiao et.al.|[2404.09544_(DAC)](http://arxiv.org/abs/2404.09544)|null|\n", "2404.08364": "|**2024-04-26**|**FlowWalker: A Memory-efficient and High-performance GPU-based Dynamic Graph Random Walk Framework**|Junyi Mei et.al.|[2404.08364](http://arxiv.org/abs/2404.08364)|null|\n", "2404.02332": "|**2025-07-21**|**Learning nuclear cross sections across the chart of nuclides with graph neural networks**|Hongjun Choi et.al.|[2404.02332](http://arxiv.org/abs/2404.02332)|null|\n", "2404.02300": "|**2024-04-02**|**CATGNN: Cost-Efficient and Scalable Distributed Training for Graph Neural Networks**|Xin Huang et.al.|[2404.02300](http://arxiv.org/abs/2404.02300)|null|\n", "2403.20212": "|**2024-11-19**|**On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem**|Yimeng Min et.al.|[2403.20212](http://arxiv.org/abs/2403.20212)|null|\n", "2403.17092": "|**2024-03-25**|**A Unified CPU-GPU Protocol for GNN Training**|Yi-Chien Lin et.al.|[2403.17092](http://arxiv.org/abs/2403.17092)|null|\n", "2403.14853": "|**2024-03-21**|**iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations**|Md Saidul Hoque Anik et.al.|[2403.14853](http://arxiv.org/abs/2403.14853)|null|\n", "2403.10995": "|**2024-03-16**|**Edge Private Graph Neural Networks with Singular Value Perturbation**|Tingting Tang et.al.|[2403.10995](http://arxiv.org/abs/2403.10995)|null|\n", "2403.05752": "|**2024-03-22**|**Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling**|Hussein Abdallah et.al.|[2403.05752](http://arxiv.org/abs/2403.05752)|null|\n", "2402.15921": "|**2024-06-18**|**Pretraining Strategy for Neural Potentials**|Zehua Zhang et.al.|[2402.15921](http://arxiv.org/abs/2402.15921)|null|\n", "2402.15113": "|**2024-07-18**|**MSPipe: Efficient Temporal GNN Training via Staleness-Aware Pipeline**|Guangming Sheng et.al.|[2402.15113](http://arxiv.org/abs/2402.15113)|null|\n", "2506.21414": "|**2025-06-26**|**Accelerating GNN Training through Locality-aware Dropout and Merge**|Gongjian Sun et.al.|[2506.21414_(DATE)](http://arxiv.org/abs/2506.21414)|null|\n", "2506.20818": "|**2025-06-25**|**Demystifying Distributed Training of Graph Neural Networks for Link Prediction**|Xin Huang et.al.|[2506.20818_(ICDCS)](http://arxiv.org/abs/2506.20818)|null|\n", "2507.08845": "|**2025-07-08**|**DAFOS: Dynamic Adaptive Fanout Optimization Sampler**|Irfan Ullah et.al.|[2507.08845](http://arxiv.org/abs/2507.08845)|null|\n", "2507.13703": "|**2025-08-01**|**Binarizing Physics-Inspired GNNs for Combinatorial Optimization**|Martin Krutsk\u00fd et.al.|[2507.13703_(CHI)](http://arxiv.org/abs/2507.13703)|null|\n", "2508.04436": "|**2025-08-06**|**Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks**|Yujia Lu et.al.|[2508.04436](http://arxiv.org/abs/2508.04436)|null|\n", "2402.10074": "|**2024-05-07**|**Class-Balanced and Reinforced Active Learning on Graphs**|Chengcheng Yu et.al.|[2402.10074](http://arxiv.org/abs/2402.10074)|null|\n", "2402.05011": "|**2024-06-18**|**Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching**|Yuchen Zhang et.al.|[2402.05011](http://arxiv.org/abs/2402.05011)|null|\n", "2402.03671": "|**2024-02-28**|**ARGO: An Auto-Tuning Runtime System for Scalable GNN Training on Multi-Core Processor**|Yi-Chien Lin et.al.|[2402.03671](http://arxiv.org/abs/2402.03671)|null|\n", "2402.01261": "|**2024-03-15**|**TEDDY: Trimming Edges with Degree-based Discrimination strategY**|Hyunjin Seo et.al.|[2402.01261](http://arxiv.org/abs/2402.01261)|null|\n", "2401.11720": "|**2025-01-27**|**Graph Condensation: A Survey**|Xinyi Gao et.al.|[2401.11720](http://arxiv.org/abs/2401.11720)|null|\n", "2401.10522": "|**2024-01-19**|**FARe: Fault-Aware GNN Training on ReRAM-based PIM Accelerators**|Pratyush Dhingra et.al.|[2401.10522](http://arxiv.org/abs/2401.10522)|null|\n", "2401.08696": "|**2024-01-14**|**Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs**|Mingzhe Gao et.al.|[2401.08696](http://arxiv.org/abs/2401.08696)|null|\n", "2401.05610": "|**2024-01-11**|**Graph Q-Learning for Combinatorial Optimization**|Victoria M. Dax et.al.|[2401.05610](http://arxiv.org/abs/2401.05610)|null|\n", "2401.00755": "|**2024-01-01**|**Saliency-Aware Regularized Graph Neural Network**|Wenjie Pei et.al.|[2401.00755](http://arxiv.org/abs/2401.00755)|null|\n", "2312.16542": "|**2023-12-27**|**FALCON: Feature-Label Constrained Graph Net Collapse for Memory Efficient GNNs**|Christopher Adnel et.al.|[2312.16542](http://arxiv.org/abs/2312.16542)|null|\n", "2312.15520": "|**2023-12-24**|**Graph Coarsening via Convolution Matching for Scalable Graph Neural Network Training**|Charles Dickens et.al.|[2312.15520](http://arxiv.org/abs/2312.15520)|null|\n", "2312.02473": "|**2023-12-05**|**NeutronStream: A Dynamic GNN Training Framework with Sliding Window for Graph Streams**|Chaoyi Chen et.al.|[2312.02473](http://arxiv.org/abs/2312.02473)|null|\n", "2311.17847": "|**2023-11-29**|**FastSample: Accelerating Distributed Graph Neural Network Training for Billion-Scale Graphs**|Hesham Mostafa et.al.|[2311.17847](http://arxiv.org/abs/2311.17847)|null|\n", "2311.17373": "|**2023-11-29**|**The Devil is in the Data: Learning Fair Graph Neural Networks via Partial Knowledge Distillation**|Yuchang Zhu et.al.|[2311.17373](http://arxiv.org/abs/2311.17373)|null|\n", "2311.15772": "|**2023-11-27**|**Attend Who is Weak: Enhancing Graph Condensation via Cross-Free Adversarial Training**|Xinglin Li et.al.|[2311.15772](http://arxiv.org/abs/2311.15772)|null|\n", "2311.14898": "|**2023-11-25**|**HongTu: Scalable Full-Graph GNN Training on Multiple GPUs (via communication-optimized CPU data offloading)**|Qiange Wang et.al.|[2311.14898](http://arxiv.org/abs/2311.14898)|null|\n", "2311.14324": "|**2025-02-23**|**Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs**|Shengyin Sun et.al.|[2311.14324](http://arxiv.org/abs/2311.14324)|null|\n", "2311.13279": "|**2024-03-20**|**Comprehensive Evaluation of GNN Training Systems: A Data Management Perspective**|Hao Yuan et.al.|[2311.13279](http://arxiv.org/abs/2311.13279)|null|\n", "2311.13225": "|**2023-12-12**|**NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU Heterogeneous Environments**|Xin Ai et.al.|[2311.13225](http://arxiv.org/abs/2311.13225)|null|\n", "2311.06837": "|**2024-08-13**|**GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs on Large Clusters**|Jaeyong Song et.al.|[2311.06837](http://arxiv.org/abs/2311.06837)|null|\n", "2311.02909": "|**2024-04-19**|**Distributed Matrix-Based Sampling for Graph Neural Network Training**|Alok Tripathy et.al.|[2311.02909](http://arxiv.org/abs/2311.02909)|null|\n", "2311.02399": "|**2023-11-04**|**Entropy Aware Training for Fast and Accurate Distributed GNN**|Dhruv Deshmukh et.al.|[2311.02399](http://arxiv.org/abs/2311.02399)|null|\n", "2310.19321": "|**2023-10-30**|**D4Explainer: In-Distribution GNN Explanations via Discrete Denoising Diffusion**|Jialin Chen et.al.|[2310.19321](http://arxiv.org/abs/2310.19321)|null|\n", "2310.10953": "|**2023-10-17**|**A Local Graph Limits Perspective on Sampling-Based GNNs**|Yeganeh Alimohammadi et.al.|[2310.10953](http://arxiv.org/abs/2310.10953)|null|\n", "2310.09202": "|**2024-05-14**|**Graph Distillation with Eigenbasis Matching**|Yang Liu et.al.|[2310.09202](http://arxiv.org/abs/2310.09202)|null|\n", "2310.07100": "|**2023-10-11**|**GraphCloak: Safeguarding Task-specific Knowledge within Graph-structured Data from Unauthorized Exploitation**|Yixin Liu et.al.|[2310.07100](http://arxiv.org/abs/2310.07100)|null|\n", "2310.04668": "|**2024-02-24**|**Label-free Node Classification on Graphs with Large Language Models (LLMS)**|Zhikai Chen et.al.|[2310.04668](http://arxiv.org/abs/2310.04668)|null|\n", "2310.00837": "|**2023-10-02**|**Helios: An Efficient Out-of-core GNN Training System on Terabyte-scale Graphs with In-memory Performance**|Jie Sun et.al.|[2310.00837](http://arxiv.org/abs/2310.00837)|null|\n", "2309.16754": "|**2023-09-28**|**An Object Condensation Pipeline for Charged Particle Tracking at the High Luminosity LHC**|Kilian Lieret et.al.|[2309.16754](http://arxiv.org/abs/2309.16754)|null|\n", "2309.14450": "|**2023-09-25**|**Learning dislocation dynamics mobility laws from large-scale MD simulations**|Nicolas Bertin et.al.|[2309.14450](http://arxiv.org/abs/2309.14450)|null|\n", "2309.06423": "|**2023-09-13**|**Accelerating Defect Predictions in Semiconductors Using Graph Neural Networks**|Md Habibur Rahman et.al.|[2309.06423](http://arxiv.org/abs/2309.06423)|null|\n", "2309.03648": "|**2023-12-12**|**Promoting Fairness in GNNs: A Characterization of Stability**|Yaning Jia et.al.|[2309.03648](http://arxiv.org/abs/2309.03648)|null|\n", "2309.01568": "|**2023-09-04**|**ML-Based Top Taggers: Performance, Uncertainty and Impact of Tower & Tracker Data Integration**|Rameswar Sahu et.al.|[2309.01568](http://arxiv.org/abs/2309.01568)|null|\n", "2308.15602": "|**2024-08-12**|**An Experimental Comparison of Partitioning Strategies for Distributed Graph Neural Network Training**|Nikolai Merkel et.al.|[2308.15602](http://arxiv.org/abs/2308.15602)|null|\n", "2308.14949": "|**2023-08-29**|**Low-bit Quantization for Deep Graph Neural Networks with Smoothness-aware Message Propagation**|Shuang Wang et.al.|[2308.14949](http://arxiv.org/abs/2308.14949)|null|\n", "2308.13466": "|**2023-12-10**|**Staleness-Alleviated Distributed GNN Training via Online Dynamic-Embedding Prediction**|Guangji Bai et.al.|[2308.13466](http://arxiv.org/abs/2308.13466)|null|\n", "2308.12093": "|**2023-08-23**|**Cached Operator Reordering: A Unified View for Fast GNN Training**|Julia Bazinska et.al.|[2308.12093](http://arxiv.org/abs/2308.12093)|null|\n", "2308.10087": "|**2023-09-24**|**GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism**|Jingji Chen et.al.|[2308.10087](http://arxiv.org/abs/2308.10087)|null|\n", "2308.08097": "|**2023-08-16**|**S-Mixup: Structural Mixup for Graph Neural Networks**|Junghurn Kim et.al.|[2308.08097](http://arxiv.org/abs/2308.08097)|null|\n", "2308.03209": "|**2023-08-06**|**Communication-Free Distributed GNN Training with Vertex Cut**|Kaidi Cao et.al.|[2308.03209](http://arxiv.org/abs/2308.03209)|null|\n", "2308.00890": "|**2023-09-01**|**Tango: rethinking quantization for graph neural network training on GPUs**|Shiyang Chen et.al.|[2308.00890](http://arxiv.org/abs/2308.00890)|null|\n", "2307.00134": "|**2023-10-31**|**Generalization Limits of Graph Neural Networks in Identity Effects Learning**|Giuseppe Alessio D'Inverno et.al.|[2307.00134](http://arxiv.org/abs/2307.00134)|null|\n", "2306.16384": "|**2024-03-06**|**Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses**|Jeongmin Brian Park et.al.|[2306.16384](http://arxiv.org/abs/2306.16384)|null|\n", "2306.14375": "|**2023-06-26**|**Interpretable Sparsification of Brain Graphs: Better Practices and Effective Designs for Graph Neural Networks**|Gaotang Li et.al.|[2306.14375](http://arxiv.org/abs/2306.14375)|null|\n", "2306.13814": "|**2023-06-23**|**BatchGNN: Efficient CPU-Based Distributed GNN Training on Very Large Graphs**|Loc Hoang et.al.|[2306.13814](http://arxiv.org/abs/2306.13814)|null|\n", "2306.11264": "|**2023-06-20**|**GraphGLOW: Universal and Generalizable Structure Learning for Graph Neural Networks**|Wentao Zhao et.al.|[2306.11264](http://arxiv.org/abs/2306.11264)|null|\n", "2306.10466": "|**2023-08-24**|**Graph Ladling: Shockingly Simple Parallel GNN Training without Intermediate Communication**|Ajay Jaiswal et.al.|[2306.10466](http://arxiv.org/abs/2306.10466)|null|\n", "2306.04828": "|**2025-02-24**|**Fast and Effective GNN Training through Sequences of Random Path Graphs**|Francesco Bonchi et.al.|[2306.04828](http://arxiv.org/abs/2306.04828)|null|\n", "2306.04791": "|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791](http://arxiv.org/abs/2306.04791)|null|\n", "2306.01381": "|**2023-06-02**|**Adaptive Message Quantization and Parallelization for Distributed Full-graph GNN Training**|Borui Wan et.al.|[2306.01381](http://arxiv.org/abs/2306.01381)|null|\n", "2306.00899": "|**2023-12-18**|**Pitfalls in Link Prediction with Graph Neural Networks: Understanding the Impact of Target-link Inclusion & Better Practices**|Jing Zhu et.al.|[2306.00899](http://arxiv.org/abs/2306.00899)|null|\n", "2305.17408": "|**2023-05-27**|**AdaptGear: Accelerating GNN Training via Adaptive Subgraph-Level Kernels on GPUs**|Yangjie Zhou et.al.|[2305.17408](http://arxiv.org/abs/2305.17408)|null|\n", "2305.16588": "|**2023-06-12**|**Legion: Automatically Pushing the Envelope of Multi-GPU System for Billion-Scale GNN Training**|Jie Sun et.al.|[2305.16588](http://arxiv.org/abs/2305.16588)|null|\n", "2305.13854": "|**2023-05-23**|**The Evolution of Distributed Systems for Graph Neural Networks and their Origin in Graph Processing and Deep Learning: A Survey**|Jana Vatter et.al.|[2305.13854](http://arxiv.org/abs/2305.13854)|null|\n", "2305.09887": "|**2023-05-17**|**Simplifying Distributed Neural Network Training on Massive Graphs: Randomized Partitions Improve Model Aggregation**|Jiong Zhu et.al.|[2305.09887](http://arxiv.org/abs/2305.09887)|null|\n", "2305.07186": "|**2023-05-12**|**Learning to Code on Graphs for Topological Interference Management**|Zhiwei Shan et.al.|[2305.07186](http://arxiv.org/abs/2305.07186)|null|\n", "2304.09975": "|**2023-04-19**|**Solving the Kidney-Exchange Problem via Graph Neural Networks with No Supervision**|Pedro Foletto Pimenta et.al.|[2304.09975](http://arxiv.org/abs/2304.09975)|null|\n", "2304.04497": "|**2025-05-06**|**A Unified Framework for Exploratory Learning-Aided Community Detection Under Topological Uncertainty**|Yu Hou et.al.|[2304.04497](http://arxiv.org/abs/2304.04497)|null|\n", "2303.13775": "|**2024-06-27**|**GSplit: Scaling Graph Neural Network Training on Large Graphs via Split-Parallelism**|Sandeep Polisetty et.al.|[2303.13775](http://arxiv.org/abs/2303.13775)|null|\n", "2303.11081": "|**2024-08-21**|**Provably Convergent Subgraph-wise Sampling for Fast GNN Training**|Jie Wang et.al.|[2303.11081](http://arxiv.org/abs/2303.11081)|null|\n", "2303.07669": "|**2023-03-14**|**AutoTransfer: AutoML with Knowledge Transfer -- An Application to Graph Neural Networks**|Kaidi Cao et.al.|[2303.07669](http://arxiv.org/abs/2303.07669)|null|\n", "2303.01568": "|**2023-03-02**|**HitGNN: High-throughput GNN Training Framework on CPU+Multi-FPGA Heterogeneous Platform**|Yi-Chien Lin et.al.|[2303.01568](http://arxiv.org/abs/2303.01568)|null|\n", "2303.01277": "|**2023-03-02**|**Boosting Distributed Full-graph GNN Training with Asynchronous One-bit Communication**|Meng Zhang et.al.|[2303.01277](http://arxiv.org/abs/2303.01277)|null|\n", "2303.00158": "|**2023-03-01**|**HyScale-GNN: A Scalable Hybrid GNN Training System on Single-Node Heterogeneous Architecture**|Yi-Chien Lin et.al.|[2303.00158](http://arxiv.org/abs/2303.00158)|null|\n", "2302.13053": "|**2024-02-11**|**Scalable Neural Network Training over Distributed Graphs**|Aashish Kolluri et.al.|[2302.13053](http://arxiv.org/abs/2302.13053)|null|\n", "2303.01263": "|**2023-02-11**|**Unnoticeable Backdoor Attacks on Graph Neural Networks**|Enyan Dai et.al.|[2303.01263](http://arxiv.org/abs/2303.01263)|null|\n", "2302.04899": "|**2023-02-09**|**GCI: A (G)raph (C)oncept (I)nterpretation Framework**|Dmitry Kazhdan et.al.|[2302.04899](http://arxiv.org/abs/2302.04899)|null|\n", "2301.00391": "|**2023-01-05**|**PiPAD: Pipelined and Parallel Dynamic GNN Training on GPUs**|Chunyang Wang et.al.|[2301.00391](http://arxiv.org/abs/2301.00391)|null|\n", "2212.05410": "|**2022-12-11**|**ABC: Aggregation before Communication, a Communication Reduction Framework for Distributed Graph Neural Network Training and Effective Partition**|Junwei Su et.al.|[2212.05410](http://arxiv.org/abs/2212.05410)|null|\n", "2212.02374": "|**2023-08-11**|**On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural Networks**|Jhony H. Giraldo et.al.|[2212.02374](http://arxiv.org/abs/2212.02374)|null|\n", "2211.05368": "|**2023-11-29**|**A Comprehensive Survey on Distributed Training of Graph Neural Networks**|Haiyang Lin et.al.|[2211.05368](http://arxiv.org/abs/2211.05368)|null|\n", "2211.04598": "|**2022-11-08**|**Reducing Down(stream)time: Pretraining Molecular GNNs using Heterogeneous AI Accelerators**|Jenna A. Bilbrey et.al.|[2211.04598](http://arxiv.org/abs/2211.04598)|null|\n", "2211.00216": "|**2023-08-25**|**Distributed Graph Neural Network Training: A Survey**|Yingxia Shao et.al.|[2211.00216](http://arxiv.org/abs/2211.00216)|null|\n", "2210.17281": "|**2022-10-31**|**GNN at the Edge: Cost-Efficient Graph Neural Network Processing over Distributed Edge Servers**|Liekang Zeng et.al.|[2210.17281](http://arxiv.org/abs/2210.17281)|null|\n", "2210.13815": "|**2023-07-17**|**FocusedCleaner: Sanitizing Poisoned Graphs for Robust GNN-based Node Classification**|Yulin Zhu et.al.|[2210.13815](http://arxiv.org/abs/2210.13815)|null|\n", "2210.10737": "|**2023-07-02**|**RSC: Accelerating Graph Neural Networks Training via Randomized Sparse Computations**|Zirui Liu et.al.|[2210.10737](http://arxiv.org/abs/2210.10737)|null|\n", "2210.00162": "|**2022-10-01**|**Diving into Unified Data-Model Sparsity for Class-Imbalanced Graph Representation Learning**|Chunhui Zhang et.al.|[2210.00162](http://arxiv.org/abs/2210.00162)|null|\n", "2210.00102": "|**2023-04-08**|**MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization**|Xiaotian Han et.al.|[2210.00102](http://arxiv.org/abs/2210.00102)|null|\n", "2209.14107": "|**2022-09-28**|**Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure**|Shaohua Fan et.al.|[2209.14107](http://arxiv.org/abs/2209.14107)|null|\n", "2209.06800": "|**2023-06-27**|**MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel Communication-Computation Pipelining on Multi-GPU Platforms**|Yuke Wang et.al.|[2209.06800](http://arxiv.org/abs/2209.06800)|null|\n", "2208.11015": "|**2022-08-23**|**META-CODE: Community Detection via Exploratory Learning in Topologically Unknown Networks**|Yu Hou et.al.|[2208.11015](http://arxiv.org/abs/2208.11015)|null|\n", "2208.09151": "|**2022-08-19**|**Ginex: SSD-enabled Billion-scale Graph Neural Network Training on a Single Machine via Provably Optimal In-memory Caching**|Yeonhong Park et.al.|[2208.09151](http://arxiv.org/abs/2208.09151)|null|\n", "2207.14696": "|**2023-02-17**|**BiFeat: Supercharge GNN Training via Graph Feature Quantization**|Yuxin Ma et.al.|[2207.14696](http://arxiv.org/abs/2207.14696)|null|\n", "2207.09179": "|**2022-07-19**|**SCARA: Scalable Graph Neural Networks with Feature-Oriented Optimization**|Ningyi Liao et.al.|[2207.09179](http://arxiv.org/abs/2207.09179)|null|\n", "2207.08026": "|**2022-07-16**|**Rewiring Networks for Graph Neural Network Training Using Discrete Geometry**|Jakub Bober et.al.|[2207.08026](http://arxiv.org/abs/2207.08026)|null|\n", "2207.06027": "|**2022-07-13**|**Graph Property Prediction on Open Graph Benchmark: A Winning Solution by Graph Neural Architecture Search**|Xu Wang et.al.|[2207.06027](http://arxiv.org/abs/2207.06027)|null|\n", "2206.13697": "|**2022-06-28**|**Graph Condensation via Receptive Field Distribution Matching**|Mengyang Liu et.al.|[2206.13697](http://arxiv.org/abs/2206.13697)|null|\n", "2206.08258": "|**2022-06-16**|**ProGNNosis: A Data-driven Model to Predict GNN Computation Time Using Graph Metrics**|Axel Wassington et.al.|[2206.08258](http://arxiv.org/abs/2206.08258)|null|\n", "2206.07161": "|**2022-06-18**|**GraphFM: Improving Large-Scale GNN Training via Feature Momentum**|Haiyang Yu et.al.|[2206.07161](http://arxiv.org/abs/2206.07161)|null|\n", "2206.06369": "|**2023-09-20**|**Toward Dynamic Stability Assessment of Power Grid Topologies using Graph Neural Networks**|Christian Nauck et.al.|[2206.06369](http://arxiv.org/abs/2206.06369)|null|\n", "2206.04255": "|**2022-06-09**|**ScatterSample: Diversified Label Sampling for Data Efficient Graph Neural Network Learning**|Zhenwei Dai et.al.|[2206.04255](http://arxiv.org/abs/2206.04255)|null|\n", "2206.00057": "|**2022-10-02**|**Distributed Graph Neural Network Training with Periodic Stale Representation Synchronization**|Zheng Chai et.al.|[2206.00057](http://arxiv.org/abs/2206.00057)|null|\n", "2205.04711": "|**2022-05-10**|**SmartSAGE: Training Large-scale Graph Neural Networks using In-Storage Processing Architectures**|Yunjae Lee et.al.|[2205.04711](http://arxiv.org/abs/2205.04711)|null|\n", "2204.11224": "|**2022-04-24**|**Optimizing Task Placement and Online Scheduling for Distributed GNN Training Acceleration**|Ziyue Luo et.al.|[2204.11224](http://arxiv.org/abs/2204.11224)|null|\n", "2204.08570": "|**2023-09-27**|**A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability**|Enyan Dai et.al.|[2204.08570](http://arxiv.org/abs/2204.08570)|null|\n", "2508.07624": "|**2025-08-11**|**Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction**|Vishakha Lall et.al.|[2508.07624](http://arxiv.org/abs/2508.07624)|null|\n"}}